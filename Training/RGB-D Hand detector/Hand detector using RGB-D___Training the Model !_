{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Hand detector using RGB-D___Training the Model ! ","provenance":[{"file_id":"1j9YAAnSnD3pjQzpVTOS_tukH9MHhwqYW","timestamp":1595596649982},{"file_id":"1cK35qC-TLZaq3yYIJ17blYwHlruDONAs","timestamp":1573686550479},{"file_id":"1C_2v6KjN6dZZ-flb_lkz0j8ziV84d6fU","timestamp":1573316705390},{"file_id":"1usT_XYE6DLENeUL3__GNCYAWn-0NbVh6","timestamp":1568919264845}],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"YRT5qvblcdFc","colab_type":"text"},"source":["# RGB-D Based Hand Detection Using Tensorflow in Google Colab\n"]},{"cell_type":"markdown","metadata":{"id":"6SJZzoLKcg16","colab_type":"text"},"source":["## Installation :"]},{"cell_type":"code","metadata":{"id":"JxDIhVU2YTqa","colab_type":"code","colab":{}},"source":["!pip uninstall tensorflow tensorflow-gpu -y\n","!pip install  tensorflow==1.14 tensorflow-gpu==1.14"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Vij1Sifcf-2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1599563163335,"user_tz":-60,"elapsed":2201,"user":{"displayName":"Hazem Barka","photoUrl":"","userId":"05856545852072919715"}},"outputId":"200ac331-f907-425b-8350-0a8265b4e8d7"},"source":["\n","#%tensorflow_version 2.x\n","import tensorflow as tf\n","print(tf.__version__)\n","print('GPU: ',tf.test.is_gpu_available())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1.14.0\n","GPU:  True\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"F_4wD4L_crWr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":161},"executionInfo":{"status":"ok","timestamp":1599563170342,"user_tz":-60,"elapsed":3776,"user":{"displayName":"Hazem Barka","photoUrl":"","userId":"05856545852072919715"}},"outputId":"f8cbe3bb-8a53-46c8-a5f6-ae3258aca2ae"},"source":["!pip install tf_slim"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting tf_slim\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n","\u001b[K     |████████████████████████████████| 358kB 2.8MB/s \n","\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf_slim) (0.8.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n","Installing collected packages: tf-slim\n","Successfully installed tf-slim-1.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Nw9Zqqbvcudj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":158},"executionInfo":{"status":"ok","timestamp":1599563195176,"user_tz":-60,"elapsed":22633,"user":{"displayName":"Hazem Barka","photoUrl":"","userId":"05856545852072919715"}},"outputId":"d6d481d4-e12e-4f26-b3da-ed9456516394"},"source":["%cd /root/\n","!git clone https://github.com/tensorflow/models.git # Import required models from Github"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/root\n","Cloning into 'models'...\n","remote: Enumerating objects: 11, done.\u001b[K\n","remote: Counting objects: 100% (11/11), done.\u001b[K\n","remote: Compressing objects: 100% (10/10), done.\u001b[K\n","remote: Total 43432 (delta 4), reused 8 (delta 1), pack-reused 43421\u001b[K\n","Receiving objects: 100% (43432/43432), 550.11 MiB | 37.77 MiB/s, done.\n","Resolving deltas: 100% (29548/29548), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KyQy36Z6RMkF","colab_type":"code","colab":{}},"source":["!rm -rf -d /root/models/trained"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vki1BqgXab5t","colab_type":"code","colab":{}},"source":["!mkdir  /root/models/trained"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LX8I-u56cza7","colab_type":"text"},"source":["Install Tensorboard :"]},{"cell_type":"markdown","metadata":{"id":"FY4MRhLNZuZb","colab_type":"text"},"source":["\n","execute it twice !"]},{"cell_type":"code","metadata":{"id":"jocUvRRQc0HY","colab_type":"code","colab":{}},"source":["!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","!unzip -o ngrok-stable-linux-amd64.zip\n","#the logs that are created while training \n","LOG_DIR = \"/root/models/trained\"\n","get_ipython().system_raw(\n","    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n","    .format(LOG_DIR)\n",")\n","get_ipython().system_raw('./ngrok http 6006 &')\n","#The link to tensorboard.\n","#works after the training starts.\n","!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8OCecfGYdIEL","colab_type":"text"},"source":["Protobuf :\n"]},{"cell_type":"code","metadata":{"id":"Yac4O0I6dJme","colab_type":"code","colab":{}},"source":["%cd /root/models/research/\n","!protoc object_detection/protos/*.proto --python_out=.\n","import os\n","os.environ['PYTHONPATH'] += ':/root/models/research/:/root/models/research/slim/:/root/models/research/object_detection/utils/:/root/models/research/object_detection'\n","!python object_detection/builders/model_builder_test.py"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CbYaVcOJdbb6","colab_type":"text"},"source":["## Importing Data :"]},{"cell_type":"code","metadata":{"id":"bnVWB5acffJ8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":125},"executionInfo":{"status":"ok","timestamp":1599563692823,"user_tz":-60,"elapsed":41898,"user":{"displayName":"Hazem Barka","photoUrl":"","userId":"05856545852072919715"}},"outputId":"8548af50-611e-438e-b030-441af15e5729"},"source":["from google.colab import drive\n","drive.mount('/root/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /root/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"f63Fk1PkzhOi","colab_type":"text"},"source":["please download the NYU dataset ! you can use the training set instead of test but it will take more than 24h"]},{"cell_type":"code","metadata":{"id":"32L67xiZddo7","colab_type":"code","colab":{}},"source":["import os\n","!unzip -qq '/root/drive/My Drive/NYU.zip' 'dataset/test/*' -d /root/"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xaPQl1P-KGCq","colab_type":"text"},"source":["Preprocessing data :"]},{"cell_type":"code","metadata":{"id":"h3ODRqLKKFFl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1599568540092,"user_tz":-60,"elapsed":4789491,"user":{"displayName":"Hazem Barka","photoUrl":"","userId":"05856545852072919715"}},"outputId":"4572e62b-bc88-4869-ae76-044504375945"},"source":["\n","from IPython.display import clear_output\n","\n","\n","import sys\n","import numpy as np\n","import cv2\n","\n","import os\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","from PIL import Image\n","\n","\n","\n","\n","## A function to rescale depth values from maximum-minimum to 0-255\n","## RGB-D Hand detector uses RGB(0-255) encoded format instead of 1 depth channel with mm values\n","\n","min_depth_for_scaling = 0   # changes for each image\n","max_depth_for_scaling = 1500\n","def mp(entry):\n","    if entry>max_depth_for_scaling or entry<50:\n","        return 0\n","    else :\n","        return 255-((entry-min_depth_for_scaling)/(max_depth_for_scaling-min_depth_for_scaling)*255)\n","\n","mp = np.vectorize(mp)\n","\n","\n","def loadDepthMap(filename):\n","        \"\"\"\n","        Read a depth-map\n","        :param filename: file name to load\n","        :return: image data of depth image\n","        \"\"\"\n","        global min_depth_for_scaling\n","\n","        img = Image.open(filename)\n","        # top 8 bits of depth are packed into green channel and lower 8 bits into blue\n","        #assert len(img.getbands()) == 3\n","\n","        r, g, b = img.split()[:3]\n","        r = np.asarray(r, np.int32)\n","        g = np.asarray(g, np.int32)\n","        b = np.asarray(b, np.int32)\n","        dpt = np.bitwise_or(np.left_shift(g, 8), b)\n","        #now we have the  depth in mm ==> preprocess and save in /255 scale\n","        imgdata = np.asarray(dpt, np.float32)\n","        min_depth_for_scaling = np.min(imgdata)\n","        imgdata = mp(imgdata)\n","\n","        return imgdata.astype(np.uint8)\n","\n","if __name__ == '__main__':\n","  for imageFolder in ['/root/dataset/test']:\n","    files = os.listdir(imageFolder)\n","    for f in range(len(files)):\n","          try:\n","                filename = os.path.join(imageFolder,files[f])\n","                clear_output(wait=True)\n","                print('file number: ',f,'   file name: ',filename)\n","                depth_frame = loadDepthMap(filename)\n","                im = Image.fromarray(depth_frame).convert('RGB')\n","                im.save(filename)\n","                if cv2.waitKey(1) >= 0:\n","                    break\n","          except:\n","                continue\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["file number:  8255    file name:  /root/dataset/test/depth_1_0005031.png\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4_vYgPaWRxVp","colab_type":"text"},"source":["After preprocessing :"]},{"cell_type":"code","metadata":{"id":"i1ibe7qJLddd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":268},"executionInfo":{"status":"ok","timestamp":1599568624323,"user_tz":-60,"elapsed":682,"user":{"displayName":"Hazem Barka","photoUrl":"","userId":"05856545852072919715"}},"outputId":"35901b07-7def-4de3-8f02-343758769580"},"source":["\n","img = Image.open(os.path.join('/root/dataset/test',files[1]))\n","plt.imshow(img)\n","plt.show()\n","\n"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAUoAAAD8CAYAAAARze3ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2deXQc1Z3vv7f31m7JWqzNlrzJNli28YodDHgDAjgJyzDJSQjDDAnJvEMm884LSQ7zJjNzzhBm5oVhQkgI5B14vJABkgcOEAPDGhyM8Y4xNl6wjeRFWLKsXerlvj+6b3H79r1V1bKWlvT7nNOnq27duvWrkurbv99dGeccBEEQhBnPaBtAEASR7ZBQEgRBOEBCSRAE4QAJJUEQhAMklARBEA6QUBIEQTgwLELJGLuKMXaQMXaYMXb3cFyDIAhipGBD3Y+SMeYF8BGAdQCaALwH4M855/uH9EIEQRAjxHB4lEsBHOacH+WcDwD4DYCNw3AdgiCIEcE3DGVWAfhE2m8CsMzuBMYYDQ8iCGK0Ocs5L9UdGA6hdAVj7A4Ad4zW9QmCIBSOmw4Mh1A2A6iR9quTaSlwzh8G8DBAHiVBENnNcNRRvgdgJmOsjjEWAHALgE3DcB2CIIgRYcg9Ss55lDH21wBeAuAF8CvO+QdDfR2CIIiRYsi7Bw3KCAq9CYIYfXZwzhfrDtDIHIIgCAdIKAmCIBwgoSQIgnCAhJIgCMIBEkqCIAgHSCgJgiAcIKEkCIJwgISSIAjCARJKgiAIB0goCYIgHCChJAiCcICEkiAIwgESSoIgCAdIKAmCIBwgoSQIgnCAhJIgCMIBEkqCIAgHSCgJgiAcIKEkCIJwgISSIAjCARJKgiAIB0goCYIgHCChJAiCcICEkiAIwgESSoIgCAdIKAmCIBwgoSQIgnCAhJIgCMIBEkqCIAgHfKNtAEGMBMXFxfD5fOjs7ERvb682T1FREaLRKLq6ukbYOiLbIaEkxjXBYBDz58/Hl770JYTDYRw+fBibN29GZ2cnzpw5g4KCAhQWFqKoqAjXXXcdent7cerUKRw6dAiffvopAKCjowPt7e2jfCfEaMI456NtAxhjo28EMW4oLi7G+vXrceLECVx66aWora0FYwyMMXg8Hni9XnR3d2Pbtm2Ix+NobGwEYwwAwDmHeCc8Hg8YY9i3bx+eeuopRCKR0bwtYvjZwTlfrDtAQkmMC7xeL3w+H6ZPn441a9Zg6tSp8Pv9lkACCeETQino6OhAb2+vJYoAUr4ZY+Cc49SpU3j66adx8uTJkb85YqQgoSTGN1deeSWWLFmC3NxcBINBhEIheDyJtkrhScrfQgx7e3vR2dkJACnH1I/X68XZs2fx+OOPo6mpCfF4fNTulRg2SCiJ8UkwGERDQwNWr16NKVOmwOPxIBgMwuv1poTbqggCn4XZ8Xgc8XgcnHNEIhHE43ErD4CU8/r6+nD//feTZzk+MQolNeYQY5ZQKIQVK1Zg7dq1CAaD8Pl8WlGURVMOq4VQyiE2AMRiMcgOhHxeKBTCypUr8eqrr6KtrW3kb5oYFRz7UTLGfsUYa2GM7ZPSihljrzDGDiW/JyXTGWPsAcbYYcbYXsbYouE0npjYXHzxxVizZg38fj/8fn+KSMr1kWJbDbtl8dQJrBqqi/3Vq1fj8ssvR3l5Oa6//nrcdtttmDx5cooXSowvHENvxthlALoAPM45vyiZdh+ANs75vYyxuwFM4px/jzF2DYD/BuAaAMsA/DvnfJmjERR6E4Pga1/7GubMmYNwOJwijHZ1kgL5/15u6eacIxqNIhqNWsfVRh4A6OrqQk9Pj5XW2tqK7du345133hm2+yWGHWPo7ehRcs7fAqDGGBsBPJbcfgzAF6T0x3mCrQCKGGNTBmczQehhjKGiogJlZWUIBoOWSPp8Pni9XsuLlL1JXeit8xxFOSaPUpyfn5+PkpISa3/SpEm45JJLkJeXN2rPhRg+BjuEsZxzfiq5fRpAeXK7CsAnUr6mZBpBDBmFhYW48847UVlZaYmhEEldmJ2JSIqygsEg/H5/SpkCUY7P50N+fr51fNKkSfj85z+PUCg0Ks+FGD4ueKw3T8QsGYfOjLE7GGPbGWPbL9QGYmIhWrblxho15M70owqsaBiSy9Z9QqFQSv1oQ0MDFi9ejGAwONqPiRhCBiuUZ0RInfxuSaY3A6iR8lUn09LgnD/MOV9sqhMgCBMXXXSRFR4Lj0/nGerqJt14mQK5PFUwZYTnKTqyr1ixAgUFBcP8FIiRZLBCuQnArcntWwE8J6V/Ldn6vRzAeSlEJ4ghoaCgAD6fLyXcNrVeA3oRlFEba1TBlRuK5OsJ5G5JHo8HAwMDxok3iLGJYz9KxtiTAC4HMJkx1gTgfwK4F8BTjLHbARwHcHMy+4tItHgfBtAD4LZhsJmYwPj9ftTW1jqKJJDasi2wOyaOi76VduliH0j0u5TrMIVtxPjBUSg5539uOLRGk5cD+PaFGkUQJvx+P6qrq40hNJDajUftOC7S3PR51JUjC6a6LcTS7/dj9uzZ2LZt24XdLJE10MS9xJjB6/Vi48aNCIfDjmG02Nb1gbRr1FGPZ9K1SGwXFBTgsssuQ2Fh4XA9CmKEIaEkxgyMMdTX16eEtXJncbvzdGkmkdQdtytXbsgR5OfnY/bs2fD5aJTweICEkhgzRKNR7N271xJH9QOkj7JxI6QmTOG8QC5b1JfG43HEYjEAwNq1a5GTkzOoaxPZBf3cEWOGUCiEuXPnWjP+mMRL/lbTTd6hqS7TDrVMj8eTNqEGMT4goSTGBIFAABs3bsTkyZOtuSDVfo1CPE39J3WowmrXyCM34OiOiana5LzE+ICEkhgTrF+/HosWLQLnHLFYLEUU4/E4/H6/JaBqA4uKLHZy+GzqEqSmqenyttfrtea3PH36tBWGE2MbEkpizKCK1sDAAAYGBuDxeJCbm5syo7lA7rajCqFch6nzRE2eo5xP5BHepLhWZ2cnnnnmGXR3d1/obRNZADXmEGOC/fv3p+zLXqDf77fqLeVZy9VtFdWbNLWAy9fTpetC7p07d+L8+fNDdPfEaEMeJTFm0ImVCLFN4bPwFk0htqnRR2zrhFa3hIScx+Px4PDhw0Nxy0SWQEJJjClUz00dd+2mEcfOu9TVX6pdjFSRVEXY7cgfYuxAQkmMGUxjsHXbunPj8XjKmGxZEEXjkM5zdONlkjCOb6iOkhgTnDx5EqdPn05Jc9vfUUbXQV13TPUa5eM6b1L9NDY2XugtE1kECSUxJujr60NfX58xrDU1wugwiaRdA5AqoHZlc85RWFhIXuY4goSSGDP09/en7JuE0Y2HaRraaOclqmIqX0sV1ZqaGpSUlGR2g0TWQkJJjBl2796d0egXnZfpVkTVfV3Djq7TOgA0NTXhhRdeQFdXVwZ3R2Qz1JhDjBk6OzsRiUSMKyuaOo7LxwaD3L1IJ6IiFBfbn376KXbu3DmoaxHZCXmUxJjhxIkT6OzsdJXXacIMk2fpJt0UinPO0dbWhrffftuVjcTYgYSSGDPE43GcOXMmbc5IgW5OSTnfYDxKNdS28yw559i5cydOnaJlosYbJJTEmCEej+PNN9/ESy+9lCZGmYrhYPKbECLZ19eHo0ePuiqPGFtQHSUxpmhqakJTUxNOnDiBW265BZWVlQDShyXa7Ys0FV14Lcp2agRqaWnB22+/jU8++STzmyKyHhJKYkxy9OhRHDt2zBJKFd247gtF9UAjkQg+/vhj7Ny5E3v27KElascxJJTEoAmFQli7di0CgQA453jrrbfQ2to6YtfftWsXLr30UgBmL1Idv23CKbTW8dZbb+H555/PaGQQMTYhoSQGhd/vx6233op//dd/hc/nQzwex8svv4y/+qu/wtmzZ0fEhmXLlqUIoTyWW0zo67YeUhVaN+La2dlJIjlBoMYcYlBs2LAB//AP/2CtMsgYw/r16/Hwww9j2rRpI2JDOBxOm+rM9HEzEkc3G5CcT/4+e/Ys1UdOIEgoiYypqqrC7bffjvz8/JR0xhg2bNiAp59+GsFgcFht8Pl81vIPshiKZSJisZj10U1sIX9isRgikQgGBgYQjUatc+LxOKLRqLUtFg7r6OjAQw89hCNHjgzrPRLZAwklkTGnTp1KG3ctYIyhrq4Oy5cvH1YbysrKUFNTo53RR90W4qcjGo0iEolYIhiLxaw0cV40GrW2Y7EYnnrqKUQiEdTX1yMvL29Y75PIDqiOksiYxsZGzJs3z3hciNNwolu3Rmzr0mOxmLX2tpxXFVDTCByZGTNm4NJLL0VtbS2efPJJ7NmzZ+hujMhKyKMkMqazs9PypHTdcFpaWrBjx44Rs0dd6kHF7thgug/V1dVh8uTJABLVEMT4h4SSyJgjR46kNGSoQjRp0iTMmTNnWG1wO15b7Tiuoq4N7obKykrk5eWBMYbp06fTvJMTABJKImM453jllVeMQlVUVIQZM2YMqw2zZs2ybFFtk7+FCAYCAW05YiaiTJDX6unu7qYuQhMAEkrCoqCgAAUFBa7y/upXv8LOnTuNIlFdXT2UpqWQl5eHZcuWWft2k+h6PB74/X7jEEYheuoiZXIZarqoB+3s7MSzzz47hHdGZCvUmDPBueiii1BaWopZs2YhHo/jwIED2LdvH86dO2d73unTp7F//34sWrRIO/rlzjvvREtLC55//vkhX9/a7/ejoKAgbWYf3Ugcu7DaLnzXHVe7FQ0MDKCjo2MI74zIVkgoJzjxeBz/8i//gunTp6OwsBCtra346U9/ivvuu89x7LK8dowqKMXFxbjvvvuwZ8+ejITS4/GgsLAQGzZsQElJCXp6evDcc8+hra0tpfxYLGaF06ZJeYey7tBU70lMDCj0nsCEw2HEYjFUVFSgqKgIjDGUlJRYImUHYwxFRUVGjysQCCA3Nxe33347CgsLXdv01a9+Fbt378YjjzyCf/u3f8NPf/pTvPHGG5g9e7aV5/z583jhhRfQ2dmZFjLL9gFIWzpCh2luSbt8nHMcO3bMdqExYvxAQjmBWb16NZ599lkUFRWlpC9btgxf/epXbc/1er2YOXMmgPTJbQUejwczZ85EJBJxZY/P58P69etRXl5uDY30er2YNWtWyrBIzjm2bduGBx98EO3t7Wlr48j9KFWRdArDVTFU70nm5MmTJJQTBBLKCczNN9+M2bNnIzc3F0CqINxwww2YOnWq7fl+vz9lX+eZvfPOO+jp6XFlT1lZGdatWwcgXdC++MUvppXd2tqK5ubmtHRTS7jORt21dKhCGovFqH5yAkFCOYGpq6szHluwYAH++q//Gl6v11VZOgGKx+N47rnnXNsjRs7ohMs00cYbb7yBgYEBrT264Y0m29WPCXE8EomM6JRyxOjiKJSMsRrG2OuMsf2MsQ8YY3cl04sZY68wxg4lvycl0xlj7AHG2GHG2F7G2KLhvglicIjRM6bQ+dvf/jZWr16tPZfzxNIHbjt+u+FLX/oScnNztWX29fVpzzl+/Dja2tqM9yD2xVhuNZ9JIHVdjuRPKBSy/aEhxhduPMoogL/lnM8FsBzAtxljcwHcDeBVzvlMAK8m9wHgagAzk587ADw05FYTQ8KLL76o9cYEfr8fU6ZM0R4bGBjAD37wg7S1q914ZTqCwSCuvPJKYxj82GOPadN9Ph/OnTvnOJWaPDmGPKOQ8DbV/Oq3TmRNndiJ8YejUHLOT3HOdya3OwF8CKAKwEYA4r/3MQBfSG5vBPA4T7AVQBFjTP+2EaPK+fPn0dPToxUBwa233mo8f+fOnbbn79+/H01NTa5s+dznPofPfe5zxuOmes7Zs2djxowZRo9Q3penX5OnU8ukL6WctmDBAqvRiRjfZFRHyRibBmAhgHcBlHPOxVJ4pwGUJ7erAMgzmjYl09Sy7mCMbWeMbc/QZuICycnJweWXX44vf/nLGBgYsBWYxsZGq4FFpby8HH6/3xi+nj59Gu3t7a5sqqurQzgc1obDH3/8MXbt2qU9r7i4OCMP1hRu27Vw687hPDEvZaaeMzE2cf1zyBjLA/BbAN/hnHcow7o4Yyyj/xjO+cMAHk6WTf9tI8hdd92FH/3oR8Yhe2Kfc45JkybhnnvuwdatW9HZ2ZmS54orrnA95NGOQCCAm266yXi8s7NT23BSU1ODK664Is1uAGmjc+RjKjqRNKWJ+s59+/bhxRdfNM5zSYwvXHmUjDE/EiL5fznnv0smnxEhdfK7JZneDKBGOr06mUZkAeFwGJdddpl2XWtTo8Yll1yCDRs2pJUlvFFTeOqWVatWYenSpUbPcPfu3dr+isFgUOvRquU4hdeq3XYiKco6ceKEa2+ZGPu4afVmAB4F8CHn/H9JhzYBEBVYtwJ4Tkr/WrL1ezmA81KITowyU6ZMweLFi9PSdaIg0rxeL1auXJl2zgsvvJA2tFA+b/r06VandDvWr1+f0idTLueTTz7Bgw8+6Koe0anxZag+0WgUBw8edLwvYvzgxqNcCeCrAK5kjO1Ofq4BcC+AdYyxQwDWJvcB4EUARwEcBvBLAN8aerOJwbJx40YrXNbVz5nq7IqKitIaLtra2rBlyxbtdTjnmDp1Kh599FEUFxcb7Zk+fTpuvvlmY51he3u7cbmF/v5+Yx2rW9GTW7/d5BUThwz1RB9EduNYR8k5fxuAaejCGk1+DuDbF2gXMUycPXsW0WjUmnpMJ5IC+VhtbS1CoVBKd6CamhrMnDlTWy8oqKurQ05OTornKbNo0SKUlpamXE+2p7S0FCdPnkw7LxAIgDGG1tZWVFRUpNmfyZrepmeg80ybm5vx8ssv23arIsYfNDJnAuHz+dDY2GjtO4Wo8v78+fNx0UUXpZR35ZVXpkxWofPsvF4vpk+frrWntrYW9957r9HL45yjt7cXLS0tKefl5OTgS1/6EjZu3AjGWMqqiWp/SrciaUpXvc6XX36ZRuRMQEgoJxDRaBQPPfSQcVZuu3rKnJwc3HnnnSl1iZs3b7adt5JzjmAwiMsuu0x7vLCwMK0aQD1/3759aZNq9Pb24vjx42CMWfboxN10f+q92V1fFm+71RyJ8Q0J5QTj1KlT2L490XXVJBimEHz9+vVYtOizEaktLS1WWbr8QKJl/L333kvLU1hYiL/8y7+0Wq3l82Rv8qGHHkoLczlPDCHknGvX7Vbvxc7DNNXL6s5taWlJWSuImDiQUE4wenp6cM8992Dbtm0p6Xbht0jLy8vDd7/7XWt+yf7+fnz44Ydp5cjfkUgE+/btS7Pjtttuw5e//OW0dPn8N998E++88472PrxeLzhPtEB3dXWlhd2D+ajXlz+xWAy5ubnYsGEDKioqLDvC4TAKCwtRWFiI4uJiLFiwIOU4MT6g8VcTkB07duD48eNYsmRJ2jE7zwwA5s6dazWkTJkyBadOnUI0Gk2ZZcipXhBI1JfKreg6T+/YsWPGyTBkIpEI4vE4PB6PMewWqJ3PTR6mKp7xeBw+nw/z5s1DKBTCli1b0NraigULFmDy5Mkp811WVlZiy5Yt1DI+jiCPcoLy5JNPpnlgAp1YCMrKyqwGnGAwiOuuuy7tHLkcHT6fD/X19Wn55DIikQh+97vfGc+XuwwxxrQNOXKZdvdmty83EsXjcTDGUFpaiquuugrLly+3uj5xzq0O/KFQCMuXL0dlZSUtZTtOIKGcoJw5c8ZYF2kXloZCIfzTP/0TZs+ejQ0bNmD+/Pna5V7FOT6fD0uWLEmZRX3JkiW45ppr0q4pn3vkyBEcOnRIa7vX67Vm7hFCJLxKk/ir96VLE8Kou/f+/n5Eo1HrOowx1NfXIxQKpYxwEis6FhYWYtmyZVi2bJltP1JibECh9wTHJJZ2+RYsWIDNmzcjJyfHcWLfQCCABx54AGfOnMHmzZvBOccXvvAFaxVFu/HmJsrLy9OuG4lErEl/1aUhRNl23p1OPIXwdnd3WwIZjUatfIwx5OTkYGBgIKXBSVzH5/OhuroaJSUleO+993D27FlaOmKMQkI5Qfn444/x0UcfGftBmvZFmhA6N4TDYUybNg3f/OY3AaQvvaC7zpEjR9Df359WFmMMdXV11sJmskc6MDAAr9drCaWos9Rd03R91bOMRCLW6B/Rwi7K45zD4/FYdbayCMod3cPhMFatWoWWlhZLUE+ePOl6Cjpi9CGhnKC0traipaUFs2bNstJMdXa643a4EVDh4em8ys2bN+Nb3/pW2qTAAFBdXY36+npj+ByJROD1eq3w2Mkmu9bueDyOSCSSJoICWQxFyA18toyv3Ljk9XqtSZA556isrEQoFMLx48ddL75GjB4klBMYdVYdnZgMJjR3iyyWctrjjz+ubTH2er1YtWoVgsGglVf9xGIxRCIRa4im8CztbNY15IjJfdW1y+VGG1nkZVEW19PV8Yq8gUAAl1xyCWbNmoUjR46gp6cHp06d0s64Tow+JJQTmPPnzyMSiWi76Zi8SvnYYNHVF4ryotGocRy17LWZbJW9QNMytjp75HJEuC2H2nI4LpcnC6dAHWeue17inKKiIixZsgSxWAw9PT3o6enBwYMHcebMGRoJlEWQUE5g7rzzTjzzzDNp/Sl1LcN2DNab1O13dXWhsbERW7ZsSaujrK6uRl5entaLk8VOFkuBnVCK82KxmNW6rbZ+q963LMSy16quKW73gyPj8XiQl5eH/Px8lJaWIhqN4vTp09i6dStNwJEFUPegCUx7e7s1asZt/aOax87jNH10ecV2QUEBvve972HevHlp5Xq93pTGGvUjlylEb2BgAJFIBNFoNEUAVaLRKLq7uzEwMOAokoBeKMVH3hc2i4+cR+ST8zPG4PV6EQwGMW3aNFx66aVp66cTIw95lBMYzjn+8Ic/4JZbbrHGTot0t+cPpS3i++WXX07rQxkKhTB37lyjlyjXH8plRSKRlMYS07rhptUYTWGzHHI7ta7rQnH5mHw9dQmL2tpaAMCePXvQ3t4+pM+ccA/LhgdPa+aMHrm5uXjvvfdQWVmZdszkOeoaKDLB1BrNOcfhw4fx+c9/Pm1WonXr1qGhoSElv+yZqfs6T1O9N10ord6bvHKjzsuU901lyPds97zkultVWPv7+9HV1YWBgQG8++67tLDZ8LCDc54+/T8o9J7wRCIRbNu2zbi2tR0X2qCjnt/a2op77rknTSTD4TAqKiq0dYICnSCaQn5T+K9r4TbVLwo71LBaDcPVkFvOZxe+y+d4PB6EQiFMnjwZlZWVuPrqqzFnzhz3D5u4YEgoJzgDAwP4u7/7O3R1dTkKw1ChK7+/vx/33HMPXn311bRjs2bNwqRJk4yjbkz1lOLbbV2paptda7WTsJk+unPVjyyuOiEOh8OYO3duyrBQYnghoSTQ0tJinM5MoApJJvWYJvGVj/l8PnzjG9/QLmJWVlaW0qqsq6fUtYTL1zBtO4XCMvI1dA03pkYmneeoNvjoBNXklTLGkJ+fr23wIoYHEkoC8Xg8ZelZFZP3lSl2dZuMMVx00UWYNm1aSno4HEZNTY0lGDpBVIWosLDQmvpMrTc03aOukUcnbjovVs1jOi6n25WnO18XtldWViIcDg/qb0FkBrV6E1i2bBmuuOIK7TGnUHQwomk6R9f44vP5kJubmyYgaiNJTk4Opk+fjnnz5qGiogJerxddXV04deoUgsEg/vCHP6CrqwvNzc04cOAAKioqMG3aNOTm5qb1gVS35aGIuq5C8vhvWZTl1m5x33Yt3rr70z0fYU9BQQFmzpyJvXv3Gp81MTSQUE5wwuEw7r77bmtYoIkLbel2g1gLR6asrCzFk5SHBwKfzW159dVXW/WYgry8PGuFxrKyMvzkJz/Bpk2b0N3dDSAxsceSJUtwySWXaIc5ilnU5Xv3eDxp816KNBmT52sSSvme5O5GKnKjk5hI+NChQ+jt7dXmJ4YGCr0nOL29vbjrrru0E1DosGs9vhAYS0x4KyaOkK8hh93yJxAI4Oqrr8aNN96YJpIq27ZtwxNPPGGJJAB0dHQgFoulTNlm1xptF06bGm0y/ah1sU6fgoICrFy50pqfkxgeSCgJdHZ2agVQ1wii5hlKPB4PqqqqUtJOnDiBjz76KEWMAMDv92P+/PlYsGCB48iVtrY2/PCHP0xZWzwYDGLhwoVYvDjRbc5OBOVvXV7T+ab5MXVVDPIxJ8FV02fMmIHq6uqMnjWRGSSUhLFrzGjwla98JWVxrmg0infffTelQ3cgEMCGDRtw1VVX2XqRQGKY5je/+U0cPnzYSmOMYf78+diwYYOtyOrqEOVjTp6hzhtVz3fjfequp563ePFilJSUuHvIRMaQUBJoa2vD5s2bAWQ+IYYTTl1wZBhjqKmpwb333ptSZ9rW1mYtE8sYQ11dnXEJCvXamzZtsu4NSNQ7rlmzBpdddllKw4vpfJ2NJjGzOy4LnNw30o0H6STGjDFMnjwZjY2Nrp4zkTkklASi0Sh++ctfup5A1jSyxdRnMRMYY1izZg2eeOIJq0N1LBbDgQMHkJeXhyVLluDqq6+2XadHZtu2bSle48qVK7FgwYK0Or1MO5o7eX864dN5l5l6kqbjQKLl38nDJgYHtXoTAICLL77YlYdmSpO7t8hpdi+uKbQNBoNYvnw5SkpKwFhiEa/7778f9fX1CAaDVuOLrnzOE8vcPvvss/jGN76B73znO9i1axf27t0LxhJ9LJ3qNN2IjZvuPHJZuj6cuvvX/Q1kMdRN6iueQ1VVFRYsWIBDhw65bpwj3EFCOcERYdvSpUutbinixXfrndiF6m7LUcXG5/PhH//xH1FVVYUZM2ZYobhqm3q9++67D7/4xS/Q1dWFbdu2Yd++fThx4gTmzZuHuXPnoq6uLqUMu3vV5ZH7SMrXlz08Nc1JRE3nqdtAelck2Rafz4fly5fj4osvxuuvv25VVxAXDgnlBKexsRGrVq1Cb28vmpqaUlpPh7vfpIosFl6vF2vXrrXSVUxi+cc//hFnz54FADz//POoqKjAddddh4aGBvj9/rTO4eq2XJ5JyFSb1XPkcsUx+bpOz0DdlssRIbxanuqRX3TRRWhqahq1RrnxBgnlBKaoqAiLFy+Gz+dDZ2en49Kzg0EnDHYN/3gAACAASURBVGqa6k2p4akuvNZ5gm+//TZOnz5t7c+aNQtf/OIXEQwGUzxB3fWdvD/52pncm0iTR/eYruNGJAVCLNXO6aIedNKkSSgoKNCuPURkDjXmTFCmT5+Oa6+9FgUFBfB4POju7sbmzZutWYRGGlUkdOKl8/o452htbcWRI0fwwx/+EB999BGAz0RSHQutayRR953qVZ3EVpfXzUdno9oi7rbs3NxcrFixwngfRGaQRzkB8Xg8aGxsRHl5ecrL5/V6LWHR1dvZNVrY4bZBJ9Py4/E4HnjgATz66KPo7OxER0cH/H4/iouLcfXVV1v3ogqsnSjL2NWFyueK45k0XunS7Rp7dHaoXjVjLMXLnDx5MvLz89HZ2Wm0iXAHCeUEJDc3FxUVFWmz3RQVFQ26QUeH23PtQm8ZNT0Wi+HZZ59Fc3OzlTZ37lxcf/31xol91WvZeXMyurHcch51HXH1mHqvpuvobLa7BzX0FnZ5PB7k5uYiJyeHhHIIIKGcgBQUFGjDtYaGBiuPLJZyWqYMlVjqrt3a2oqOjg7rnIqKCqxYsSKtrlUVmEwaVAS6BhQ3giXb79Sg4yTYuh8wtd5V3neqRiDcQ0I5AWloaLCWfZVfSHks9HDhxoPSibRKW1sbHnzwQRw7dgx+vx8rVqzAqlWrrG5ETo0uTrbpOpyrXXPs6lDlbXGeXX6RbipDtcFUBonk8OAolIyxEIC3AAST+Z/hnP9PxlgdgN8AKAGwA8BXOecDjLEggMcBXAKgFcCfcc6PDZP9RIaEw2GUlpYCSH+pjh8/jmXLlll5nero7HDzkl7Ii/z73/8eP/vZz7BkyRIsW7YMRUVF1mgbU/2q+HbT19Mkmrr6TV0ncJOAmfLZebqmv4HOC5f/nh6Ph5a6HSLctHr3A7iSc94IYAGAqxhjywH8GMBPOOczAJwDcHsy/+0AziXTf5LMR2QBoVAIV111FWpqaqwXSf50dnbizJkzaecNthXcTnx02HWfEcdisRj27t2LRx55BDU1NVi7di3KyspSxobrqhVUO0zHdenyt6kV2q58+Vz5uGnCDKdnZlevqn5oEbKhwVEoeQIxHsqf/HAAVwJ4Jpn+GIAvJLc3JveRPL6GUQyQFdTX12PGjBnadVk8Hg/6+vqwc+dOR8Fywu2fW76GblvN19bWhkceeQTXX389WlpasGHDBuTk5KRc1614mT5qOaY0pxBXPFv1uPzcTddwI/DqdcQyESpTpkxBbm6u9pkQ7nFVR8kY8yIRXs8A8CCAIwDaOefRZJYmAGIiwSoAnwAA5zzKGDuPRHh+VinzDgB3XOgNEO4Q3oW62p/6svb09KC1tVU7ZVcmnqVOPJwaUkzi3NHRga1bt+LnP/853n77bdTU1ODmm29GYWGhY8ftwdgrh7E6+9VQWO5MrhNBU3gslys3BukahXQ/IE5CDSRmeZ8zZw62b9+e8TMhPsOVUHLOYwAWMMaKAPw/AA0Op7gp82EADwMAY4zGWQ0zCxYsQH19fcoyqOpaMYwxtLS04IMPPsDq1autc3Vi5GYEixuxtPNYOefo7OzEd7/7XWzatAkAUF1djZtuugmFhYUptrvBzh71B0NnjyqS8rbcrUonpibxla8pi6quLBnZe9RVHcj7lZWV8Pl8iEajIAZHRq3enPN2xtjrAFYAKGKM+ZJeZTUA0ZmtGUANgCbGmA9AIRKNOsQoMmfOHAQCAe3chzIlJSWoqqqyFUK3ImknljKyQMjHT548iVdffRXvvfceQqEQysvLccMNN2jXs3YjmCYPURzLxAtWPUXdt1yuqSVf/dHQCax6PdP96o57PB6Ul5cjEAiQUF4Ablq9SwFEkiIZBrAOiQaa1wHciETL960Ankuesim5/07y+Gt8sK0BxAWTk5OD1atXo7y8HD5f4s9t1xixePFiVFRUWCM8VEweoM5TtBNLU5kixOzr68PWrVvR3d2NpUuXora2FkVFRSmtuCaRsxMb3T3ocBI3J09R9TzdPAs5j2m6NVNVgyr6pu5DxOBw41FOAfBYsp7SA+ApzvnzjLH9AH7DGPsnALsAPJrM/yiA/8MYOwygDcAtw2A34ZJgMIglS5bA5/Npu48I4vE4CgsLUybLdVOfKG+rHo2dWKovstgXfQSPHj2K8+fPw+/3Y+nSpdouODI6oXS776ZMU7oqpiZRNu3L5Yh0Nz8udjaqz97j8aCkpATxeBx9fX2uyiVScRRKzvleAAs16UcBLNWk9wG4aUisIy4YIYjqaBXVo/T7/aiqqrK62YjVCd3UJ+peflUk3dRzxuNx9Pf3Y/v27Th+/HiKYKiz78j359SgobNNpJnCWTmPXXis8+ZM4bJqm+kZ6cTSKey2+2EKhUJYt24d9uzZgx07dmjtIeyhkTnjnL6+Ppw/fx7l5eUp6fKL5PV6sXjxYtTW1qa8kGr4bSd2bsNZOW9vby8++eQTy+spLy/Hjh070tb2Vu1Vr62rG3SLG69Rvp6cLo+4MTX66EJw9Rq6OtrB3Ivc8q6W6ff7UVdXZ3X/IjKDhHKc09vbi7Nnz2rXyxaEQqGUlQ8FsVjMdYOMnKarLxMvrwihI5EI/vjHP6YIZU5OTkpoaPK2ZOw8SicyPcckaKrnaxJT+TyTLU4iZvKC5WGN6jHGGPx+v+NSH4QZEspxDGMMl156KebMmaMNH71eL0pLSzFz5kyroUdGnQ3cTWu3fC5jDAMDA/iP//gPcM5x4403wu/34/Tp04hEImhubrauwTlHb29vmgdrEkmdh6bmsbNPxanO0C6f+mNgEnO7Bha7KgrTtXVlyHnlMvv6+qwJRIjMIaEcx4TDYaxduxZ+vz/lBa6qqkJpaSlCoRCKi4vh8/mMAiB7Q25fVBECihf06aefRnNzM372s59hw4YNWLlyJThPDEcU5erCVblMp8YQOW2wDSUmMTM9GwDa/pO6cNvJY3TzQ2RCV3crl8kYw/79+7F161YKuwcJCeU4Zs6cOcjJybG8NI/Hg9LSUkyfPh25ublpo3MEbrwbHapQAsCZM2fQ29sLACguLsbChQuNLzZgHiHjJJC6xhSdfbr70l3TDpPgmq6tE11dw5jb5+30g6W7H865Y88BwgwJ5TjC5/PB6/WioKAAs2bNwqxZsxAKhaz6q/LycsybN89qAXfympyQRcX0/c4776CtrQ05OTm46qqrEAqF0kRB51GavEAngTUJlZtWY3XbKQy2a6ARmEJ4XXm6ekbd9UxetpymerVUP3lhkFCOA/Lz83HJJZegoaEBVVVV8Pv9yMvLA5A6Hrm2tlYbIjqh88RMIilv9/b24qmnngIArFq1CrNmzXJVz2iHG49StV1nsy6vGztM5ZkEyu76uvtwK866Y6b745yjoaEBO3futLx7IjNIKMc406ZNw9e//nUUFxcbRScUCqGmpgb5+fkpdWu6+jSnVm6n0FEWywceeADvv/8+ACAQCNi+4E5epc4W+fxMcBMi24XpTt6pnM/tM5V/NExi6WSLfG/qvRQVFWHu3Lno6enBpEmTcPr0aRw9elR7HSIdEsoxzKRJk4wiyViiS0hpaSmmTJmCUChk5bEbmuhUh2f3Eqse5fvvv494PI6SkhLU19enCYaTyKmi7JTXTfWB6ZqmZ2IKbzOpmlDF32SX/C3ncRJOOWrQ2SjKXLZsGTo6Oqzle0ko3UNCOUZhLLEkaVFRkdYjq6urQ0FBAUKhkHbuQxMmr0UnQmr4LW8fOXIEH3zwAQBg3rx51qzqdvej8yZ1Ntvt68TV5NkNJvQWZdv9oKgi5aZBysljl6+rO89kh5wvHA4jFoshEolQ63eGkFCOMTweD6qqqnD55Zdj+vTp8Pl8aUJYWlqKkpKStBm1neom7UTS9OKqAgkAXV1d+PGPf4yOjg40NDRg+fLltveke7EvNJx2qlJwKl8Ng2VvUFeerq5STtMtLOZGrNRnK9unPn/Tj6Gc1+v1Wt2yCPeQUI4hvF4vrr32WqxatQo5OTlp9Y1Aoj6yqqpKG+JmKj5u68rkl5kxhjfeeANbtmxBZWUlGhsbtTNsq8It15mayjdhV0+oOz+T52Dy/pzqONXruwnXTfbKAi3ymQRULksVdSGU1AKeOSSUY4ja2lqsWbMmpe+jmDINSHQPKi8vN07qqmL3ktnlM9Wf7dmzB7/97W+xd+9e1NXVYePGjQiHw45CPdgQ2M05pqoD+Vgm11BFyilUVm2wazV3avFWn6GbulsVj8cDn8+HSCTi+hyChHJM4fV6rVE06icnJwdlZWUoKCiw8qv1fqqHI7ZlTPWDdo0LPT09uP/++7F9+3bs27cP1dXV+PKXv4xAIIB4PK5dckJu5dXZqmIKdVXc1OGp13NTjlyWyU5da7wccjtVY9jZmylO5VBDTmaQUI4hli9fnjIcMRAIoKysDF6vF+Fw2Ciibl56U7pOINWX8I033sBjjz1mpc+ZMydtmVQnr1EVH9Xb0qXL55rqJ3XnONVVuvV81WuYyndq/BHHRYdz9TnbeY7yvZtG3sjPTkQg+fn5OHfunDY/kQ4J5RihrKwMS5cutf7RCwoKrLWs5fBb4LZeMhMPRhVNzjneeust/P3f/711rKamBrNnz055udW1eUx26jw1t3WBgwmj3aSZ0nUibBJIN2WaxFRXtl2LuCm//Iw9Hg/q6+vR1NREwxpdQkI5RvD5fFZXn9zcXJSUlFghrRq+ZiqSdkJgSuec480338T3v/99tLe3A0gs/HXdddchLy9PG4aquBFJUzWAk9BdSAOOG3T1izoBl4XIJOaqB+zkpapppmoUNa885n/mzJlob2/HgQMHaNZzF1Dz1xihvb0dTzzxBLZt22Y12JhE0U4k1S4lapqbTzwet0Ty3Llz8Hq9mDZtGq677jrk5+en5NV5u6qNdnWTbu7P6YfBzQ+IqcrC9COkO19ni5NAu/nb2ZWRyY+kfMzv92PhwoVYu3btkP+IjEfIoxwj9PT04K233krruO3mRbYTTV0ep8YGzjl+9rOfWXVcS5YswYoVK1LW5ZHzqjh5SnaYwku392EqM1N73HpxJtEyPReTF22yVy5P93fXNdyJ63i9XoRCIQQCAfT39xvvgyCPMusR/9AAMHPmTPzFX/yFle72pTb1y1MbDuw8SPHd2dmJ1157zQq3c3NzMX/+fHi9Xm3DTyAQMN6X033bCb9O3DIROZOnqjuuppvuw025djYBqd29TD80bu5Ptyyx+gPGGENhYaHjqCmCPMqshjGG2267DUuWLMErr7yCVatWITc31zbsdOs92nURMnUF4pyjubkZf/M3f2ON7igrK0Nubm5Ky60cag9V52Ynz8ou7HYSG7khxK6cTGwT6fLHrnuQk61u7kO2RX026nIUYoTOUHVHGu+QUGYxtbW1uPbaa1FUVITZs2cbvRu7EE9GFQQ7gdSld3V1YevWrSkNFGLRMtlLkcVSFR83npYuj13XGhO6e3Qbytqhe4Zu7kXsq2nq32Uo6wzVHwDhbYoROvF4HOXl5Whqahqya45HSCizmOrqahQWFqakuRVFFSdvRs0rb3PO8d577+GBBx7A/v37U47v3r0btbW1qKysTLEpFoshGAw6CqM63Zt6r+q2k/C5EUeTUNnl05Wp+xHQ1Qe6xe3fx0058reuB4IYoROPx9MWniPSIaHMUnJycrB27dq0CnixLae5CbszeQnVbiqccxw6dAh79+5Ny1taWpoyHE6+hqifNDU0uPHu7ITHTaiq8/p0eZ2eoUl0TMj5ByuWTs/Crgzdc1M/smdJ2ENPKEv5+te/jksvvdT4Yjq92AI3jTVOn/7+frzyyitpZfv9fsycOTOlvks0+ng8nrTROZnYqztP/WRSrlN5chl2Hnum3rzpOqa/pSxwbp+FmuZ0L6pXWV5ejrq6Otf3NBEhocxCGGMoKyuzttVvO89Rt5+JKMot3OLzxBNPaL3Jqqoq5OXlIRqNoqWlJUUsxUTBpvvTbZvuwyQsQ8lghFaXphNyN+IqC6RutIzdj4TJLpMt6rR8wWAQkyZNsrVvokOhdxYyZcoUzJ8/39o31amZkMMtXV6dl6qKKgBLKF9//XVEo1HrHL/fD5/Ph7q6Ouuli8ViVku48FScWpEvRJzUsNtt3atdSHwhAmwScl3Vic5Wu4Y009/RZIPbHyi5wY0ac+whocxCvF6vtcaMzpO0eyHsuv3o8ukabuSQ+9e//jWam5utPLm5uZg3bx5CoZC1FC5jiZEeYo1r0X8vk7rBwWJXT6nLk2mdoVO5btJ0dtghWqOdfuTs6jLVHwQ1TRbJaDRKk/k6QEKZZfh8Pqxfvz5t5nIVO5F0299O99LJoV9TUxN+8YtfWN4kYwz19fVWX04hjkCilTsajcLr9SIYDKbYo7PbTfjoJGpO96o7nmn9orBDt6/Lr3qTsoeubqtlieOmZ+T272o6T6R7PB7EYjErrxwNEHpIKLOMdevW4YYbbtBOvuvkLZqEwW1YCiBlqq8TJ06k1JcVFRVh8uTJKS+c2Pb5fNb56sgSO09YFUO7agY3nrKJTMJs+XqZeKBOnp2pDlmHOGbXIm13PfnvrrNfiCWQmBVf/LgReqgxJ4vwer1obGxMeznkl8yuQt/kIZoabeSP3JDDOcf58+fx5JNPWkLp9/sxZ84ca8YiIZLyMDnhUQYCAaPHNFgG25ijNoLonp2ubDvP15Smu4YQLNMPm64s8Xdwc12TDW7skz80jNEeEsosgTGG66+/HkuWLLH27cRQJ4RyunrMqaVb/vT19eGf//mfsWvXLqusKVOmIC8vz7LL7/eniKbwUMTkwTpb3WISFlPeocJNtYCcV3xMVSTiuPo30l1DzmM3tNCug76djTqb5U9tba1jeRMZCr2zBMYY1q5di1AoZDwuUMNB9QV004ijpskv6S9/+Uv86U9/ssopLCzE9OnTU+wQy1KINOEFizWjVVvchrCZCN+FiqSTJ+mmkUjelj92omhCFVTTeboqAVU83Qqp6HSeiZc+ESGhzCLUOkiT4KiNNm5earsQWH5B29ra8F//9V/WtFs+nw/Tp09PEUAA1oxGskdlquuS7TUJiKmu0m39rF26EzrPSz2ulm8SJVWw1D6LTj9UTphEVPUa5XT5+au2iTplEkp7SCizAMYYLr744rRlXVVxkMVGzAbjxoPUpenC41gshvfffx+nT5+27GpoaEB5eXnaSybGcctCKWY213m8JoFwI5bDgS4cdXtNNyKpliNESS1H9/dRp6wTuPE01W1VJHViyTm3bTQiSCizgqlTp+IHP/gBcnJy0o6ZvErx7VRfZWppVT1M0YAgPMlgMIh58+ahtLTU1nuR68yEl6kTeJMtOgHVeUeZ3KMTTp6juu/kxdnZJ56R09o0agSRiXA5ecM6sZTPc/ofIjJozGGMeRljuxhjzyf36xhj7zLGDjPG/pMxFkimB5P7h5PHpw2P6eMDr9eL0tJSq25S9hidGmZEutxaLbdiOzXaqK3enHO88sor8Pl8WLFiBSorK1NWdpRRX7K8vDxrNI7ORievVxXw4fAsdYIy2LJ1HqmpbKcGGLdht93fQU3ThdOmc8W4fOoiZCYTf/suAB9K+z8G8BPO+QwA5wDcnky/HcC5ZPpPkvkIA2vWrMHf/u3f2tZbXYhgik8sFtN2B5I/LS0tAIC6ujpr5h9T3ZfX67VmngkEAtpqA939OGG63oWgithgwm2TjWqZpmu7EUn5b+pU3lDZJVq9Z8yYgT/7sz+z5hggUnEllIyxagCfB/BIcp8BuBLAM8ksjwH4QnJ7Y3IfyeNrGPn1WmprazFjxgyEw2ErTW2ssfPQdPuqB2nyJFXhjEajKCgowLx58zB79uyUJRx04iJP0ZWTk2OsbxP26bZN2ImYrurAqSy7Mk3i4qY8Ob/Jm3QSSfEt/82i0eigPUw3qH9Plqw2qaqqwg033ICGhgYsXbo043LHM27rKO8H8D8A5Cf3SwC0c87FTAlNAKqS21UAPgEAznmUMXY+mf/skFg8jjh37hzmzZunDTfV+iQTugYRga5eTCc0cv1kf39/Wt2cQBZJMXzRNK5brXPTiaXTS+5WBExiahd6mryswdjhJKy6lm/ZVvlZ9fX1oaenB8FgEOFw2LVNuh8BXUTidE5+fj7Wr1+Pnp4eHDp0yFpAbqLj6FEyxq4F0MI53zGUF2aM3cEY284Y2z6U5Y4liouLceLEiZQ00z+63UfnLQqP0c7T5DwxIUJfXx/6+vpw4MABa9EwYYvJ+xACKfpT6oTQThAGgy6c16F6Wm7q6nRlmMjE+xQf02gb9RkNDAykTIrhdH2747p9XTiuijmQaMxbuXIlKioqjPc3kXDjUa4EcD1j7BoAIQAFAP4dQBFjzJf0KqsBiClmmgHUAGhijPkAFAJoVQvlnD8M4GEAYIwN3fCKMcS5c+cwe/bslDT55TB5diLNKaSTt3Xi1dPTg61bt+Ljjz8GAO2SpbqXToSHwWAwZXJeudpAvb7JO1a9P91L7FYg7TCJSyahq53g2HmMbpGnqcvkXLs6SWGPyesWCHGWy6itrUVra6vVXWwi4yiUnPPvA/g+ADDGLgfw3znnX2GMPQ3gRgC/AXArgOeSp2xK7r+TPP4avxA3YhzT29uLo0ePori4GIDziyGOixfJzcupE8hYLIaTJ0/itddeQ1dXV1pZ8rfJhr6+PhQVFVmjc0x5nYTIbRjuVDfpRvAyFUk7j81U5ynvy/fv5CVynujHKncLUjuDu/VeVTtMVTPq+WqXJDdVPxOFC+ll+j0A32WMHUaiDvLRZPqjAEqS6d8FcPeFmTh+iUQi+OCDD7Qhsq7rjvintWuYEWG3GnoDn7WMnzx5Eps2bUJnZycAc4ht6mIijtkNfbNreFLzCNR1qE35nerdTB81T6aI+zaJl129od315OoQ2V5ddGH3g+b2x0Jnjyr8ok9sW1ubY5kTgYw6nHPO3wDwRnL7KIC0pjHOeR+Am4bAtgnB888/j4svvhiLFi2y9TZ0L7vaWCOLrJqf88SMQG+++SZaW1tTvBXhSZg6OYuXVrYvPz/fOmaHLvS2a2xRX2Q3Ho2Tp+U2n+6aJpGz8zZ1ZeierfqjKATKrZetK08XauvCbmGT+B+S00R+n8+H0tJSfPTRRxnZMR6hkTmjTCQSwe9//3ssXLgwRZB0L4lOME0NPADQ3d2Nl19+GQMDA+CcIxKJoLe3FwCsiYHFi2ESNFPYJjqi6+oPdaGnrgwZ+SV1KxAmMchE2ORrm44NJkRXn42pB4IcNQCpP1aq6JlCafX/RjeXqcleuW5SHJMn9rWrWplI0FPIAo4dO4bNmzdj3bp11j+mKlaqlyF3yREvSXNzs7U8Q3t7O/70pz+ho6Mj5Vw5bLabHkwVPBX5xbQTSx06j0etd9Wh85bUc+yEwc4LVMvQeXWZCrBclq66QE7TXUf3o2iyTc7jZI9clnwdubuXEO+pU6ciEAhgYGDAttzxDgllFnDu3Dk88sgjaG9vx0033aQVSxnGmHbq/qNHj2LPnj1pL4Batya/EKJ8U52Y2wYmXZrbOjMxyifTc9VyBoNaN2dXLeB0PV0e4TVGIpE0b11dF0cn2ALd30Y+pqu2sBN5+UdHzi/+FmL5j2PHjk14kQRo4t6sIRaLYdOmTTh37pwrcRIvWiwWQ2dnJ3bu3IkjR46kNeQAn80dKQ87VEXUri7OLvQT9rhBFl9ZkOQp29R7zKR8N9fWCYoun5uynMqXj4nnDpgbb9TJdO2qWESafE1dI5P69zMJquzRi0Y6zjk6Ojocn8dEgDzKLKKvrw9bt27Ftddeq60zlInH4+jt7cXBgwexf/9+K8RWXzohkrouRfK3is6Ltdt3i/qiipfSbRip83ydwmNTXtM5qjedSflqHvE38fv9iEQiKeXKdYFerzelrlDOp+6bIgaTONrdq+4ZezwenD59GocPH8b7779vvN+JBAllFsE5T2mRFmnyN5DwPo8fP44tW7akdfER27JQqh6knEdGiJCpddouNM0UO9FyW8/mlOb2XLd5VcF0ElJxj7pGOPm4QPbkgM88T905dt6hnVCa7lG1ZevWrTh69KjtuRMJEsos4+2338bixYuxc+dOrWDk5OQgEAigubkZ0WjU2Frr8Xjg8/lSlr3VvVAC+YUWL6fqWclpphDW1JCje3llT+hCBczkiZnuV1eOmu4khLoRNLpnYffs1bkq5WOiXPnvodri9Ld18iBNAkukQkKZZZw9exY/+tGPrDBNxuPxYObMmZgyZYpVr6dDzC0oN96YhEqHbrlZtX5MF/KZypbzyjY5rdWiEz/TtUxiZmeT+LYTdye7TOXLx9QfBvmZmgTcVO1gEjQ7z9IuhJe3hWh3dHTg008/1d77RIWEMgvRiSQA5OXloayszPblBoBAIGCNwda9WLJw6bqu6LwQ9YVzG/apgiq+RcOSyRNUcRtC2qXbCbrOe9aVpfPCnexTPUj5B0hOUzE9bzlNHTSg+xvo7DF1WWKMYWBgwBraSiQgoRxDyHWOgN6TCYfD8Pv9aV6MrixdmOimhZnzxJRsoVDINuyT92XvSRZJNwKlw02YqcurptltZ1qOLr8ubFYnoDDVQ9vdj6n+2SSoonz5byFsUK8/efJkVFVVoampyXhvEw0SyjFCKBTC1KlT07wRVTACgUCKkMr9JQWmBhu7DtGqd9PR0YG8vDxjx3W7EFEXrmfaxchuW5ffzpt06mEwWCE11ZUCqdUbaoTAObdaxFVkj1zXlUhng5wm/z11P1QDAwPo6OhAX1+f8T4nIiSUYwCPx4P6+noUFhYC0NfXeTwe5Obmwu/3pzUiqHlVATOJlJ2ARSIRdHR0WFUBdoKoCoAuvx12QuW0L9Ls8mXqRdqdY/rBkLd1IuXkPYpnJzxxedvkQarX111H/Rtv2bIFf/rTn0goFUgoxwAlhOJuWQAADFZJREFUJSXIz883voRer9dqDZfT1XpBgSq0prBbDQ1VhMfj9LIKdCNR7HAjUk7XdGOXqWw35WeKKTx2skfMKq9WW6gibCpDFUm1UY4xhmg0ikOHDpFIaiChHAPk5+cjLy8vRWiERxEMBq0WbkDvTejEQm1MEKh990xCKa4v26NeX2eD6k2ZxE33rR53k1d3jh2ZeKymHxYVXXgsfuDUBhXx/HXPSw211YhCtdH0oyT66ar1px999BFOnjzp4ilNPEgosxyv12utjCf+ocVwRNG6bffiuPFg5JdVreAXZaiiEAqFUFhYmBZOm0aPiDzyHJnyyy13m5Gvayek6r7dDEC6fVOfQrtzxLbqhTsJsahTFM/X1NKtiqN8b6pImn5w7H401B9I2Z7u7m7be5jIkFBmOR5PYjlY9aURYZhdH0nTuGEVIWByOaqXY2oAEtOEiWnX5DJ1H3G+LmR06x3K5+lERZfXLl0n0Lrz7Lxyu+uJfLIHLtLV/LpO6uLHUR48ID8DnW0qTtcCgIULF6KyshJ79uzBwYMHcfYsrQcoIKHMckpLS9OWjhUCqeuwLXtwpuGLOhEUyDOlq3nkj9w1CEjvbqTaI+cV11BbzHUCor7Ycj61fPWYaoeMXYu06Ry7MnWdx1XPU52xSf3WVUuI5yN+GN2Io+rd68RZPkd4lsFgEJWVlaioqMDUqVPx61//2vb+JxIklFlORUVFyuSpol5S7h4ikEXSNENQX18fYrEYfD6fNc9gf3+/NZWWPOO1QOdNxmIxoxDLqEIpQk6xPozupdfVd9o1ArkRSt0xnWio5bkpy+SRql1/xP0Dn9UTys9VnvFJfWbyxCbqcRX5uao/cKZnoHqp8qJxBAllVjNv3jyUl5dbwxVFyC3CXN2LIoui/GJu3boVZ8+eRXd3N6LRKGbPno38/HyrxVycaycmMtFoNGUOSZ1HJduk8yzluko3oa9apm5f5zmZ8stel84blDGJqhs7VRFyK8TiB0/2Jk1lyja6vQ/5uLrwmbxsMUFCmdUUFxcjGAyCMZbivZnCXFNFf29vL44fP56ymP327dvBGMPq1asB6OvrTCLp8XgwadKklPPkUFpF9WpFmjono5xf/tahempuxcspPdPz7PLJNgL64YtAep2v2BZdgXQht+6+7bxaYYv4yD0bxPVFCH727Fm89NJLru53okBCmaXk5eWhoKDAGmkj/7OrL4k6jyHwmUdy/vx5vPjii8YJWJ1eNlUsvV4vcnNzkZOToxU/tx6l+vKqQiB/mzpKm67pRtRUEdPdeyaoVRW68nT3KJ8jl2E3RFE3hFXnKao/eqoXrYplf38/duzYgU8//ZT6UiqQUGYpjY2NKCoqAqBvFBCY6p1E2gcffGAUSdUDdBIHn88Hv9+PWCyG7u5uFBUVpQmVaQy5jHpcDWvdCtZghM3phyCTstwi//2EAIoGLSB9xnfxrXYsl+uk7e5dFVBdVyZZNEW5u3fvxnPPPTek9z5eIKHMQjweD8LhsNb70L3Epi4l/f39OHz4sPE6DQ0NyM3NtcpVXybxLV4mUVcGwKoS0L2kdl6aKWxUcSOCbrvnuMHtsxbXdVuGKZ/6vNXj8lBFWSRN19Dt6zxKdVvOrxtbTiQgocxC8vLyMHnyZAD2XVdMLdOyCJleagApU2nZhYnAZ6GgXWu7yT433o+uLNXzVDGF6m7O1eWzK8fUmKO7R9N1dD9odvck94N140nqynFT5wwkFhHbtWuX7T1MZGhxsSykq6vLceJUtbsOkPpyAUBnZ6etl6B2gHbyXMSxUCiU1n1EDfPUsmTvSPeRGxpEeapoOgmLXT71HLVsk23qOabrO6GrXnD66BaDczpfd5+6bTmNc47f/e53OHHihKt7mYiQR5mFxONxDAwMOHorav2enDcajWLPnj3GSYABoLy83PZFUssUeeQO4yabhPioOL3cpu464phJrEy2m87R2aM7JttkV4Zst5t6T53HLturdjB38sRNNmXqWRJ6SCizGNULsdsXaYJDhw7hyJEjxrJDoZDVf9JUhmqLED91uKLOZpNwyddx640NZT434aouXb0vVRhNYqkKle5vpnq2YriiyUtWn61Tn1HTPck/qmIdb0IPCWWWcuLECUyZMsWaXxJwN8Gs8Pg+/PBDW88hFAohFAqlnesEY8xaN9yEnVfoBlN9oJ1H5MbDyvQcNa8bz1LddvqbyYiqCnmdc90Pjum5OnV3Uq8v9s+cOYPW1lZb2yY6VEeZpRw/fhxNTU0pHYR1obaMONbX1zcs/eBEGC93bRHIL6/coVl4SW6GOsr34TQSxqnOTmeX07lOmMpVr23XOg0gbaiiXKba2m0qWyeiuvx29yZsqK6uxoYNGxzvfyJDQpnFHDhwwBqDLYuH2vAhEPVcra2t1nrfJgbj7UUiEWuMcnd3N3p7ezEwMGC9wALZNnXJArupwmTUFn07ITIJrxsBdRIVU9jrdA2TN6j7m6kNXuoILPVbZ4NdY5R6T/IPmbBn6dKlVr9dIh0Syiymra0NTU1NKd6kyauUxwIfPHjQtly/34+GhgZHj0P3gvX394OxRPjd09OD7u5unD9/3loMSx1dIr/8pn31GqZ7NXlW8jE1r+mYWp7dfeuei5M469C16It78Xq9KVPn6fpR6u7dTa8Cnc3qs83JyUmZfIVIhWVDCxhjrBOA/dudnUwGMNYm7SObR46xaPdEtnkq57xUdyBbfkIOcs4Xj7YRmcIY2z7W7CabR46xaDfZrIdCb4IgCAdIKAmCIBzIFqF8eLQNGCRj0W6yeeQYi3aTzRqyojGHIAgim8kWj5IgCCJrGXWhZIxdxRg7yBg7zBi7e7TtETDGfsUYa2GM7ZPSihljrzDGDiW/JyXTGWPsgeQ97GWMLRolm2sYY68zxvYzxj5gjN01RuwOMca2Mcb2JO3+UTK9jjH2btK+/2SMBZLpweT+4eTxaaNhd9IWL2NsF2Ps+bFgM2PsGGPsfcbYbsbY9mRatv9/FDHGnmGMHWCMfcgYWzHiNus6+I7UB4AXwBEA9QACAPYAmDuaNkm2XQZgEYB9Utp9AO5Obt8N4MfJ7WsA/AEAA7AcwLujZPMUAIuS2/kAPgIwdwzYzQDkJbf9AN5N2vMUgFuS6T8HcGdy+1sAfp7cvgXAf47i/8l3AfwawPPJ/ay2GcAxAJOVtGz//3gMwF8mtwMAikba5lH555IewAoAL0n73wfw/dG0SbFvmiKUBwFMSW5PQaL/JwD8AsCf6/KNsv3PAVg3luwGkANgJ4BlSHQi9qn/KwBeArAiue1L5mOjYGs1gFcBXAng+eTLme0264Qya/8/ABQC+Fh9ViNt82iH3lUAPpH2m5Jp2Uo55/xUcvs0gPLkdtbdRzK0W4iEd5b1didD2N0AWgC8gkSk0c45F/N/ybZZdiePnwdQMrIWAwDuB/A/AIgZQkqQ/TZzAC8zxnYwxu5IpmXz/0cdgE8B/O9kFccjjLFcjLDNoy2UYxae+LnKyi4DjLE8AL8F8B3OecrKYtlqN+c8xjlfgISXthRAwyibZAtj7FoALZzzHaNtS4as4pwvAnA1gG8zxi6TD2bh/4cPiSqwhzjnCwF0IxFqW4yEzaMtlM0AaqT96mRatnKGMTYFAJLfLcn0rLkPxpgfCZH8v5zz3yWTs95uAee8HcDrSIStRYwxMcxWts2yO3m8EMBIT6i4EsD1jLFjAH6DRPj978hum8E5b05+twD4f0j8KGXz/0cTgCbO+bvJ/WeQEM4RtXm0hfI9ADOTLYUBJCq5N42yTXZsAnBrcvtWJOoARfrXki1uywGcl8KCEYMxxgA8CuBDzvn/kg5lu92ljLGi5HYYiXrVD5EQzBuT2VS7xf3cCOC1pFcxYnDOv885r+acT0Pi//Y1zvlXkMU2M8ZyGWP5YhvAegD7kMX/H5zz0wA+YYzNTiatAbB/xG0e6cpkTWXtNUi0zh4B8MPRtkey60kApwBEkPhVux2JOqVXARwC8F8AipN5GYAHk/fwPoDFo2TzKiRCkL0Adic/14wBu+cD2JW0ex+Av0um1wPYBuAwgKcBBJPpoeT+4eTx+lH+X7kcn7V6Z63NSdv2JD8fiPdtDPx/LACwPfn/8SyASSNtM43MIQiCcGC0Q2+CIIish4SSIAjCARJKgiAIB0goCYIgHCChJAiCcICEkiAIwgESSoIgCAdIKAmCIBz4/+/aOIAaRVSwAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"y4yfu6aZnY4r","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":123},"executionInfo":{"status":"ok","timestamp":1599568633973,"user_tz":-60,"elapsed":5180,"user":{"displayName":"Hazem Barka","photoUrl":"","userId":"05856545852072919715"}},"outputId":"d363f37c-6462-4c59-f80f-700d7fcc6953"},"source":["%cd /root/models/\n","!git clone https://github.com/fllay/totoro.git #Import Totoro and Nekobus data from Github"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/root/models\n","Cloning into 'totoro'...\n","remote: Enumerating objects: 823, done.\u001b[K\n","remote: Total 823 (delta 0), reused 0 (delta 0), pack-reused 823\u001b[K\n","Receiving objects: 100% (823/823), 63.31 MiB | 42.29 MiB/s, done.\n","Resolving deltas: 100% (407/407), done.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"n2AznC4usiGw","colab_type":"text"},"source":["!!! we need to modify /root/models/totoro/tfrecord/generate_tfrecord.py and change classes"]},{"cell_type":"code","metadata":{"id":"82CZv-8kfQDB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":676},"executionInfo":{"status":"ok","timestamp":1599568672323,"user_tz":-60,"elapsed":14876,"user":{"displayName":"Hazem Barka","photoUrl":"","userId":"05856545852072919715"}},"outputId":"77e691e9-f2b6-48b1-fa48-13c6d5c958b5"},"source":["%cd /root/models/totoro/tfrecord\n","!python generate_tfrecord.py --csv_input='/root/drive/My Drive/RGB-D Hand detector/CSV_TFRecords_test.csv'  --output_path=test.record --image_dir=/root/dataset/test"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/root/models/totoro/tfrecord\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","WARNING:tensorflow:From generate_tfrecord.py:101: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n","\n","WARNING:tensorflow:From generate_tfrecord.py:87: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n","W0908 12:37:37.297093 140398704158592 deprecation_wrapper.py:119] From generate_tfrecord.py:87: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n","WARNING:tensorflow:From generate_tfrecord.py:46: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W0908 12:37:41.439275 140398704158592 deprecation_wrapper.py:119] From generate_tfrecord.py:46: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","Successfully created the TFRecords: /root/models/totoro/tfrecord/test.record\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dljdjj7smy3h","colab_type":"code","colab":{}},"source":["%cd /root/models/totoro/tfrecord\n","!python generate_tfrecord.py --csv_input='/root/drive/My Drive/RGB-D Hand detector/CSV_TFRecords_train.csv'  --output_path=train.record --image_dir=/root/dataset/train"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g4um-v7-gJH0","colab_type":"text"},"source":["## Downloading the model :"]},{"cell_type":"code","metadata":{"id":"x1Ozj-H8gIzz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1599578774890,"user_tz":-60,"elapsed":7785,"user":{"displayName":"Hazem Barka","photoUrl":"","userId":"05856545852072919715"}},"outputId":"a293d882-70d9-47d7-df6f-e85b54d8b814"},"source":["\n","%cd ~/models\n","\n","import os\n","import shutil\n","import glob\n","import urllib\n","import tarfile\n","from requests import get\n","\n","MODEL = 'ssd_mobilenet_v2_coco_2018_03_29'\n","MODEL_FILE = MODEL + '.tar.gz'\n","DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n","DEST_DIR = 'pretrained_model'\n","\n","if not (os.path.exists(MODEL_FILE)):\n","  with open(MODEL_FILE, \"wb\") as file:\n","    # get request\n","    response = get(DOWNLOAD_BASE + MODEL_FILE)\n","    # write to file\n","    file.write(response.content)\n","    #opener = urllib.URLopener()\n","    #opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n","\n","tar = tarfile.open(MODEL_FILE)\n","tar.extractall()\n","tar.close()\n","\n","os.remove(MODEL_FILE)\n","if (os.path.exists(DEST_DIR)):\n","  shutil.rmtree(DEST_DIR)\n","os.rename(MODEL, DEST_DIR)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/root/models\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EXiPwM-QiFio","colab_type":"text"},"source":["## Model Config :"]},{"cell_type":"code","metadata":{"id":"0Y2ZrvmRgQBT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1599578803580,"user_tz":-60,"elapsed":899,"user":{"displayName":"Hazem Barka","photoUrl":"","userId":"05856545852072919715"}},"outputId":"a9b69b98-81b8-408a-d797-217745eaa710"},"source":["\n","%cd /root/models/research/\n","!protoc object_detection/protos/*.proto --python_out=.\n","#!export PYTHONPATH=$PYTHONPATH: /usr/local/lib/python3.6/dist-packages/tensorflow/models/research/:/usr/local/lib/python3.6/dist-packages/tensorflow/models/research/slim\n","#!pwd\n","#!python /usr/local/lib/python3.6/dist-packages/tensorflow/models/research/object_detection/builders/model_builder_test.py\n","#!python setup.py build\n","import os\n","os.environ['PYTHONPATH'] += ':/root/models/research/:/root/models/research/slim/:/root/models/research/object_detection/utils/:/root/models/research/object_detection'\n","\n","# Edit Pipeline \n","import tensorflow as tf\n","from google.protobuf import text_format\n","from object_detection.protos import pipeline_pb2\n","\n","pipeline = pipeline_pb2.TrainEvalPipelineConfig()                                                                                                                                                                                                          \n","config_path = '/root/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config'\n","with tf.gfile.GFile( config_path, \"r\") as f:                                                                                                                                                                                                                     \n","    proto_str = f.read()                                                                                                                                                                                                                                          \n","    text_format.Merge(proto_str, pipeline)\n","\n","pipeline.train_input_reader.tf_record_input_reader.input_path[:] = ['/root/models/totoro/tfrecord/test.record'] \n","pipeline.train_input_reader.label_map_path = '/root/drive/My Drive/RGB-D Hand detector/inference_graph_hand_RGBD/hand_label_map_RGBD.pbtxt' \n","pipeline.eval_input_reader[0].tf_record_input_reader.input_path[:] = ['/root/models/totoro/tfrecord/test.record'] \n","pipeline.eval_input_reader[0].label_map_path = '/root/drive/My Drive/RGB-D Hand detector/inference_graph_hand_RGBD/hand_label_map_RGBD.pbtxt' \n","pipeline.train_config.fine_tune_checkpoint = '/root/models/pretrained_model/model.ckpt'\n","pipeline.train_config.num_steps = 5000\n","pipeline.model.ssd.num_classes = 1\n","pipeline.eval_config.num_examples = 16\n","\n","config_text = text_format.MessageToString(pipeline)                                                                                                                                                                                                        \n","with tf.gfile.Open( config_path, \"wb\") as f:                                                                                                                                                                                                                       \n","    f.write(config_text)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/root/models/research\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lG9bjSqbiHLs","colab_type":"text"},"source":["## training :"]},{"cell_type":"code","metadata":{"id":"WD6YGGYWiIzR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1599582726585,"user_tz":-60,"elapsed":1493264,"user":{"displayName":"Hazem Barka","photoUrl":"","userId":"05856545852072919715"}},"outputId":"c5b71044-ab6f-48c6-fa79-7dff71d0bf4a"},"source":["# Compile protobuf and change Python path\n","%cd /root/models/research/\n","!protoc object_detection/protos/*.proto --python_out=.\n","import os\n","os.environ['PYTHONPATH'] += ':/root/models/research/:/root/models/research/slim/:/root/models/research/object_detection/utils/:/root/models/research/object_detection'\n","\n","# Begin training\n","!python /root/models/research/object_detection/legacy/train.py \\\n","    --logtostderr \\\n","    --train_dir=/root/models/trained_v2 \\\n","    --pipeline_config_path=/root/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[1;30;43mLe flux de sortie a été tronqué et ne contient que les 5000 dernières lignes.\u001b[0m\n","I0908 16:00:25.084162 140650862335872 learning.py:512] global step 2526: loss = 2.3328 (0.762 sec/step)\n","INFO:tensorflow:global step 2527: loss = 2.1726 (0.758 sec/step)\n","I0908 16:00:25.843820 140650862335872 learning.py:512] global step 2527: loss = 2.1726 (0.758 sec/step)\n","INFO:tensorflow:global step 2528: loss = 2.1400 (0.768 sec/step)\n","I0908 16:00:26.613733 140650862335872 learning.py:512] global step 2528: loss = 2.1400 (0.768 sec/step)\n","INFO:tensorflow:global step 2529: loss = 2.1405 (0.764 sec/step)\n","I0908 16:00:27.379441 140650862335872 learning.py:512] global step 2529: loss = 2.1405 (0.764 sec/step)\n","INFO:tensorflow:global step 2530: loss = 2.1523 (0.775 sec/step)\n","I0908 16:00:28.155827 140650862335872 learning.py:512] global step 2530: loss = 2.1523 (0.775 sec/step)\n","INFO:tensorflow:global step 2531: loss = 2.3720 (0.760 sec/step)\n","I0908 16:00:28.917235 140650862335872 learning.py:512] global step 2531: loss = 2.3720 (0.760 sec/step)\n","INFO:tensorflow:global step 2532: loss = 2.2509 (0.749 sec/step)\n","I0908 16:00:29.667427 140650862335872 learning.py:512] global step 2532: loss = 2.2509 (0.749 sec/step)\n","INFO:tensorflow:global step 2533: loss = 2.2387 (0.759 sec/step)\n","I0908 16:00:30.427813 140650862335872 learning.py:512] global step 2533: loss = 2.2387 (0.759 sec/step)\n","INFO:tensorflow:global step 2534: loss = 2.5324 (0.773 sec/step)\n","I0908 16:00:31.202755 140650862335872 learning.py:512] global step 2534: loss = 2.5324 (0.773 sec/step)\n","INFO:tensorflow:global step 2535: loss = 1.7578 (0.775 sec/step)\n","I0908 16:00:31.979497 140650862335872 learning.py:512] global step 2535: loss = 1.7578 (0.775 sec/step)\n","INFO:tensorflow:global step 2536: loss = 2.0135 (0.770 sec/step)\n","I0908 16:00:32.751196 140650862335872 learning.py:512] global step 2536: loss = 2.0135 (0.770 sec/step)\n","INFO:tensorflow:global step 2537: loss = 2.2765 (0.765 sec/step)\n","I0908 16:00:33.517894 140650862335872 learning.py:512] global step 2537: loss = 2.2765 (0.765 sec/step)\n","INFO:tensorflow:global step 2538: loss = 2.5467 (0.771 sec/step)\n","I0908 16:00:34.290362 140650862335872 learning.py:512] global step 2538: loss = 2.5467 (0.771 sec/step)\n","INFO:tensorflow:global step 2539: loss = 2.1305 (0.746 sec/step)\n","I0908 16:00:35.037659 140650862335872 learning.py:512] global step 2539: loss = 2.1305 (0.746 sec/step)\n","INFO:tensorflow:global step 2540: loss = 2.0694 (0.757 sec/step)\n","I0908 16:00:35.796783 140650862335872 learning.py:512] global step 2540: loss = 2.0694 (0.757 sec/step)\n","INFO:tensorflow:global step 2541: loss = 2.1531 (0.761 sec/step)\n","I0908 16:00:36.559310 140650862335872 learning.py:512] global step 2541: loss = 2.1531 (0.761 sec/step)\n","INFO:tensorflow:global step 2542: loss = 1.9124 (0.767 sec/step)\n","I0908 16:00:37.328431 140650862335872 learning.py:512] global step 2542: loss = 1.9124 (0.767 sec/step)\n","INFO:tensorflow:global step 2543: loss = 2.1868 (0.768 sec/step)\n","I0908 16:00:38.097496 140650862335872 learning.py:512] global step 2543: loss = 2.1868 (0.768 sec/step)\n","INFO:tensorflow:global step 2544: loss = 2.0759 (0.754 sec/step)\n","I0908 16:00:38.852851 140650862335872 learning.py:512] global step 2544: loss = 2.0759 (0.754 sec/step)\n","INFO:tensorflow:global step 2545: loss = 2.4830 (0.750 sec/step)\n","I0908 16:00:39.604414 140650862335872 learning.py:512] global step 2545: loss = 2.4830 (0.750 sec/step)\n","INFO:tensorflow:global step 2546: loss = 2.2247 (0.768 sec/step)\n","I0908 16:00:40.374267 140650862335872 learning.py:512] global step 2546: loss = 2.2247 (0.768 sec/step)\n","INFO:tensorflow:global step 2547: loss = 1.9789 (0.768 sec/step)\n","I0908 16:00:41.144039 140650862335872 learning.py:512] global step 2547: loss = 1.9789 (0.768 sec/step)\n","INFO:tensorflow:global step 2548: loss = 1.8628 (0.753 sec/step)\n","I0908 16:00:41.898206 140650862335872 learning.py:512] global step 2548: loss = 1.8628 (0.753 sec/step)\n","INFO:tensorflow:global step 2549: loss = 2.5518 (0.764 sec/step)\n","I0908 16:00:42.663933 140650862335872 learning.py:512] global step 2549: loss = 2.5518 (0.764 sec/step)\n","INFO:tensorflow:global step 2550: loss = 2.0261 (0.768 sec/step)\n","I0908 16:00:43.434110 140650862335872 learning.py:512] global step 2550: loss = 2.0261 (0.768 sec/step)\n","INFO:tensorflow:global step 2551: loss = 2.3446 (0.761 sec/step)\n","I0908 16:00:44.197196 140650862335872 learning.py:512] global step 2551: loss = 2.3446 (0.761 sec/step)\n","INFO:tensorflow:global step 2552: loss = 2.0501 (0.765 sec/step)\n","I0908 16:00:44.964339 140650862335872 learning.py:512] global step 2552: loss = 2.0501 (0.765 sec/step)\n","INFO:tensorflow:global step 2553: loss = 1.9366 (0.760 sec/step)\n","I0908 16:00:45.725982 140650862335872 learning.py:512] global step 2553: loss = 1.9366 (0.760 sec/step)\n","INFO:tensorflow:global step 2554: loss = 2.5178 (0.755 sec/step)\n","I0908 16:00:46.482968 140650862335872 learning.py:512] global step 2554: loss = 2.5178 (0.755 sec/step)\n","INFO:tensorflow:global step 2555: loss = 2.2619 (0.757 sec/step)\n","I0908 16:00:47.241255 140650862335872 learning.py:512] global step 2555: loss = 2.2619 (0.757 sec/step)\n","INFO:tensorflow:global step 2556: loss = 2.0413 (0.743 sec/step)\n","I0908 16:00:47.986455 140650862335872 learning.py:512] global step 2556: loss = 2.0413 (0.743 sec/step)\n","INFO:tensorflow:global step 2557: loss = 2.4299 (0.760 sec/step)\n","I0908 16:00:48.748005 140650862335872 learning.py:512] global step 2557: loss = 2.4299 (0.760 sec/step)\n","INFO:tensorflow:global step 2558: loss = 1.9949 (0.762 sec/step)\n","I0908 16:00:49.511343 140650862335872 learning.py:512] global step 2558: loss = 1.9949 (0.762 sec/step)\n","INFO:tensorflow:global step 2559: loss = 2.3747 (0.776 sec/step)\n","I0908 16:00:50.289996 140650862335872 learning.py:512] global step 2559: loss = 2.3747 (0.776 sec/step)\n","INFO:tensorflow:global step 2560: loss = 2.8030 (0.737 sec/step)\n","I0908 16:00:51.029074 140650862335872 learning.py:512] global step 2560: loss = 2.8030 (0.737 sec/step)\n","INFO:tensorflow:global step 2561: loss = 1.8681 (0.734 sec/step)\n","I0908 16:00:51.765204 140650862335872 learning.py:512] global step 2561: loss = 1.8681 (0.734 sec/step)\n","INFO:tensorflow:global step 2562: loss = 2.1455 (0.778 sec/step)\n","I0908 16:00:52.544683 140650862335872 learning.py:512] global step 2562: loss = 2.1455 (0.778 sec/step)\n","INFO:tensorflow:global step 2563: loss = 1.9664 (0.769 sec/step)\n","I0908 16:00:53.315567 140650862335872 learning.py:512] global step 2563: loss = 1.9664 (0.769 sec/step)\n","INFO:tensorflow:global step 2564: loss = 1.9604 (0.769 sec/step)\n","I0908 16:00:54.085890 140650862335872 learning.py:512] global step 2564: loss = 1.9604 (0.769 sec/step)\n","INFO:tensorflow:global step 2565: loss = 2.2600 (0.786 sec/step)\n","I0908 16:00:54.873315 140650862335872 learning.py:512] global step 2565: loss = 2.2600 (0.786 sec/step)\n","INFO:tensorflow:global step 2566: loss = 2.7689 (0.759 sec/step)\n","I0908 16:00:55.633817 140650862335872 learning.py:512] global step 2566: loss = 2.7689 (0.759 sec/step)\n","INFO:tensorflow:global step 2567: loss = 2.0210 (0.759 sec/step)\n","I0908 16:00:56.395032 140650862335872 learning.py:512] global step 2567: loss = 2.0210 (0.759 sec/step)\n","INFO:tensorflow:global step 2568: loss = 2.3584 (0.766 sec/step)\n","I0908 16:00:57.163326 140650862335872 learning.py:512] global step 2568: loss = 2.3584 (0.766 sec/step)\n","INFO:tensorflow:global step 2569: loss = 2.8009 (0.772 sec/step)\n","I0908 16:00:57.936856 140650862335872 learning.py:512] global step 2569: loss = 2.8009 (0.772 sec/step)\n","INFO:tensorflow:global step 2570: loss = 2.2668 (0.762 sec/step)\n","I0908 16:00:58.700524 140650862335872 learning.py:512] global step 2570: loss = 2.2668 (0.762 sec/step)\n","INFO:tensorflow:global step 2571: loss = 2.0127 (0.738 sec/step)\n","I0908 16:00:59.440636 140650862335872 learning.py:512] global step 2571: loss = 2.0127 (0.738 sec/step)\n","INFO:tensorflow:global step 2572: loss = 2.9628 (0.747 sec/step)\n","I0908 16:01:00.189262 140650862335872 learning.py:512] global step 2572: loss = 2.9628 (0.747 sec/step)\n","INFO:tensorflow:global step 2573: loss = 2.9344 (0.774 sec/step)\n","I0908 16:01:00.965103 140650862335872 learning.py:512] global step 2573: loss = 2.9344 (0.774 sec/step)\n","INFO:tensorflow:global step 2574: loss = 2.6672 (0.756 sec/step)\n","I0908 16:01:01.722482 140650862335872 learning.py:512] global step 2574: loss = 2.6672 (0.756 sec/step)\n","INFO:tensorflow:global step 2575: loss = 2.5454 (0.756 sec/step)\n","I0908 16:01:02.480647 140650862335872 learning.py:512] global step 2575: loss = 2.5454 (0.756 sec/step)\n","INFO:tensorflow:global step 2576: loss = 2.4242 (0.766 sec/step)\n","I0908 16:01:03.248027 140650862335872 learning.py:512] global step 2576: loss = 2.4242 (0.766 sec/step)\n","INFO:tensorflow:global step 2577: loss = 2.2520 (0.754 sec/step)\n","I0908 16:01:04.003453 140650862335872 learning.py:512] global step 2577: loss = 2.2520 (0.754 sec/step)\n","INFO:tensorflow:global step 2578: loss = 2.5001 (0.760 sec/step)\n","I0908 16:01:04.765335 140650862335872 learning.py:512] global step 2578: loss = 2.5001 (0.760 sec/step)\n","INFO:tensorflow:global step 2579: loss = 1.9362 (0.768 sec/step)\n","I0908 16:01:05.535319 140650862335872 learning.py:512] global step 2579: loss = 1.9362 (0.768 sec/step)\n","INFO:tensorflow:global step 2580: loss = 2.0395 (0.759 sec/step)\n","I0908 16:01:06.295853 140650862335872 learning.py:512] global step 2580: loss = 2.0395 (0.759 sec/step)\n","INFO:tensorflow:global step 2581: loss = 2.3414 (0.762 sec/step)\n","I0908 16:01:07.059284 140650862335872 learning.py:512] global step 2581: loss = 2.3414 (0.762 sec/step)\n","INFO:tensorflow:global step 2582: loss = 2.6499 (0.752 sec/step)\n","I0908 16:01:07.813273 140650862335872 learning.py:512] global step 2582: loss = 2.6499 (0.752 sec/step)\n","INFO:tensorflow:global step 2583: loss = 2.0777 (0.770 sec/step)\n","I0908 16:01:08.584522 140650862335872 learning.py:512] global step 2583: loss = 2.0777 (0.770 sec/step)\n","INFO:tensorflow:global step 2584: loss = 2.4182 (0.758 sec/step)\n","I0908 16:01:09.344004 140650862335872 learning.py:512] global step 2584: loss = 2.4182 (0.758 sec/step)\n","INFO:tensorflow:global step 2585: loss = 2.4948 (0.761 sec/step)\n","I0908 16:01:10.106936 140650862335872 learning.py:512] global step 2585: loss = 2.4948 (0.761 sec/step)\n","INFO:tensorflow:global step 2586: loss = 2.5139 (0.757 sec/step)\n","I0908 16:01:10.864982 140650862335872 learning.py:512] global step 2586: loss = 2.5139 (0.757 sec/step)\n","INFO:tensorflow:global step 2587: loss = 2.5442 (0.761 sec/step)\n","I0908 16:01:11.627450 140650862335872 learning.py:512] global step 2587: loss = 2.5442 (0.761 sec/step)\n","INFO:tensorflow:global step 2588: loss = 2.1862 (0.743 sec/step)\n","I0908 16:01:12.372201 140650862335872 learning.py:512] global step 2588: loss = 2.1862 (0.743 sec/step)\n","INFO:tensorflow:global step 2589: loss = 2.2895 (0.742 sec/step)\n","I0908 16:01:13.116162 140650862335872 learning.py:512] global step 2589: loss = 2.2895 (0.742 sec/step)\n","INFO:tensorflow:global step 2590: loss = 1.9237 (0.763 sec/step)\n","I0908 16:01:13.880491 140650862335872 learning.py:512] global step 2590: loss = 1.9237 (0.763 sec/step)\n","INFO:tensorflow:global step 2591: loss = 2.0318 (0.767 sec/step)\n","I0908 16:01:14.649493 140650862335872 learning.py:512] global step 2591: loss = 2.0318 (0.767 sec/step)\n","INFO:tensorflow:global step 2592: loss = 2.2315 (0.770 sec/step)\n","I0908 16:01:15.421479 140650862335872 learning.py:512] global step 2592: loss = 2.2315 (0.770 sec/step)\n","INFO:tensorflow:global step 2593: loss = 2.0177 (0.761 sec/step)\n","I0908 16:01:16.184329 140650862335872 learning.py:512] global step 2593: loss = 2.0177 (0.761 sec/step)\n","INFO:tensorflow:global step 2594: loss = 1.9887 (0.756 sec/step)\n","I0908 16:01:16.942263 140650862335872 learning.py:512] global step 2594: loss = 1.9887 (0.756 sec/step)\n","INFO:tensorflow:global step 2595: loss = 2.6178 (0.755 sec/step)\n","I0908 16:01:17.699133 140650862335872 learning.py:512] global step 2595: loss = 2.6178 (0.755 sec/step)\n","INFO:tensorflow:global step 2596: loss = 2.1167 (0.762 sec/step)\n","I0908 16:01:18.463293 140650862335872 learning.py:512] global step 2596: loss = 2.1167 (0.762 sec/step)\n","INFO:tensorflow:global step 2597: loss = 2.2298 (0.764 sec/step)\n","I0908 16:01:19.228774 140650862335872 learning.py:512] global step 2597: loss = 2.2298 (0.764 sec/step)\n","INFO:tensorflow:global step 2598: loss = 2.4641 (0.748 sec/step)\n","I0908 16:01:19.978810 140650862335872 learning.py:512] global step 2598: loss = 2.4641 (0.748 sec/step)\n","INFO:tensorflow:global step 2599: loss = 2.8349 (0.775 sec/step)\n","I0908 16:01:20.755498 140650862335872 learning.py:512] global step 2599: loss = 2.8349 (0.775 sec/step)\n","INFO:tensorflow:global step 2600: loss = 2.1203 (0.759 sec/step)\n","I0908 16:01:21.516552 140650862335872 learning.py:512] global step 2600: loss = 2.1203 (0.759 sec/step)\n","INFO:tensorflow:global step 2601: loss = 2.1156 (0.770 sec/step)\n","I0908 16:01:22.287689 140650862335872 learning.py:512] global step 2601: loss = 2.1156 (0.770 sec/step)\n","INFO:tensorflow:global step 2602: loss = 2.0106 (0.770 sec/step)\n","I0908 16:01:23.059169 140650862335872 learning.py:512] global step 2602: loss = 2.0106 (0.770 sec/step)\n","INFO:tensorflow:global step 2603: loss = 2.5097 (0.757 sec/step)\n","I0908 16:01:23.817331 140650862335872 learning.py:512] global step 2603: loss = 2.5097 (0.757 sec/step)\n","INFO:tensorflow:global step 2604: loss = 1.9999 (0.738 sec/step)\n","I0908 16:01:24.556994 140650862335872 learning.py:512] global step 2604: loss = 1.9999 (0.738 sec/step)\n","INFO:tensorflow:global step 2605: loss = 2.1007 (0.771 sec/step)\n","I0908 16:01:25.329660 140650862335872 learning.py:512] global step 2605: loss = 2.1007 (0.771 sec/step)\n","INFO:tensorflow:global step 2606: loss = 2.7368 (0.771 sec/step)\n","I0908 16:01:26.101881 140650862335872 learning.py:512] global step 2606: loss = 2.7368 (0.771 sec/step)\n","INFO:tensorflow:global step 2607: loss = 2.0472 (0.777 sec/step)\n","I0908 16:01:26.880698 140650862335872 learning.py:512] global step 2607: loss = 2.0472 (0.777 sec/step)\n","INFO:tensorflow:global step 2608: loss = 2.3074 (0.762 sec/step)\n","I0908 16:01:27.644774 140650862335872 learning.py:512] global step 2608: loss = 2.3074 (0.762 sec/step)\n","INFO:tensorflow:global step 2609: loss = 2.1424 (0.748 sec/step)\n","I0908 16:01:28.394917 140650862335872 learning.py:512] global step 2609: loss = 2.1424 (0.748 sec/step)\n","INFO:tensorflow:global step 2610: loss = 1.7769 (0.754 sec/step)\n","I0908 16:01:29.150470 140650862335872 learning.py:512] global step 2610: loss = 1.7769 (0.754 sec/step)\n","INFO:tensorflow:global step 2611: loss = 2.1790 (0.789 sec/step)\n","I0908 16:01:29.941525 140650862335872 learning.py:512] global step 2611: loss = 2.1790 (0.789 sec/step)\n","INFO:tensorflow:global step 2612: loss = 2.3017 (0.764 sec/step)\n","I0908 16:01:30.706988 140650862335872 learning.py:512] global step 2612: loss = 2.3017 (0.764 sec/step)\n","INFO:tensorflow:global step 2613: loss = 2.0197 (0.769 sec/step)\n","I0908 16:01:31.478013 140650862335872 learning.py:512] global step 2613: loss = 2.0197 (0.769 sec/step)\n","INFO:tensorflow:global step 2614: loss = 2.3459 (0.770 sec/step)\n","I0908 16:01:32.249556 140650862335872 learning.py:512] global step 2614: loss = 2.3459 (0.770 sec/step)\n","INFO:tensorflow:global step 2615: loss = 2.3571 (0.761 sec/step)\n","I0908 16:01:33.012215 140650862335872 learning.py:512] global step 2615: loss = 2.3571 (0.761 sec/step)\n","INFO:tensorflow:global step 2616: loss = 1.8532 (0.754 sec/step)\n","I0908 16:01:33.768060 140650862335872 learning.py:512] global step 2616: loss = 1.8532 (0.754 sec/step)\n","INFO:tensorflow:global step 2617: loss = 1.9053 (0.757 sec/step)\n","I0908 16:01:34.526155 140650862335872 learning.py:512] global step 2617: loss = 1.9053 (0.757 sec/step)\n","INFO:tensorflow:global step 2618: loss = 1.8416 (0.763 sec/step)\n","I0908 16:01:35.291406 140650862335872 learning.py:512] global step 2618: loss = 1.8416 (0.763 sec/step)\n","INFO:tensorflow:global step 2619: loss = 2.2586 (0.771 sec/step)\n","I0908 16:01:36.064222 140650862335872 learning.py:512] global step 2619: loss = 2.2586 (0.771 sec/step)\n","INFO:tensorflow:global step 2620: loss = 2.5070 (0.760 sec/step)\n","I0908 16:01:36.825636 140650862335872 learning.py:512] global step 2620: loss = 2.5070 (0.760 sec/step)\n","INFO:tensorflow:global step 2621: loss = 2.0470 (0.780 sec/step)\n","I0908 16:01:37.607733 140650862335872 learning.py:512] global step 2621: loss = 2.0470 (0.780 sec/step)\n","INFO:tensorflow:global step 2622: loss = 1.7972 (0.762 sec/step)\n","I0908 16:01:38.371582 140650862335872 learning.py:512] global step 2622: loss = 1.7972 (0.762 sec/step)\n","INFO:tensorflow:global step 2623: loss = 1.9477 (0.754 sec/step)\n","I0908 16:01:39.127462 140650862335872 learning.py:512] global step 2623: loss = 1.9477 (0.754 sec/step)\n","INFO:tensorflow:global step 2624: loss = 1.7079 (0.748 sec/step)\n","I0908 16:01:39.876749 140650862335872 learning.py:512] global step 2624: loss = 1.7079 (0.748 sec/step)\n","INFO:tensorflow:global step 2625: loss = 2.5123 (0.764 sec/step)\n","I0908 16:01:40.642120 140650862335872 learning.py:512] global step 2625: loss = 2.5123 (0.764 sec/step)\n","INFO:tensorflow:global step 2626: loss = 2.2820 (0.755 sec/step)\n","I0908 16:01:41.398674 140650862335872 learning.py:512] global step 2626: loss = 2.2820 (0.755 sec/step)\n","INFO:tensorflow:global step 2627: loss = 2.2775 (0.758 sec/step)\n","I0908 16:01:42.158697 140650862335872 learning.py:512] global step 2627: loss = 2.2775 (0.758 sec/step)\n","INFO:tensorflow:global step 2628: loss = 2.7853 (0.739 sec/step)\n","I0908 16:01:42.899496 140650862335872 learning.py:512] global step 2628: loss = 2.7853 (0.739 sec/step)\n","INFO:tensorflow:global step 2629: loss = 2.3913 (0.772 sec/step)\n","I0908 16:01:43.673745 140650862335872 learning.py:512] global step 2629: loss = 2.3913 (0.772 sec/step)\n","INFO:tensorflow:global step 2630: loss = 2.1799 (0.766 sec/step)\n","I0908 16:01:44.441135 140650862335872 learning.py:512] global step 2630: loss = 2.1799 (0.766 sec/step)\n","INFO:tensorflow:global step 2631: loss = 2.2982 (0.757 sec/step)\n","I0908 16:01:45.199882 140650862335872 learning.py:512] global step 2631: loss = 2.2982 (0.757 sec/step)\n","INFO:tensorflow:global step 2632: loss = 2.2127 (0.749 sec/step)\n","I0908 16:01:45.950502 140650862335872 learning.py:512] global step 2632: loss = 2.2127 (0.749 sec/step)\n","INFO:tensorflow:global step 2633: loss = 2.2462 (0.938 sec/step)\n","I0908 16:01:46.894209 140650862335872 learning.py:512] global step 2633: loss = 2.2462 (0.938 sec/step)\n","INFO:tensorflow:Recording summary at step 2633.\n","I0908 16:01:47.819004 140646941251328 supervisor.py:1050] Recording summary at step 2633.\n","INFO:tensorflow:global step 2634: loss = 2.0676 (1.141 sec/step)\n","I0908 16:01:48.047528 140650862335872 learning.py:512] global step 2634: loss = 2.0676 (1.141 sec/step)\n","INFO:tensorflow:global step 2635: loss = 2.2275 (0.755 sec/step)\n","I0908 16:01:48.804461 140650862335872 learning.py:512] global step 2635: loss = 2.2275 (0.755 sec/step)\n","INFO:tensorflow:global step 2636: loss = 1.6592 (0.768 sec/step)\n","I0908 16:01:49.573848 140650862335872 learning.py:512] global step 2636: loss = 1.6592 (0.768 sec/step)\n","INFO:tensorflow:global step 2637: loss = 2.2087 (0.751 sec/step)\n","I0908 16:01:50.326206 140650862335872 learning.py:512] global step 2637: loss = 2.2087 (0.751 sec/step)\n","INFO:tensorflow:global step 2638: loss = 2.1279 (0.766 sec/step)\n","I0908 16:01:51.094331 140650862335872 learning.py:512] global step 2638: loss = 2.1279 (0.766 sec/step)\n","INFO:tensorflow:global step 2639: loss = 2.2785 (0.767 sec/step)\n","I0908 16:01:51.863452 140650862335872 learning.py:512] global step 2639: loss = 2.2785 (0.767 sec/step)\n","INFO:tensorflow:global step 2640: loss = 2.9010 (0.779 sec/step)\n","I0908 16:01:52.644367 140650862335872 learning.py:512] global step 2640: loss = 2.9010 (0.779 sec/step)\n","INFO:tensorflow:global step 2641: loss = 2.3714 (0.757 sec/step)\n","I0908 16:01:53.402704 140650862335872 learning.py:512] global step 2641: loss = 2.3714 (0.757 sec/step)\n","INFO:tensorflow:global step 2642: loss = 2.0395 (0.756 sec/step)\n","I0908 16:01:54.160198 140650862335872 learning.py:512] global step 2642: loss = 2.0395 (0.756 sec/step)\n","INFO:tensorflow:global step 2643: loss = 1.9364 (0.765 sec/step)\n","I0908 16:01:54.927290 140650862335872 learning.py:512] global step 2643: loss = 1.9364 (0.765 sec/step)\n","INFO:tensorflow:global step 2644: loss = 1.6582 (0.765 sec/step)\n","I0908 16:01:55.694316 140650862335872 learning.py:512] global step 2644: loss = 1.6582 (0.765 sec/step)\n","INFO:tensorflow:global step 2645: loss = 1.9993 (0.746 sec/step)\n","I0908 16:01:56.441462 140650862335872 learning.py:512] global step 2645: loss = 1.9993 (0.746 sec/step)\n","INFO:tensorflow:global step 2646: loss = 2.0606 (0.758 sec/step)\n","I0908 16:01:57.200863 140650862335872 learning.py:512] global step 2646: loss = 2.0606 (0.758 sec/step)\n","INFO:tensorflow:global step 2647: loss = 2.4136 (0.755 sec/step)\n","I0908 16:01:57.957144 140650862335872 learning.py:512] global step 2647: loss = 2.4136 (0.755 sec/step)\n","INFO:tensorflow:global step 2648: loss = 2.1892 (0.765 sec/step)\n","I0908 16:01:58.723860 140650862335872 learning.py:512] global step 2648: loss = 2.1892 (0.765 sec/step)\n","INFO:tensorflow:global step 2649: loss = 2.0154 (0.769 sec/step)\n","I0908 16:01:59.494312 140650862335872 learning.py:512] global step 2649: loss = 2.0154 (0.769 sec/step)\n","INFO:tensorflow:global step 2650: loss = 2.2282 (0.764 sec/step)\n","I0908 16:02:00.260246 140650862335872 learning.py:512] global step 2650: loss = 2.2282 (0.764 sec/step)\n","INFO:tensorflow:global step 2651: loss = 2.7672 (0.774 sec/step)\n","I0908 16:02:01.035925 140650862335872 learning.py:512] global step 2651: loss = 2.7672 (0.774 sec/step)\n","INFO:tensorflow:global step 2652: loss = 2.2053 (0.768 sec/step)\n","I0908 16:02:01.805285 140650862335872 learning.py:512] global step 2652: loss = 2.2053 (0.768 sec/step)\n","INFO:tensorflow:global step 2653: loss = 2.3408 (0.729 sec/step)\n","I0908 16:02:02.535781 140650862335872 learning.py:512] global step 2653: loss = 2.3408 (0.729 sec/step)\n","INFO:tensorflow:global step 2654: loss = 1.7096 (0.755 sec/step)\n","I0908 16:02:03.292358 140650862335872 learning.py:512] global step 2654: loss = 1.7096 (0.755 sec/step)\n","INFO:tensorflow:global step 2655: loss = 2.1245 (0.772 sec/step)\n","I0908 16:02:04.065732 140650862335872 learning.py:512] global step 2655: loss = 2.1245 (0.772 sec/step)\n","INFO:tensorflow:global step 2656: loss = 2.1235 (0.746 sec/step)\n","I0908 16:02:04.813642 140650862335872 learning.py:512] global step 2656: loss = 2.1235 (0.746 sec/step)\n","INFO:tensorflow:global step 2657: loss = 2.3707 (0.765 sec/step)\n","I0908 16:02:05.580607 140650862335872 learning.py:512] global step 2657: loss = 2.3707 (0.765 sec/step)\n","INFO:tensorflow:global step 2658: loss = 2.2692 (0.771 sec/step)\n","I0908 16:02:06.353185 140650862335872 learning.py:512] global step 2658: loss = 2.2692 (0.771 sec/step)\n","INFO:tensorflow:global step 2659: loss = 1.9397 (0.760 sec/step)\n","I0908 16:02:07.114912 140650862335872 learning.py:512] global step 2659: loss = 1.9397 (0.760 sec/step)\n","INFO:tensorflow:global step 2660: loss = 2.2808 (0.740 sec/step)\n","I0908 16:02:07.857088 140650862335872 learning.py:512] global step 2660: loss = 2.2808 (0.740 sec/step)\n","INFO:tensorflow:global step 2661: loss = 2.0175 (0.767 sec/step)\n","I0908 16:02:08.625649 140650862335872 learning.py:512] global step 2661: loss = 2.0175 (0.767 sec/step)\n","INFO:tensorflow:global step 2662: loss = 2.2763 (0.767 sec/step)\n","I0908 16:02:09.394522 140650862335872 learning.py:512] global step 2662: loss = 2.2763 (0.767 sec/step)\n","INFO:tensorflow:global step 2663: loss = 2.2120 (0.780 sec/step)\n","I0908 16:02:10.176183 140650862335872 learning.py:512] global step 2663: loss = 2.2120 (0.780 sec/step)\n","INFO:tensorflow:global step 2664: loss = 2.5925 (0.753 sec/step)\n","I0908 16:02:10.931272 140650862335872 learning.py:512] global step 2664: loss = 2.5925 (0.753 sec/step)\n","INFO:tensorflow:global step 2665: loss = 2.2787 (0.769 sec/step)\n","I0908 16:02:11.702311 140650862335872 learning.py:512] global step 2665: loss = 2.2787 (0.769 sec/step)\n","INFO:tensorflow:global step 2666: loss = 1.8676 (0.762 sec/step)\n","I0908 16:02:12.465629 140650862335872 learning.py:512] global step 2666: loss = 1.8676 (0.762 sec/step)\n","INFO:tensorflow:global step 2667: loss = 2.4047 (0.764 sec/step)\n","I0908 16:02:13.231242 140650862335872 learning.py:512] global step 2667: loss = 2.4047 (0.764 sec/step)\n","INFO:tensorflow:global step 2668: loss = 2.4263 (0.751 sec/step)\n","I0908 16:02:13.984047 140650862335872 learning.py:512] global step 2668: loss = 2.4263 (0.751 sec/step)\n","INFO:tensorflow:global step 2669: loss = 2.4431 (0.757 sec/step)\n","I0908 16:02:14.743094 140650862335872 learning.py:512] global step 2669: loss = 2.4431 (0.757 sec/step)\n","INFO:tensorflow:global step 2670: loss = 2.3146 (0.754 sec/step)\n","I0908 16:02:15.498524 140650862335872 learning.py:512] global step 2670: loss = 2.3146 (0.754 sec/step)\n","INFO:tensorflow:global step 2671: loss = 2.2359 (0.746 sec/step)\n","I0908 16:02:16.246081 140650862335872 learning.py:512] global step 2671: loss = 2.2359 (0.746 sec/step)\n","INFO:tensorflow:global step 2672: loss = 2.1987 (0.766 sec/step)\n","I0908 16:02:17.013729 140650862335872 learning.py:512] global step 2672: loss = 2.1987 (0.766 sec/step)\n","INFO:tensorflow:global step 2673: loss = 2.4145 (0.758 sec/step)\n","I0908 16:02:17.773316 140650862335872 learning.py:512] global step 2673: loss = 2.4145 (0.758 sec/step)\n","INFO:tensorflow:global step 2674: loss = 2.3665 (0.768 sec/step)\n","I0908 16:02:18.543342 140650862335872 learning.py:512] global step 2674: loss = 2.3665 (0.768 sec/step)\n","INFO:tensorflow:global step 2675: loss = 2.1812 (0.764 sec/step)\n","I0908 16:02:19.309437 140650862335872 learning.py:512] global step 2675: loss = 2.1812 (0.764 sec/step)\n","INFO:tensorflow:global step 2676: loss = 1.6615 (0.776 sec/step)\n","I0908 16:02:20.087114 140650862335872 learning.py:512] global step 2676: loss = 1.6615 (0.776 sec/step)\n","INFO:tensorflow:global step 2677: loss = 2.2019 (0.765 sec/step)\n","I0908 16:02:20.853836 140650862335872 learning.py:512] global step 2677: loss = 2.2019 (0.765 sec/step)\n","INFO:tensorflow:global step 2678: loss = 2.0147 (0.763 sec/step)\n","I0908 16:02:21.618820 140650862335872 learning.py:512] global step 2678: loss = 2.0147 (0.763 sec/step)\n","INFO:tensorflow:global step 2679: loss = 1.8174 (0.763 sec/step)\n","I0908 16:02:22.383529 140650862335872 learning.py:512] global step 2679: loss = 1.8174 (0.763 sec/step)\n","INFO:tensorflow:global step 2680: loss = 2.0050 (0.778 sec/step)\n","I0908 16:02:23.163676 140650862335872 learning.py:512] global step 2680: loss = 2.0050 (0.778 sec/step)\n","INFO:tensorflow:global step 2681: loss = 2.3031 (0.782 sec/step)\n","I0908 16:02:23.947054 140650862335872 learning.py:512] global step 2681: loss = 2.3031 (0.782 sec/step)\n","INFO:tensorflow:global step 2682: loss = 2.0721 (0.772 sec/step)\n","I0908 16:02:24.720409 140650862335872 learning.py:512] global step 2682: loss = 2.0721 (0.772 sec/step)\n","INFO:tensorflow:global step 2683: loss = 2.1367 (0.766 sec/step)\n","I0908 16:02:25.487915 140650862335872 learning.py:512] global step 2683: loss = 2.1367 (0.766 sec/step)\n","INFO:tensorflow:global step 2684: loss = 2.7485 (0.765 sec/step)\n","I0908 16:02:26.254824 140650862335872 learning.py:512] global step 2684: loss = 2.7485 (0.765 sec/step)\n","INFO:tensorflow:global step 2685: loss = 2.3595 (0.777 sec/step)\n","I0908 16:02:27.033856 140650862335872 learning.py:512] global step 2685: loss = 2.3595 (0.777 sec/step)\n","INFO:tensorflow:global step 2686: loss = 2.1935 (0.760 sec/step)\n","I0908 16:02:27.795256 140650862335872 learning.py:512] global step 2686: loss = 2.1935 (0.760 sec/step)\n","INFO:tensorflow:global step 2687: loss = 1.9995 (0.760 sec/step)\n","I0908 16:02:28.557053 140650862335872 learning.py:512] global step 2687: loss = 1.9995 (0.760 sec/step)\n","INFO:tensorflow:global step 2688: loss = 1.9969 (0.769 sec/step)\n","I0908 16:02:29.328024 140650862335872 learning.py:512] global step 2688: loss = 1.9969 (0.769 sec/step)\n","INFO:tensorflow:global step 2689: loss = 1.9515 (0.770 sec/step)\n","I0908 16:02:30.099274 140650862335872 learning.py:512] global step 2689: loss = 1.9515 (0.770 sec/step)\n","INFO:tensorflow:global step 2690: loss = 2.2002 (0.751 sec/step)\n","I0908 16:02:30.851790 140650862335872 learning.py:512] global step 2690: loss = 2.2002 (0.751 sec/step)\n","INFO:tensorflow:global step 2691: loss = 2.0227 (0.749 sec/step)\n","I0908 16:02:31.602123 140650862335872 learning.py:512] global step 2691: loss = 2.0227 (0.749 sec/step)\n","INFO:tensorflow:global step 2692: loss = 2.4540 (0.763 sec/step)\n","I0908 16:02:32.366679 140650862335872 learning.py:512] global step 2692: loss = 2.4540 (0.763 sec/step)\n","INFO:tensorflow:global step 2693: loss = 1.9408 (0.759 sec/step)\n","I0908 16:02:33.127051 140650862335872 learning.py:512] global step 2693: loss = 1.9408 (0.759 sec/step)\n","INFO:tensorflow:global step 2694: loss = 2.1081 (0.752 sec/step)\n","I0908 16:02:33.880452 140650862335872 learning.py:512] global step 2694: loss = 2.1081 (0.752 sec/step)\n","INFO:tensorflow:global step 2695: loss = 2.3747 (0.768 sec/step)\n","I0908 16:02:34.650153 140650862335872 learning.py:512] global step 2695: loss = 2.3747 (0.768 sec/step)\n","INFO:tensorflow:global step 2696: loss = 2.1458 (0.765 sec/step)\n","I0908 16:02:35.417358 140650862335872 learning.py:512] global step 2696: loss = 2.1458 (0.765 sec/step)\n","INFO:tensorflow:global step 2697: loss = 2.2421 (0.781 sec/step)\n","I0908 16:02:36.199974 140650862335872 learning.py:512] global step 2697: loss = 2.2421 (0.781 sec/step)\n","INFO:tensorflow:global step 2698: loss = 2.0532 (0.737 sec/step)\n","I0908 16:02:36.938162 140650862335872 learning.py:512] global step 2698: loss = 2.0532 (0.737 sec/step)\n","INFO:tensorflow:global step 2699: loss = 2.3233 (0.758 sec/step)\n","I0908 16:02:37.698244 140650862335872 learning.py:512] global step 2699: loss = 2.3233 (0.758 sec/step)\n","INFO:tensorflow:global step 2700: loss = 2.3772 (0.777 sec/step)\n","I0908 16:02:38.477012 140650862335872 learning.py:512] global step 2700: loss = 2.3772 (0.777 sec/step)\n","INFO:tensorflow:global step 2701: loss = 2.2460 (0.756 sec/step)\n","I0908 16:02:39.234415 140650862335872 learning.py:512] global step 2701: loss = 2.2460 (0.756 sec/step)\n","INFO:tensorflow:global step 2702: loss = 2.5090 (0.772 sec/step)\n","I0908 16:02:40.007670 140650862335872 learning.py:512] global step 2702: loss = 2.5090 (0.772 sec/step)\n","INFO:tensorflow:global step 2703: loss = 2.3453 (0.770 sec/step)\n","I0908 16:02:40.779301 140650862335872 learning.py:512] global step 2703: loss = 2.3453 (0.770 sec/step)\n","INFO:tensorflow:global step 2704: loss = 2.2319 (0.772 sec/step)\n","I0908 16:02:41.552760 140650862335872 learning.py:512] global step 2704: loss = 2.2319 (0.772 sec/step)\n","INFO:tensorflow:global step 2705: loss = 2.2944 (0.744 sec/step)\n","I0908 16:02:42.298722 140650862335872 learning.py:512] global step 2705: loss = 2.2944 (0.744 sec/step)\n","INFO:tensorflow:global step 2706: loss = 2.1143 (0.755 sec/step)\n","I0908 16:02:43.055651 140650862335872 learning.py:512] global step 2706: loss = 2.1143 (0.755 sec/step)\n","INFO:tensorflow:global step 2707: loss = 2.1097 (0.773 sec/step)\n","I0908 16:02:43.830660 140650862335872 learning.py:512] global step 2707: loss = 2.1097 (0.773 sec/step)\n","INFO:tensorflow:global step 2708: loss = 2.2731 (0.767 sec/step)\n","I0908 16:02:44.599621 140650862335872 learning.py:512] global step 2708: loss = 2.2731 (0.767 sec/step)\n","INFO:tensorflow:global step 2709: loss = 2.7053 (0.758 sec/step)\n","I0908 16:02:45.359115 140650862335872 learning.py:512] global step 2709: loss = 2.7053 (0.758 sec/step)\n","INFO:tensorflow:global step 2710: loss = 1.7591 (0.758 sec/step)\n","I0908 16:02:46.119077 140650862335872 learning.py:512] global step 2710: loss = 1.7591 (0.758 sec/step)\n","INFO:tensorflow:global step 2711: loss = 2.1682 (0.778 sec/step)\n","I0908 16:02:46.898822 140650862335872 learning.py:512] global step 2711: loss = 2.1682 (0.778 sec/step)\n","INFO:tensorflow:global step 2712: loss = 2.0486 (0.758 sec/step)\n","I0908 16:02:47.658053 140650862335872 learning.py:512] global step 2712: loss = 2.0486 (0.758 sec/step)\n","INFO:tensorflow:global step 2713: loss = 2.1333 (0.768 sec/step)\n","I0908 16:02:48.427986 140650862335872 learning.py:512] global step 2713: loss = 2.1333 (0.768 sec/step)\n","INFO:tensorflow:global step 2714: loss = 2.3014 (0.763 sec/step)\n","I0908 16:02:49.193264 140650862335872 learning.py:512] global step 2714: loss = 2.3014 (0.763 sec/step)\n","INFO:tensorflow:global step 2715: loss = 2.5216 (0.762 sec/step)\n","I0908 16:02:49.957514 140650862335872 learning.py:512] global step 2715: loss = 2.5216 (0.762 sec/step)\n","INFO:tensorflow:global step 2716: loss = 2.2488 (0.764 sec/step)\n","I0908 16:02:50.723350 140650862335872 learning.py:512] global step 2716: loss = 2.2488 (0.764 sec/step)\n","INFO:tensorflow:global step 2717: loss = 1.8480 (0.765 sec/step)\n","I0908 16:02:51.490017 140650862335872 learning.py:512] global step 2717: loss = 1.8480 (0.765 sec/step)\n","INFO:tensorflow:global step 2718: loss = 2.1377 (0.743 sec/step)\n","I0908 16:02:52.234581 140650862335872 learning.py:512] global step 2718: loss = 2.1377 (0.743 sec/step)\n","INFO:tensorflow:global step 2719: loss = 1.8678 (0.768 sec/step)\n","I0908 16:02:53.004144 140650862335872 learning.py:512] global step 2719: loss = 1.8678 (0.768 sec/step)\n","INFO:tensorflow:global step 2720: loss = 2.5148 (0.752 sec/step)\n","I0908 16:02:53.757568 140650862335872 learning.py:512] global step 2720: loss = 2.5148 (0.752 sec/step)\n","INFO:tensorflow:global step 2721: loss = 2.5379 (0.738 sec/step)\n","I0908 16:02:54.496949 140650862335872 learning.py:512] global step 2721: loss = 2.5379 (0.738 sec/step)\n","INFO:tensorflow:global step 2722: loss = 2.1244 (0.756 sec/step)\n","I0908 16:02:55.254737 140650862335872 learning.py:512] global step 2722: loss = 2.1244 (0.756 sec/step)\n","INFO:tensorflow:global step 2723: loss = 2.1855 (0.749 sec/step)\n","I0908 16:02:56.005810 140650862335872 learning.py:512] global step 2723: loss = 2.1855 (0.749 sec/step)\n","INFO:tensorflow:global step 2724: loss = 2.5143 (0.760 sec/step)\n","I0908 16:02:56.767675 140650862335872 learning.py:512] global step 2724: loss = 2.5143 (0.760 sec/step)\n","INFO:tensorflow:global step 2725: loss = 2.1397 (0.750 sec/step)\n","I0908 16:02:57.519545 140650862335872 learning.py:512] global step 2725: loss = 2.1397 (0.750 sec/step)\n","INFO:tensorflow:global step 2726: loss = 2.1103 (0.770 sec/step)\n","I0908 16:02:58.291241 140650862335872 learning.py:512] global step 2726: loss = 2.1103 (0.770 sec/step)\n","INFO:tensorflow:global step 2727: loss = 2.2617 (0.757 sec/step)\n","I0908 16:02:59.049740 140650862335872 learning.py:512] global step 2727: loss = 2.2617 (0.757 sec/step)\n","INFO:tensorflow:global step 2728: loss = 2.5684 (0.772 sec/step)\n","I0908 16:02:59.823130 140650862335872 learning.py:512] global step 2728: loss = 2.5684 (0.772 sec/step)\n","INFO:tensorflow:global step 2729: loss = 1.9642 (0.757 sec/step)\n","I0908 16:03:00.581551 140650862335872 learning.py:512] global step 2729: loss = 1.9642 (0.757 sec/step)\n","INFO:tensorflow:global step 2730: loss = 2.1015 (0.766 sec/step)\n","I0908 16:03:01.349167 140650862335872 learning.py:512] global step 2730: loss = 2.1015 (0.766 sec/step)\n","INFO:tensorflow:global step 2731: loss = 1.9993 (0.772 sec/step)\n","I0908 16:03:02.123102 140650862335872 learning.py:512] global step 2731: loss = 1.9993 (0.772 sec/step)\n","INFO:tensorflow:global step 2732: loss = 2.0957 (0.747 sec/step)\n","I0908 16:03:02.871511 140650862335872 learning.py:512] global step 2732: loss = 2.0957 (0.747 sec/step)\n","INFO:tensorflow:global step 2733: loss = 3.4509 (0.758 sec/step)\n","I0908 16:03:03.630569 140650862335872 learning.py:512] global step 2733: loss = 3.4509 (0.758 sec/step)\n","INFO:tensorflow:global step 2734: loss = 2.1605 (0.754 sec/step)\n","I0908 16:03:04.386814 140650862335872 learning.py:512] global step 2734: loss = 2.1605 (0.754 sec/step)\n","INFO:tensorflow:global step 2735: loss = 2.2440 (0.769 sec/step)\n","I0908 16:03:05.157327 140650862335872 learning.py:512] global step 2735: loss = 2.2440 (0.769 sec/step)\n","INFO:tensorflow:global step 2736: loss = 2.5084 (0.749 sec/step)\n","I0908 16:03:05.907640 140650862335872 learning.py:512] global step 2736: loss = 2.5084 (0.749 sec/step)\n","INFO:tensorflow:global step 2737: loss = 2.1388 (0.768 sec/step)\n","I0908 16:03:06.676773 140650862335872 learning.py:512] global step 2737: loss = 2.1388 (0.768 sec/step)\n","INFO:tensorflow:global step 2738: loss = 2.4365 (0.750 sec/step)\n","I0908 16:03:07.428195 140650862335872 learning.py:512] global step 2738: loss = 2.4365 (0.750 sec/step)\n","INFO:tensorflow:global step 2739: loss = 2.2173 (0.760 sec/step)\n","I0908 16:03:08.190005 140650862335872 learning.py:512] global step 2739: loss = 2.2173 (0.760 sec/step)\n","INFO:tensorflow:global step 2740: loss = 2.0933 (0.769 sec/step)\n","I0908 16:03:08.961096 140650862335872 learning.py:512] global step 2740: loss = 2.0933 (0.769 sec/step)\n","INFO:tensorflow:global step 2741: loss = 2.0389 (0.773 sec/step)\n","I0908 16:03:09.736013 140650862335872 learning.py:512] global step 2741: loss = 2.0389 (0.773 sec/step)\n","INFO:tensorflow:global step 2742: loss = 2.1656 (0.766 sec/step)\n","I0908 16:03:10.503406 140650862335872 learning.py:512] global step 2742: loss = 2.1656 (0.766 sec/step)\n","INFO:tensorflow:global step 2743: loss = 2.4533 (0.759 sec/step)\n","I0908 16:03:11.263734 140650862335872 learning.py:512] global step 2743: loss = 2.4533 (0.759 sec/step)\n","INFO:tensorflow:global step 2744: loss = 2.2695 (0.765 sec/step)\n","I0908 16:03:12.030485 140650862335872 learning.py:512] global step 2744: loss = 2.2695 (0.765 sec/step)\n","INFO:tensorflow:global step 2745: loss = 1.9119 (0.782 sec/step)\n","I0908 16:03:12.813876 140650862335872 learning.py:512] global step 2745: loss = 1.9119 (0.782 sec/step)\n","INFO:tensorflow:global step 2746: loss = 1.8850 (0.763 sec/step)\n","I0908 16:03:13.578555 140650862335872 learning.py:512] global step 2746: loss = 1.8850 (0.763 sec/step)\n","INFO:tensorflow:global step 2747: loss = 2.3390 (0.760 sec/step)\n","I0908 16:03:14.340198 140650862335872 learning.py:512] global step 2747: loss = 2.3390 (0.760 sec/step)\n","INFO:tensorflow:global step 2748: loss = 2.4847 (0.738 sec/step)\n","I0908 16:03:15.080551 140650862335872 learning.py:512] global step 2748: loss = 2.4847 (0.738 sec/step)\n","INFO:tensorflow:global step 2749: loss = 1.8626 (0.765 sec/step)\n","I0908 16:03:15.847292 140650862335872 learning.py:512] global step 2749: loss = 1.8626 (0.765 sec/step)\n","INFO:tensorflow:global step 2750: loss = 2.0698 (0.759 sec/step)\n","I0908 16:03:16.607799 140650862335872 learning.py:512] global step 2750: loss = 2.0698 (0.759 sec/step)\n","INFO:tensorflow:global step 2751: loss = 2.0893 (0.765 sec/step)\n","I0908 16:03:17.374125 140650862335872 learning.py:512] global step 2751: loss = 2.0893 (0.765 sec/step)\n","INFO:tensorflow:global step 2752: loss = 2.1557 (0.775 sec/step)\n","I0908 16:03:18.151266 140650862335872 learning.py:512] global step 2752: loss = 2.1557 (0.775 sec/step)\n","INFO:tensorflow:global step 2753: loss = 2.1854 (0.759 sec/step)\n","I0908 16:03:18.911728 140650862335872 learning.py:512] global step 2753: loss = 2.1854 (0.759 sec/step)\n","INFO:tensorflow:global step 2754: loss = 2.1878 (0.756 sec/step)\n","I0908 16:03:19.669762 140650862335872 learning.py:512] global step 2754: loss = 2.1878 (0.756 sec/step)\n","INFO:tensorflow:global step 2755: loss = 2.2991 (0.741 sec/step)\n","I0908 16:03:20.411968 140650862335872 learning.py:512] global step 2755: loss = 2.2991 (0.741 sec/step)\n","INFO:tensorflow:global step 2756: loss = 2.4118 (0.754 sec/step)\n","I0908 16:03:21.167331 140650862335872 learning.py:512] global step 2756: loss = 2.4118 (0.754 sec/step)\n","INFO:tensorflow:global step 2757: loss = 1.6681 (0.755 sec/step)\n","I0908 16:03:21.924220 140650862335872 learning.py:512] global step 2757: loss = 1.6681 (0.755 sec/step)\n","INFO:tensorflow:global step 2758: loss = 2.0065 (0.748 sec/step)\n","I0908 16:03:22.673924 140650862335872 learning.py:512] global step 2758: loss = 2.0065 (0.748 sec/step)\n","INFO:tensorflow:global step 2759: loss = 2.5797 (0.770 sec/step)\n","I0908 16:03:23.445985 140650862335872 learning.py:512] global step 2759: loss = 2.5797 (0.770 sec/step)\n","INFO:tensorflow:global step 2760: loss = 2.1074 (0.780 sec/step)\n","I0908 16:03:24.227430 140650862335872 learning.py:512] global step 2760: loss = 2.1074 (0.780 sec/step)\n","INFO:tensorflow:global step 2761: loss = 1.9328 (0.760 sec/step)\n","I0908 16:03:24.989221 140650862335872 learning.py:512] global step 2761: loss = 1.9328 (0.760 sec/step)\n","INFO:tensorflow:global step 2762: loss = 2.1191 (0.748 sec/step)\n","I0908 16:03:25.738358 140650862335872 learning.py:512] global step 2762: loss = 2.1191 (0.748 sec/step)\n","INFO:tensorflow:global step 2763: loss = 2.1179 (0.770 sec/step)\n","I0908 16:03:26.510483 140650862335872 learning.py:512] global step 2763: loss = 2.1179 (0.770 sec/step)\n","INFO:tensorflow:global step 2764: loss = 2.0112 (0.760 sec/step)\n","I0908 16:03:27.271630 140650862335872 learning.py:512] global step 2764: loss = 2.0112 (0.760 sec/step)\n","INFO:tensorflow:global step 2765: loss = 2.4366 (0.770 sec/step)\n","I0908 16:03:28.043228 140650862335872 learning.py:512] global step 2765: loss = 2.4366 (0.770 sec/step)\n","INFO:tensorflow:global step 2766: loss = 2.1260 (0.767 sec/step)\n","I0908 16:03:28.811671 140650862335872 learning.py:512] global step 2766: loss = 2.1260 (0.767 sec/step)\n","INFO:tensorflow:global step 2767: loss = 1.8808 (0.768 sec/step)\n","I0908 16:03:29.581144 140650862335872 learning.py:512] global step 2767: loss = 1.8808 (0.768 sec/step)\n","INFO:tensorflow:global step 2768: loss = 2.5992 (0.762 sec/step)\n","I0908 16:03:30.344539 140650862335872 learning.py:512] global step 2768: loss = 2.5992 (0.762 sec/step)\n","INFO:tensorflow:global step 2769: loss = 1.7407 (0.750 sec/step)\n","I0908 16:03:31.096286 140650862335872 learning.py:512] global step 2769: loss = 1.7407 (0.750 sec/step)\n","INFO:tensorflow:global step 2770: loss = 2.5766 (0.757 sec/step)\n","I0908 16:03:31.854665 140650862335872 learning.py:512] global step 2770: loss = 2.5766 (0.757 sec/step)\n","INFO:tensorflow:global step 2771: loss = 1.9467 (0.763 sec/step)\n","I0908 16:03:32.619367 140650862335872 learning.py:512] global step 2771: loss = 1.9467 (0.763 sec/step)\n","INFO:tensorflow:global step 2772: loss = 1.7432 (0.741 sec/step)\n","I0908 16:03:33.362149 140650862335872 learning.py:512] global step 2772: loss = 1.7432 (0.741 sec/step)\n","INFO:tensorflow:global step 2773: loss = 2.3047 (0.763 sec/step)\n","I0908 16:03:34.126756 140650862335872 learning.py:512] global step 2773: loss = 2.3047 (0.763 sec/step)\n","INFO:tensorflow:global step 2774: loss = 2.1655 (0.756 sec/step)\n","I0908 16:03:34.884425 140650862335872 learning.py:512] global step 2774: loss = 2.1655 (0.756 sec/step)\n","INFO:tensorflow:global step 2775: loss = 1.9499 (0.754 sec/step)\n","I0908 16:03:35.640503 140650862335872 learning.py:512] global step 2775: loss = 1.9499 (0.754 sec/step)\n","INFO:tensorflow:global step 2776: loss = 2.6204 (0.760 sec/step)\n","I0908 16:03:36.402624 140650862335872 learning.py:512] global step 2776: loss = 2.6204 (0.760 sec/step)\n","INFO:tensorflow:global step 2777: loss = 1.9248 (0.768 sec/step)\n","I0908 16:03:37.172054 140650862335872 learning.py:512] global step 2777: loss = 1.9248 (0.768 sec/step)\n","INFO:tensorflow:global step 2778: loss = 2.3204 (0.778 sec/step)\n","I0908 16:03:37.952001 140650862335872 learning.py:512] global step 2778: loss = 2.3204 (0.778 sec/step)\n","INFO:tensorflow:global step 2779: loss = 2.3194 (0.777 sec/step)\n","I0908 16:03:38.730178 140650862335872 learning.py:512] global step 2779: loss = 2.3194 (0.777 sec/step)\n","INFO:tensorflow:global step 2780: loss = 1.9160 (0.780 sec/step)\n","I0908 16:03:39.511955 140650862335872 learning.py:512] global step 2780: loss = 1.9160 (0.780 sec/step)\n","INFO:tensorflow:global step 2781: loss = 2.1279 (0.743 sec/step)\n","I0908 16:03:40.256355 140650862335872 learning.py:512] global step 2781: loss = 2.1279 (0.743 sec/step)\n","INFO:tensorflow:global step 2782: loss = 1.8630 (0.764 sec/step)\n","I0908 16:03:41.021955 140650862335872 learning.py:512] global step 2782: loss = 1.8630 (0.764 sec/step)\n","INFO:tensorflow:global step 2783: loss = 2.2969 (0.778 sec/step)\n","I0908 16:03:41.801832 140650862335872 learning.py:512] global step 2783: loss = 2.2969 (0.778 sec/step)\n","INFO:tensorflow:global step 2784: loss = 2.1838 (0.756 sec/step)\n","I0908 16:03:42.559229 140650862335872 learning.py:512] global step 2784: loss = 2.1838 (0.756 sec/step)\n","INFO:tensorflow:global step 2785: loss = 2.0241 (0.765 sec/step)\n","I0908 16:03:43.325935 140650862335872 learning.py:512] global step 2785: loss = 2.0241 (0.765 sec/step)\n","INFO:tensorflow:global step 2786: loss = 2.3773 (0.761 sec/step)\n","I0908 16:03:44.088875 140650862335872 learning.py:512] global step 2786: loss = 2.3773 (0.761 sec/step)\n","INFO:tensorflow:global step 2787: loss = 2.3900 (0.760 sec/step)\n","I0908 16:03:44.850407 140650862335872 learning.py:512] global step 2787: loss = 2.3900 (0.760 sec/step)\n","INFO:tensorflow:global step 2788: loss = 1.7864 (0.775 sec/step)\n","I0908 16:03:45.626781 140650862335872 learning.py:512] global step 2788: loss = 1.7864 (0.775 sec/step)\n","INFO:tensorflow:global step 2789: loss = 1.9970 (0.771 sec/step)\n","I0908 16:03:46.416130 140650862335872 learning.py:512] global step 2789: loss = 1.9970 (0.771 sec/step)\n","INFO:tensorflow:global step 2790: loss = 1.8618 (1.287 sec/step)\n","I0908 16:03:47.716564 140650862335872 learning.py:512] global step 2790: loss = 1.8618 (1.287 sec/step)\n","INFO:tensorflow:Recording summary at step 2790.\n","I0908 16:03:47.718770 140646941251328 supervisor.py:1050] Recording summary at step 2790.\n","INFO:tensorflow:global step 2791: loss = 2.2234 (0.772 sec/step)\n","I0908 16:03:48.490617 140650862335872 learning.py:512] global step 2791: loss = 2.2234 (0.772 sec/step)\n","INFO:tensorflow:global step 2792: loss = 2.0172 (0.743 sec/step)\n","I0908 16:03:49.234755 140650862335872 learning.py:512] global step 2792: loss = 2.0172 (0.743 sec/step)\n","INFO:tensorflow:global step 2793: loss = 2.0411 (0.776 sec/step)\n","I0908 16:03:50.012459 140650862335872 learning.py:512] global step 2793: loss = 2.0411 (0.776 sec/step)\n","INFO:tensorflow:global step 2794: loss = 2.4794 (0.770 sec/step)\n","I0908 16:03:50.783946 140650862335872 learning.py:512] global step 2794: loss = 2.4794 (0.770 sec/step)\n","INFO:tensorflow:global step 2795: loss = 2.6169 (0.755 sec/step)\n","I0908 16:03:51.540242 140650862335872 learning.py:512] global step 2795: loss = 2.6169 (0.755 sec/step)\n","INFO:tensorflow:global step 2796: loss = 1.9026 (0.783 sec/step)\n","I0908 16:03:52.325195 140650862335872 learning.py:512] global step 2796: loss = 1.9026 (0.783 sec/step)\n","INFO:tensorflow:global step 2797: loss = 2.2712 (0.752 sec/step)\n","I0908 16:03:53.079196 140650862335872 learning.py:512] global step 2797: loss = 2.2712 (0.752 sec/step)\n","INFO:tensorflow:global step 2798: loss = 2.0563 (0.781 sec/step)\n","I0908 16:03:53.862469 140650862335872 learning.py:512] global step 2798: loss = 2.0563 (0.781 sec/step)\n","INFO:tensorflow:global step 2799: loss = 2.7152 (0.751 sec/step)\n","I0908 16:03:54.615656 140650862335872 learning.py:512] global step 2799: loss = 2.7152 (0.751 sec/step)\n","INFO:tensorflow:global step 2800: loss = 2.5622 (0.770 sec/step)\n","I0908 16:03:55.387058 140650862335872 learning.py:512] global step 2800: loss = 2.5622 (0.770 sec/step)\n","INFO:tensorflow:global step 2801: loss = 2.1045 (0.775 sec/step)\n","I0908 16:03:56.163903 140650862335872 learning.py:512] global step 2801: loss = 2.1045 (0.775 sec/step)\n","INFO:tensorflow:global step 2802: loss = 2.3165 (0.762 sec/step)\n","I0908 16:03:56.927767 140650862335872 learning.py:512] global step 2802: loss = 2.3165 (0.762 sec/step)\n","INFO:tensorflow:global step 2803: loss = 2.3368 (0.760 sec/step)\n","I0908 16:03:57.690314 140650862335872 learning.py:512] global step 2803: loss = 2.3368 (0.760 sec/step)\n","INFO:tensorflow:global step 2804: loss = 2.0472 (0.752 sec/step)\n","I0908 16:03:58.444294 140650862335872 learning.py:512] global step 2804: loss = 2.0472 (0.752 sec/step)\n","INFO:tensorflow:global step 2805: loss = 2.8254 (0.780 sec/step)\n","I0908 16:03:59.226477 140650862335872 learning.py:512] global step 2805: loss = 2.8254 (0.780 sec/step)\n","INFO:tensorflow:global step 2806: loss = 2.3197 (0.767 sec/step)\n","I0908 16:03:59.995216 140650862335872 learning.py:512] global step 2806: loss = 2.3197 (0.767 sec/step)\n","INFO:tensorflow:global step 2807: loss = 1.7423 (0.735 sec/step)\n","I0908 16:04:00.731907 140650862335872 learning.py:512] global step 2807: loss = 1.7423 (0.735 sec/step)\n","INFO:tensorflow:global step 2808: loss = 2.3671 (0.756 sec/step)\n","I0908 16:04:01.489751 140650862335872 learning.py:512] global step 2808: loss = 2.3671 (0.756 sec/step)\n","INFO:tensorflow:global step 2809: loss = 2.2084 (0.768 sec/step)\n","I0908 16:04:02.259920 140650862335872 learning.py:512] global step 2809: loss = 2.2084 (0.768 sec/step)\n","INFO:tensorflow:global step 2810: loss = 2.2398 (0.753 sec/step)\n","I0908 16:04:03.014851 140650862335872 learning.py:512] global step 2810: loss = 2.2398 (0.753 sec/step)\n","INFO:tensorflow:global step 2811: loss = 2.0140 (0.775 sec/step)\n","I0908 16:04:03.794936 140650862335872 learning.py:512] global step 2811: loss = 2.0140 (0.775 sec/step)\n","INFO:tensorflow:global step 2812: loss = 2.0770 (0.786 sec/step)\n","I0908 16:04:04.582730 140650862335872 learning.py:512] global step 2812: loss = 2.0770 (0.786 sec/step)\n","INFO:tensorflow:global step 2813: loss = 2.0515 (0.762 sec/step)\n","I0908 16:04:05.346268 140650862335872 learning.py:512] global step 2813: loss = 2.0515 (0.762 sec/step)\n","INFO:tensorflow:global step 2814: loss = 2.3475 (0.769 sec/step)\n","I0908 16:04:06.117418 140650862335872 learning.py:512] global step 2814: loss = 2.3475 (0.769 sec/step)\n","INFO:tensorflow:global step 2815: loss = 2.0633 (0.759 sec/step)\n","I0908 16:04:06.877756 140650862335872 learning.py:512] global step 2815: loss = 2.0633 (0.759 sec/step)\n","INFO:tensorflow:global step 2816: loss = 2.1816 (0.763 sec/step)\n","I0908 16:04:07.641976 140650862335872 learning.py:512] global step 2816: loss = 2.1816 (0.763 sec/step)\n","INFO:tensorflow:global step 2817: loss = 2.1898 (0.744 sec/step)\n","I0908 16:04:08.387718 140650862335872 learning.py:512] global step 2817: loss = 2.1898 (0.744 sec/step)\n","INFO:tensorflow:global step 2818: loss = 2.3605 (0.762 sec/step)\n","I0908 16:04:09.152034 140650862335872 learning.py:512] global step 2818: loss = 2.3605 (0.762 sec/step)\n","INFO:tensorflow:global step 2819: loss = 2.1535 (0.755 sec/step)\n","I0908 16:04:09.908715 140650862335872 learning.py:512] global step 2819: loss = 2.1535 (0.755 sec/step)\n","INFO:tensorflow:global step 2820: loss = 1.7227 (0.763 sec/step)\n","I0908 16:04:10.673310 140650862335872 learning.py:512] global step 2820: loss = 1.7227 (0.763 sec/step)\n","INFO:tensorflow:global step 2821: loss = 2.1985 (0.776 sec/step)\n","I0908 16:04:11.451283 140650862335872 learning.py:512] global step 2821: loss = 2.1985 (0.776 sec/step)\n","INFO:tensorflow:global step 2822: loss = 1.7521 (0.758 sec/step)\n","I0908 16:04:12.211508 140650862335872 learning.py:512] global step 2822: loss = 1.7521 (0.758 sec/step)\n","INFO:tensorflow:global step 2823: loss = 2.4182 (0.773 sec/step)\n","I0908 16:04:12.986044 140650862335872 learning.py:512] global step 2823: loss = 2.4182 (0.773 sec/step)\n","INFO:tensorflow:global step 2824: loss = 2.0893 (0.775 sec/step)\n","I0908 16:04:13.762830 140650862335872 learning.py:512] global step 2824: loss = 2.0893 (0.775 sec/step)\n","INFO:tensorflow:global step 2825: loss = 1.9830 (0.758 sec/step)\n","I0908 16:04:14.522947 140650862335872 learning.py:512] global step 2825: loss = 1.9830 (0.758 sec/step)\n","INFO:tensorflow:global step 2826: loss = 2.0884 (0.769 sec/step)\n","I0908 16:04:15.293831 140650862335872 learning.py:512] global step 2826: loss = 2.0884 (0.769 sec/step)\n","INFO:tensorflow:global step 2827: loss = 2.5253 (0.754 sec/step)\n","I0908 16:04:16.050548 140650862335872 learning.py:512] global step 2827: loss = 2.5253 (0.754 sec/step)\n","INFO:tensorflow:global step 2828: loss = 2.3112 (0.761 sec/step)\n","I0908 16:04:16.812877 140650862335872 learning.py:512] global step 2828: loss = 2.3112 (0.761 sec/step)\n","INFO:tensorflow:global step 2829: loss = 2.2182 (0.773 sec/step)\n","I0908 16:04:17.587341 140650862335872 learning.py:512] global step 2829: loss = 2.2182 (0.773 sec/step)\n","INFO:tensorflow:global step 2830: loss = 2.0560 (0.758 sec/step)\n","I0908 16:04:18.346943 140650862335872 learning.py:512] global step 2830: loss = 2.0560 (0.758 sec/step)\n","INFO:tensorflow:global step 2831: loss = 1.9678 (0.765 sec/step)\n","I0908 16:04:19.113842 140650862335872 learning.py:512] global step 2831: loss = 1.9678 (0.765 sec/step)\n","INFO:tensorflow:global step 2832: loss = 2.2997 (0.773 sec/step)\n","I0908 16:04:19.888140 140650862335872 learning.py:512] global step 2832: loss = 2.2997 (0.773 sec/step)\n","INFO:tensorflow:global step 2833: loss = 2.0938 (0.755 sec/step)\n","I0908 16:04:20.645226 140650862335872 learning.py:512] global step 2833: loss = 2.0938 (0.755 sec/step)\n","INFO:tensorflow:global step 2834: loss = 2.3027 (0.755 sec/step)\n","I0908 16:04:21.402151 140650862335872 learning.py:512] global step 2834: loss = 2.3027 (0.755 sec/step)\n","INFO:tensorflow:global step 2835: loss = 1.8828 (0.773 sec/step)\n","I0908 16:04:22.176855 140650862335872 learning.py:512] global step 2835: loss = 1.8828 (0.773 sec/step)\n","INFO:tensorflow:global step 2836: loss = 2.1292 (0.766 sec/step)\n","I0908 16:04:22.944480 140650862335872 learning.py:512] global step 2836: loss = 2.1292 (0.766 sec/step)\n","INFO:tensorflow:global step 2837: loss = 2.2429 (0.748 sec/step)\n","I0908 16:04:23.693588 140650862335872 learning.py:512] global step 2837: loss = 2.2429 (0.748 sec/step)\n","INFO:tensorflow:global step 2838: loss = 1.8608 (0.765 sec/step)\n","I0908 16:04:24.460753 140650862335872 learning.py:512] global step 2838: loss = 1.8608 (0.765 sec/step)\n","INFO:tensorflow:global step 2839: loss = 2.6445 (0.753 sec/step)\n","I0908 16:04:25.215706 140650862335872 learning.py:512] global step 2839: loss = 2.6445 (0.753 sec/step)\n","INFO:tensorflow:global step 2840: loss = 2.3886 (0.756 sec/step)\n","I0908 16:04:25.973742 140650862335872 learning.py:512] global step 2840: loss = 2.3886 (0.756 sec/step)\n","INFO:tensorflow:global step 2841: loss = 1.5694 (0.768 sec/step)\n","I0908 16:04:26.743847 140650862335872 learning.py:512] global step 2841: loss = 1.5694 (0.768 sec/step)\n","INFO:tensorflow:global step 2842: loss = 2.2948 (0.768 sec/step)\n","I0908 16:04:27.513406 140650862335872 learning.py:512] global step 2842: loss = 2.2948 (0.768 sec/step)\n","INFO:tensorflow:global step 2843: loss = 2.0786 (0.772 sec/step)\n","I0908 16:04:28.287636 140650862335872 learning.py:512] global step 2843: loss = 2.0786 (0.772 sec/step)\n","INFO:tensorflow:global step 2844: loss = 1.9139 (0.765 sec/step)\n","I0908 16:04:29.054105 140650862335872 learning.py:512] global step 2844: loss = 1.9139 (0.765 sec/step)\n","INFO:tensorflow:global step 2845: loss = 2.0537 (0.741 sec/step)\n","I0908 16:04:29.796905 140650862335872 learning.py:512] global step 2845: loss = 2.0537 (0.741 sec/step)\n","INFO:tensorflow:global step 2846: loss = 2.0550 (0.764 sec/step)\n","I0908 16:04:30.562587 140650862335872 learning.py:512] global step 2846: loss = 2.0550 (0.764 sec/step)\n","INFO:tensorflow:global step 2847: loss = 2.2234 (0.767 sec/step)\n","I0908 16:04:31.331788 140650862335872 learning.py:512] global step 2847: loss = 2.2234 (0.767 sec/step)\n","INFO:tensorflow:global step 2848: loss = 1.9780 (0.765 sec/step)\n","I0908 16:04:32.098473 140650862335872 learning.py:512] global step 2848: loss = 1.9780 (0.765 sec/step)\n","INFO:tensorflow:global step 2849: loss = 1.7694 (0.775 sec/step)\n","I0908 16:04:32.875671 140650862335872 learning.py:512] global step 2849: loss = 1.7694 (0.775 sec/step)\n","INFO:tensorflow:global step 2850: loss = 2.2423 (0.768 sec/step)\n","I0908 16:04:33.644862 140650862335872 learning.py:512] global step 2850: loss = 2.2423 (0.768 sec/step)\n","INFO:tensorflow:global step 2851: loss = 2.7917 (0.761 sec/step)\n","I0908 16:04:34.407460 140650862335872 learning.py:512] global step 2851: loss = 2.7917 (0.761 sec/step)\n","INFO:tensorflow:global step 2852: loss = 2.4223 (0.748 sec/step)\n","I0908 16:04:35.157495 140650862335872 learning.py:512] global step 2852: loss = 2.4223 (0.748 sec/step)\n","INFO:tensorflow:global step 2853: loss = 1.8187 (0.750 sec/step)\n","I0908 16:04:35.908937 140650862335872 learning.py:512] global step 2853: loss = 1.8187 (0.750 sec/step)\n","INFO:tensorflow:global step 2854: loss = 2.2778 (0.777 sec/step)\n","I0908 16:04:36.687954 140650862335872 learning.py:512] global step 2854: loss = 2.2778 (0.777 sec/step)\n","INFO:tensorflow:global step 2855: loss = 2.5151 (0.775 sec/step)\n","I0908 16:04:37.464411 140650862335872 learning.py:512] global step 2855: loss = 2.5151 (0.775 sec/step)\n","INFO:tensorflow:global step 2856: loss = 2.0254 (0.743 sec/step)\n","I0908 16:04:38.209403 140650862335872 learning.py:512] global step 2856: loss = 2.0254 (0.743 sec/step)\n","INFO:tensorflow:global step 2857: loss = 2.3032 (0.767 sec/step)\n","I0908 16:04:38.977552 140650862335872 learning.py:512] global step 2857: loss = 2.3032 (0.767 sec/step)\n","INFO:tensorflow:global step 2858: loss = 2.4550 (0.767 sec/step)\n","I0908 16:04:39.746241 140650862335872 learning.py:512] global step 2858: loss = 2.4550 (0.767 sec/step)\n","INFO:tensorflow:global step 2859: loss = 2.2458 (0.745 sec/step)\n","I0908 16:04:40.492900 140650862335872 learning.py:512] global step 2859: loss = 2.2458 (0.745 sec/step)\n","INFO:tensorflow:global step 2860: loss = 2.1775 (0.746 sec/step)\n","I0908 16:04:41.241063 140650862335872 learning.py:512] global step 2860: loss = 2.1775 (0.746 sec/step)\n","INFO:tensorflow:global step 2861: loss = 1.9674 (0.781 sec/step)\n","I0908 16:04:42.023773 140650862335872 learning.py:512] global step 2861: loss = 1.9674 (0.781 sec/step)\n","INFO:tensorflow:global step 2862: loss = 2.3466 (0.775 sec/step)\n","I0908 16:04:42.800437 140650862335872 learning.py:512] global step 2862: loss = 2.3466 (0.775 sec/step)\n","INFO:tensorflow:global step 2863: loss = 2.2551 (0.738 sec/step)\n","I0908 16:04:43.540191 140650862335872 learning.py:512] global step 2863: loss = 2.2551 (0.738 sec/step)\n","INFO:tensorflow:global step 2864: loss = 2.0170 (0.742 sec/step)\n","I0908 16:04:44.284480 140650862335872 learning.py:512] global step 2864: loss = 2.0170 (0.742 sec/step)\n","INFO:tensorflow:global step 2865: loss = 2.3165 (0.776 sec/step)\n","I0908 16:04:45.062988 140650862335872 learning.py:512] global step 2865: loss = 2.3165 (0.776 sec/step)\n","INFO:tensorflow:global step 2866: loss = 1.9726 (0.770 sec/step)\n","I0908 16:04:45.834676 140650862335872 learning.py:512] global step 2866: loss = 1.9726 (0.770 sec/step)\n","INFO:tensorflow:global step 2867: loss = 2.3660 (0.758 sec/step)\n","I0908 16:04:46.594646 140650862335872 learning.py:512] global step 2867: loss = 2.3660 (0.758 sec/step)\n","INFO:tensorflow:global step 2868: loss = 2.1061 (0.769 sec/step)\n","I0908 16:04:47.366799 140650862335872 learning.py:512] global step 2868: loss = 2.1061 (0.769 sec/step)\n","INFO:tensorflow:global step 2869: loss = 2.1419 (0.752 sec/step)\n","I0908 16:04:48.120938 140650862335872 learning.py:512] global step 2869: loss = 2.1419 (0.752 sec/step)\n","INFO:tensorflow:global step 2870: loss = 2.4552 (0.758 sec/step)\n","I0908 16:04:48.881500 140650862335872 learning.py:512] global step 2870: loss = 2.4552 (0.758 sec/step)\n","INFO:tensorflow:global step 2871: loss = 2.0332 (0.761 sec/step)\n","I0908 16:04:49.644528 140650862335872 learning.py:512] global step 2871: loss = 2.0332 (0.761 sec/step)\n","INFO:tensorflow:global step 2872: loss = 2.7536 (0.776 sec/step)\n","I0908 16:04:50.422492 140650862335872 learning.py:512] global step 2872: loss = 2.7536 (0.776 sec/step)\n","INFO:tensorflow:global step 2873: loss = 2.3611 (0.767 sec/step)\n","I0908 16:04:51.191291 140650862335872 learning.py:512] global step 2873: loss = 2.3611 (0.767 sec/step)\n","INFO:tensorflow:global step 2874: loss = 2.2020 (0.770 sec/step)\n","I0908 16:04:51.964010 140650862335872 learning.py:512] global step 2874: loss = 2.2020 (0.770 sec/step)\n","INFO:tensorflow:global step 2875: loss = 2.1369 (0.753 sec/step)\n","I0908 16:04:52.718782 140650862335872 learning.py:512] global step 2875: loss = 2.1369 (0.753 sec/step)\n","INFO:tensorflow:global step 2876: loss = 1.5961 (0.767 sec/step)\n","I0908 16:04:53.488267 140650862335872 learning.py:512] global step 2876: loss = 1.5961 (0.767 sec/step)\n","INFO:tensorflow:global step 2877: loss = 2.2180 (0.779 sec/step)\n","I0908 16:04:54.269399 140650862335872 learning.py:512] global step 2877: loss = 2.2180 (0.779 sec/step)\n","INFO:tensorflow:global step 2878: loss = 2.0698 (0.756 sec/step)\n","I0908 16:04:55.026575 140650862335872 learning.py:512] global step 2878: loss = 2.0698 (0.756 sec/step)\n","INFO:tensorflow:global step 2879: loss = 1.9811 (0.748 sec/step)\n","I0908 16:04:55.776470 140650862335872 learning.py:512] global step 2879: loss = 1.9811 (0.748 sec/step)\n","INFO:tensorflow:global step 2880: loss = 2.1757 (0.772 sec/step)\n","I0908 16:04:56.550471 140650862335872 learning.py:512] global step 2880: loss = 2.1757 (0.772 sec/step)\n","INFO:tensorflow:global step 2881: loss = 2.7208 (0.793 sec/step)\n","I0908 16:04:57.345240 140650862335872 learning.py:512] global step 2881: loss = 2.7208 (0.793 sec/step)\n","INFO:tensorflow:global step 2882: loss = 2.0155 (0.766 sec/step)\n","I0908 16:04:58.112604 140650862335872 learning.py:512] global step 2882: loss = 2.0155 (0.766 sec/step)\n","INFO:tensorflow:global step 2883: loss = 2.1979 (0.783 sec/step)\n","I0908 16:04:58.897338 140650862335872 learning.py:512] global step 2883: loss = 2.1979 (0.783 sec/step)\n","INFO:tensorflow:global step 2884: loss = 2.0760 (0.767 sec/step)\n","I0908 16:04:59.665987 140650862335872 learning.py:512] global step 2884: loss = 2.0760 (0.767 sec/step)\n","INFO:tensorflow:global step 2885: loss = 2.2316 (0.771 sec/step)\n","I0908 16:05:00.438341 140650862335872 learning.py:512] global step 2885: loss = 2.2316 (0.771 sec/step)\n","INFO:tensorflow:global step 2886: loss = 2.3065 (0.760 sec/step)\n","I0908 16:05:01.200226 140650862335872 learning.py:512] global step 2886: loss = 2.3065 (0.760 sec/step)\n","INFO:tensorflow:global step 2887: loss = 2.3082 (0.753 sec/step)\n","I0908 16:05:01.955279 140650862335872 learning.py:512] global step 2887: loss = 2.3082 (0.753 sec/step)\n","INFO:tensorflow:global step 2888: loss = 2.2872 (0.760 sec/step)\n","I0908 16:05:02.716640 140650862335872 learning.py:512] global step 2888: loss = 2.2872 (0.760 sec/step)\n","INFO:tensorflow:global step 2889: loss = 2.0674 (0.756 sec/step)\n","I0908 16:05:03.474601 140650862335872 learning.py:512] global step 2889: loss = 2.0674 (0.756 sec/step)\n","INFO:tensorflow:global step 2890: loss = 2.1382 (0.755 sec/step)\n","I0908 16:05:04.232304 140650862335872 learning.py:512] global step 2890: loss = 2.1382 (0.755 sec/step)\n","INFO:tensorflow:global step 2891: loss = 2.3377 (0.739 sec/step)\n","I0908 16:05:04.972845 140650862335872 learning.py:512] global step 2891: loss = 2.3377 (0.739 sec/step)\n","INFO:tensorflow:global step 2892: loss = 2.4042 (0.739 sec/step)\n","I0908 16:05:05.713302 140650862335872 learning.py:512] global step 2892: loss = 2.4042 (0.739 sec/step)\n","INFO:tensorflow:global step 2893: loss = 1.7472 (0.758 sec/step)\n","I0908 16:05:06.472734 140650862335872 learning.py:512] global step 2893: loss = 1.7472 (0.758 sec/step)\n","INFO:tensorflow:global step 2894: loss = 2.0786 (0.760 sec/step)\n","I0908 16:05:07.234510 140650862335872 learning.py:512] global step 2894: loss = 2.0786 (0.760 sec/step)\n","INFO:tensorflow:global step 2895: loss = 2.6059 (0.775 sec/step)\n","I0908 16:05:08.011668 140650862335872 learning.py:512] global step 2895: loss = 2.6059 (0.775 sec/step)\n","INFO:tensorflow:global step 2896: loss = 1.7699 (0.759 sec/step)\n","I0908 16:05:08.771870 140650862335872 learning.py:512] global step 2896: loss = 1.7699 (0.759 sec/step)\n","INFO:tensorflow:global step 2897: loss = 2.3641 (0.775 sec/step)\n","I0908 16:05:09.548149 140650862335872 learning.py:512] global step 2897: loss = 2.3641 (0.775 sec/step)\n","INFO:tensorflow:global step 2898: loss = 2.3852 (0.756 sec/step)\n","I0908 16:05:10.306065 140650862335872 learning.py:512] global step 2898: loss = 2.3852 (0.756 sec/step)\n","INFO:tensorflow:global step 2899: loss = 2.1020 (0.758 sec/step)\n","I0908 16:05:11.065836 140650862335872 learning.py:512] global step 2899: loss = 2.1020 (0.758 sec/step)\n","INFO:tensorflow:global step 2900: loss = 1.9752 (0.746 sec/step)\n","I0908 16:05:11.814070 140650862335872 learning.py:512] global step 2900: loss = 1.9752 (0.746 sec/step)\n","INFO:tensorflow:global step 2901: loss = 2.5965 (0.750 sec/step)\n","I0908 16:05:12.565705 140650862335872 learning.py:512] global step 2901: loss = 2.5965 (0.750 sec/step)\n","INFO:tensorflow:global step 2902: loss = 2.4234 (0.761 sec/step)\n","I0908 16:05:13.328255 140650862335872 learning.py:512] global step 2902: loss = 2.4234 (0.761 sec/step)\n","INFO:tensorflow:global step 2903: loss = 2.3504 (0.765 sec/step)\n","I0908 16:05:14.094449 140650862335872 learning.py:512] global step 2903: loss = 2.3504 (0.765 sec/step)\n","INFO:tensorflow:global step 2904: loss = 2.4703 (0.747 sec/step)\n","I0908 16:05:14.843523 140650862335872 learning.py:512] global step 2904: loss = 2.4703 (0.747 sec/step)\n","INFO:tensorflow:global step 2905: loss = 2.2889 (0.751 sec/step)\n","I0908 16:05:15.596553 140650862335872 learning.py:512] global step 2905: loss = 2.2889 (0.751 sec/step)\n","INFO:tensorflow:global step 2906: loss = 2.3291 (0.744 sec/step)\n","I0908 16:05:16.344344 140650862335872 learning.py:512] global step 2906: loss = 2.3291 (0.744 sec/step)\n","INFO:tensorflow:global step 2907: loss = 2.4587 (0.764 sec/step)\n","I0908 16:05:17.110107 140650862335872 learning.py:512] global step 2907: loss = 2.4587 (0.764 sec/step)\n","INFO:tensorflow:global step 2908: loss = 2.3880 (0.754 sec/step)\n","I0908 16:05:17.866021 140650862335872 learning.py:512] global step 2908: loss = 2.3880 (0.754 sec/step)\n","INFO:tensorflow:global step 2909: loss = 2.1270 (0.756 sec/step)\n","I0908 16:05:18.623734 140650862335872 learning.py:512] global step 2909: loss = 2.1270 (0.756 sec/step)\n","INFO:tensorflow:global step 2910: loss = 2.5083 (0.754 sec/step)\n","I0908 16:05:19.379143 140650862335872 learning.py:512] global step 2910: loss = 2.5083 (0.754 sec/step)\n","INFO:tensorflow:global step 2911: loss = 2.0483 (0.760 sec/step)\n","I0908 16:05:20.140481 140650862335872 learning.py:512] global step 2911: loss = 2.0483 (0.760 sec/step)\n","INFO:tensorflow:global step 2912: loss = 2.1020 (0.747 sec/step)\n","I0908 16:05:20.889058 140650862335872 learning.py:512] global step 2912: loss = 2.1020 (0.747 sec/step)\n","INFO:tensorflow:global step 2913: loss = 2.2743 (0.759 sec/step)\n","I0908 16:05:21.649801 140650862335872 learning.py:512] global step 2913: loss = 2.2743 (0.759 sec/step)\n","INFO:tensorflow:global step 2914: loss = 2.1944 (0.749 sec/step)\n","I0908 16:05:22.400753 140650862335872 learning.py:512] global step 2914: loss = 2.1944 (0.749 sec/step)\n","INFO:tensorflow:global step 2915: loss = 2.4788 (0.755 sec/step)\n","I0908 16:05:23.156970 140650862335872 learning.py:512] global step 2915: loss = 2.4788 (0.755 sec/step)\n","INFO:tensorflow:global step 2916: loss = 1.9695 (0.755 sec/step)\n","I0908 16:05:23.913932 140650862335872 learning.py:512] global step 2916: loss = 1.9695 (0.755 sec/step)\n","INFO:tensorflow:global step 2917: loss = 2.1839 (0.765 sec/step)\n","I0908 16:05:24.680320 140650862335872 learning.py:512] global step 2917: loss = 2.1839 (0.765 sec/step)\n","INFO:tensorflow:global step 2918: loss = 2.1011 (0.748 sec/step)\n","I0908 16:05:25.430076 140650862335872 learning.py:512] global step 2918: loss = 2.1011 (0.748 sec/step)\n","INFO:tensorflow:global step 2919: loss = 2.5237 (0.745 sec/step)\n","I0908 16:05:26.176928 140650862335872 learning.py:512] global step 2919: loss = 2.5237 (0.745 sec/step)\n","INFO:tensorflow:global step 2920: loss = 1.9951 (0.751 sec/step)\n","I0908 16:05:26.929889 140650862335872 learning.py:512] global step 2920: loss = 1.9951 (0.751 sec/step)\n","INFO:tensorflow:global step 2921: loss = 2.2672 (0.750 sec/step)\n","I0908 16:05:27.681400 140650862335872 learning.py:512] global step 2921: loss = 2.2672 (0.750 sec/step)\n","INFO:tensorflow:global step 2922: loss = 2.2531 (0.767 sec/step)\n","I0908 16:05:28.450689 140650862335872 learning.py:512] global step 2922: loss = 2.2531 (0.767 sec/step)\n","INFO:tensorflow:global step 2923: loss = 2.0454 (0.759 sec/step)\n","I0908 16:05:29.212002 140650862335872 learning.py:512] global step 2923: loss = 2.0454 (0.759 sec/step)\n","INFO:tensorflow:global step 2924: loss = 2.4213 (0.770 sec/step)\n","I0908 16:05:29.983979 140650862335872 learning.py:512] global step 2924: loss = 2.4213 (0.770 sec/step)\n","INFO:tensorflow:global step 2925: loss = 1.9876 (0.772 sec/step)\n","I0908 16:05:30.757874 140650862335872 learning.py:512] global step 2925: loss = 1.9876 (0.772 sec/step)\n","INFO:tensorflow:global step 2926: loss = 2.4930 (0.765 sec/step)\n","I0908 16:05:31.524471 140650862335872 learning.py:512] global step 2926: loss = 2.4930 (0.765 sec/step)\n","INFO:tensorflow:global step 2927: loss = 2.4857 (0.751 sec/step)\n","I0908 16:05:32.277492 140650862335872 learning.py:512] global step 2927: loss = 2.4857 (0.751 sec/step)\n","INFO:tensorflow:global step 2928: loss = 2.4214 (0.752 sec/step)\n","I0908 16:05:33.031476 140650862335872 learning.py:512] global step 2928: loss = 2.4214 (0.752 sec/step)\n","INFO:tensorflow:global step 2929: loss = 2.4752 (0.746 sec/step)\n","I0908 16:05:33.778869 140650862335872 learning.py:512] global step 2929: loss = 2.4752 (0.746 sec/step)\n","INFO:tensorflow:global step 2930: loss = 1.9165 (0.755 sec/step)\n","I0908 16:05:34.535959 140650862335872 learning.py:512] global step 2930: loss = 1.9165 (0.755 sec/step)\n","INFO:tensorflow:global step 2931: loss = 2.4062 (0.751 sec/step)\n","I0908 16:05:35.289140 140650862335872 learning.py:512] global step 2931: loss = 2.4062 (0.751 sec/step)\n","INFO:tensorflow:global step 2932: loss = 2.1205 (0.775 sec/step)\n","I0908 16:05:36.066198 140650862335872 learning.py:512] global step 2932: loss = 2.1205 (0.775 sec/step)\n","INFO:tensorflow:global step 2933: loss = 2.3955 (0.768 sec/step)\n","I0908 16:05:36.836028 140650862335872 learning.py:512] global step 2933: loss = 2.3955 (0.768 sec/step)\n","INFO:tensorflow:global step 2934: loss = 2.1753 (0.752 sec/step)\n","I0908 16:05:37.589347 140650862335872 learning.py:512] global step 2934: loss = 2.1753 (0.752 sec/step)\n","INFO:tensorflow:global step 2935: loss = 2.5452 (0.769 sec/step)\n","I0908 16:05:38.360035 140650862335872 learning.py:512] global step 2935: loss = 2.5452 (0.769 sec/step)\n","INFO:tensorflow:global step 2936: loss = 1.7562 (0.769 sec/step)\n","I0908 16:05:39.130554 140650862335872 learning.py:512] global step 2936: loss = 1.7562 (0.769 sec/step)\n","INFO:tensorflow:global step 2937: loss = 1.9091 (0.752 sec/step)\n","I0908 16:05:39.884233 140650862335872 learning.py:512] global step 2937: loss = 1.9091 (0.752 sec/step)\n","INFO:tensorflow:global step 2938: loss = 2.1075 (0.769 sec/step)\n","I0908 16:05:40.655529 140650862335872 learning.py:512] global step 2938: loss = 2.1075 (0.769 sec/step)\n","INFO:tensorflow:global step 2939: loss = 1.7139 (0.740 sec/step)\n","I0908 16:05:41.397403 140650862335872 learning.py:512] global step 2939: loss = 1.7139 (0.740 sec/step)\n","INFO:tensorflow:global step 2940: loss = 1.9990 (0.766 sec/step)\n","I0908 16:05:42.164695 140650862335872 learning.py:512] global step 2940: loss = 1.9990 (0.766 sec/step)\n","INFO:tensorflow:global step 2941: loss = 2.0202 (0.738 sec/step)\n","I0908 16:05:42.904821 140650862335872 learning.py:512] global step 2941: loss = 2.0202 (0.738 sec/step)\n","INFO:tensorflow:global step 2942: loss = 1.8221 (0.758 sec/step)\n","I0908 16:05:43.663955 140650862335872 learning.py:512] global step 2942: loss = 1.8221 (0.758 sec/step)\n","INFO:tensorflow:global step 2943: loss = 2.0897 (0.747 sec/step)\n","I0908 16:05:44.412265 140650862335872 learning.py:512] global step 2943: loss = 2.0897 (0.747 sec/step)\n","INFO:tensorflow:global step 2944: loss = 1.9187 (0.772 sec/step)\n","I0908 16:05:45.186139 140650862335872 learning.py:512] global step 2944: loss = 1.9187 (0.772 sec/step)\n","INFO:tensorflow:global step 2945: loss = 2.1219 (0.748 sec/step)\n","I0908 16:05:45.935957 140650862335872 learning.py:512] global step 2945: loss = 2.1219 (0.748 sec/step)\n","INFO:tensorflow:global step 2946: loss = 2.0530 (0.832 sec/step)\n","I0908 16:05:46.769768 140650862335872 learning.py:512] global step 2946: loss = 2.0530 (0.832 sec/step)\n","INFO:tensorflow:Recording summary at step 2946.\n","I0908 16:05:47.774845 140646941251328 supervisor.py:1050] Recording summary at step 2946.\n","INFO:tensorflow:global step 2947: loss = 2.4708 (1.205 sec/step)\n","I0908 16:05:47.986517 140650862335872 learning.py:512] global step 2947: loss = 2.4708 (1.205 sec/step)\n","INFO:tensorflow:global step 2948: loss = 1.8877 (0.752 sec/step)\n","I0908 16:05:48.740282 140650862335872 learning.py:512] global step 2948: loss = 1.8877 (0.752 sec/step)\n","INFO:tensorflow:global step 2949: loss = 2.2488 (0.741 sec/step)\n","I0908 16:05:49.482308 140650862335872 learning.py:512] global step 2949: loss = 2.2488 (0.741 sec/step)\n","INFO:tensorflow:global step 2950: loss = 2.3575 (0.770 sec/step)\n","I0908 16:05:50.254225 140650862335872 learning.py:512] global step 2950: loss = 2.3575 (0.770 sec/step)\n","INFO:tensorflow:global step 2951: loss = 2.5654 (0.756 sec/step)\n","I0908 16:05:51.011992 140650862335872 learning.py:512] global step 2951: loss = 2.5654 (0.756 sec/step)\n","INFO:tensorflow:global step 2952: loss = 2.3935 (0.738 sec/step)\n","I0908 16:05:51.752317 140650862335872 learning.py:512] global step 2952: loss = 2.3935 (0.738 sec/step)\n","INFO:tensorflow:global step 2953: loss = 2.9136 (0.787 sec/step)\n","I0908 16:05:52.540648 140650862335872 learning.py:512] global step 2953: loss = 2.9136 (0.787 sec/step)\n","INFO:tensorflow:global step 2954: loss = 2.0432 (0.761 sec/step)\n","I0908 16:05:53.303546 140650862335872 learning.py:512] global step 2954: loss = 2.0432 (0.761 sec/step)\n","INFO:tensorflow:global step 2955: loss = 2.3674 (0.744 sec/step)\n","I0908 16:05:54.049226 140650862335872 learning.py:512] global step 2955: loss = 2.3674 (0.744 sec/step)\n","INFO:tensorflow:global step 2956: loss = 2.2437 (0.743 sec/step)\n","I0908 16:05:54.793929 140650862335872 learning.py:512] global step 2956: loss = 2.2437 (0.743 sec/step)\n","INFO:tensorflow:global step 2957: loss = 2.1768 (0.778 sec/step)\n","I0908 16:05:55.573449 140650862335872 learning.py:512] global step 2957: loss = 2.1768 (0.778 sec/step)\n","INFO:tensorflow:global step 2958: loss = 2.2751 (0.753 sec/step)\n","I0908 16:05:56.327869 140650862335872 learning.py:512] global step 2958: loss = 2.2751 (0.753 sec/step)\n","INFO:tensorflow:global step 2959: loss = 2.1062 (0.760 sec/step)\n","I0908 16:05:57.090244 140650862335872 learning.py:512] global step 2959: loss = 2.1062 (0.760 sec/step)\n","INFO:tensorflow:global step 2960: loss = 2.0023 (0.742 sec/step)\n","I0908 16:05:57.833896 140650862335872 learning.py:512] global step 2960: loss = 2.0023 (0.742 sec/step)\n","INFO:tensorflow:global step 2961: loss = 1.8909 (0.776 sec/step)\n","I0908 16:05:58.611128 140650862335872 learning.py:512] global step 2961: loss = 1.8909 (0.776 sec/step)\n","INFO:tensorflow:global step 2962: loss = 2.6440 (0.767 sec/step)\n","I0908 16:05:59.380210 140650862335872 learning.py:512] global step 2962: loss = 2.6440 (0.767 sec/step)\n","INFO:tensorflow:global step 2963: loss = 2.3160 (0.769 sec/step)\n","I0908 16:06:00.151159 140650862335872 learning.py:512] global step 2963: loss = 2.3160 (0.769 sec/step)\n","INFO:tensorflow:global step 2964: loss = 2.4870 (0.771 sec/step)\n","I0908 16:06:00.923321 140650862335872 learning.py:512] global step 2964: loss = 2.4870 (0.771 sec/step)\n","INFO:tensorflow:global step 2965: loss = 1.8293 (0.761 sec/step)\n","I0908 16:06:01.685701 140650862335872 learning.py:512] global step 2965: loss = 1.8293 (0.761 sec/step)\n","INFO:tensorflow:global step 2966: loss = 2.3903 (0.765 sec/step)\n","I0908 16:06:02.452157 140650862335872 learning.py:512] global step 2966: loss = 2.3903 (0.765 sec/step)\n","INFO:tensorflow:global step 2967: loss = 1.8479 (0.754 sec/step)\n","I0908 16:06:03.208343 140650862335872 learning.py:512] global step 2967: loss = 1.8479 (0.754 sec/step)\n","INFO:tensorflow:global step 2968: loss = 2.0000 (0.770 sec/step)\n","I0908 16:06:03.980137 140650862335872 learning.py:512] global step 2968: loss = 2.0000 (0.770 sec/step)\n","INFO:tensorflow:global step 2969: loss = 1.8513 (0.752 sec/step)\n","I0908 16:06:04.734074 140650862335872 learning.py:512] global step 2969: loss = 1.8513 (0.752 sec/step)\n","INFO:tensorflow:global step 2970: loss = 2.1811 (0.733 sec/step)\n","I0908 16:06:05.468546 140650862335872 learning.py:512] global step 2970: loss = 2.1811 (0.733 sec/step)\n","INFO:tensorflow:global step 2971: loss = 1.9333 (0.756 sec/step)\n","I0908 16:06:06.226648 140650862335872 learning.py:512] global step 2971: loss = 1.9333 (0.756 sec/step)\n","INFO:tensorflow:global step 2972: loss = 2.1806 (0.765 sec/step)\n","I0908 16:06:06.993498 140650862335872 learning.py:512] global step 2972: loss = 2.1806 (0.765 sec/step)\n","INFO:tensorflow:global step 2973: loss = 2.2749 (0.782 sec/step)\n","I0908 16:06:07.777273 140650862335872 learning.py:512] global step 2973: loss = 2.2749 (0.782 sec/step)\n","INFO:tensorflow:global step 2974: loss = 2.2301 (0.743 sec/step)\n","I0908 16:06:08.522320 140650862335872 learning.py:512] global step 2974: loss = 2.2301 (0.743 sec/step)\n","INFO:tensorflow:global step 2975: loss = 2.2114 (0.749 sec/step)\n","I0908 16:06:09.272855 140650862335872 learning.py:512] global step 2975: loss = 2.2114 (0.749 sec/step)\n","INFO:tensorflow:global step 2976: loss = 2.3539 (0.769 sec/step)\n","I0908 16:06:10.043137 140650862335872 learning.py:512] global step 2976: loss = 2.3539 (0.769 sec/step)\n","INFO:tensorflow:global step 2977: loss = 2.1474 (0.774 sec/step)\n","I0908 16:06:10.818335 140650862335872 learning.py:512] global step 2977: loss = 2.1474 (0.774 sec/step)\n","INFO:tensorflow:global step 2978: loss = 2.3773 (0.761 sec/step)\n","I0908 16:06:11.580867 140650862335872 learning.py:512] global step 2978: loss = 2.3773 (0.761 sec/step)\n","INFO:tensorflow:global step 2979: loss = 2.1777 (0.764 sec/step)\n","I0908 16:06:12.345952 140650862335872 learning.py:512] global step 2979: loss = 2.1777 (0.764 sec/step)\n","INFO:tensorflow:global step 2980: loss = 1.8253 (0.770 sec/step)\n","I0908 16:06:13.117525 140650862335872 learning.py:512] global step 2980: loss = 1.8253 (0.770 sec/step)\n","INFO:tensorflow:global step 2981: loss = 1.9997 (0.769 sec/step)\n","I0908 16:06:13.888583 140650862335872 learning.py:512] global step 2981: loss = 1.9997 (0.769 sec/step)\n","INFO:tensorflow:global step 2982: loss = 1.9246 (0.760 sec/step)\n","I0908 16:06:14.650019 140650862335872 learning.py:512] global step 2982: loss = 1.9246 (0.760 sec/step)\n","INFO:tensorflow:global step 2983: loss = 2.3619 (0.757 sec/step)\n","I0908 16:06:15.408926 140650862335872 learning.py:512] global step 2983: loss = 2.3619 (0.757 sec/step)\n","INFO:tensorflow:global step 2984: loss = 2.1562 (0.764 sec/step)\n","I0908 16:06:16.174445 140650862335872 learning.py:512] global step 2984: loss = 2.1562 (0.764 sec/step)\n","INFO:tensorflow:global step 2985: loss = 1.6103 (0.759 sec/step)\n","I0908 16:06:16.935555 140650862335872 learning.py:512] global step 2985: loss = 1.6103 (0.759 sec/step)\n","INFO:tensorflow:global step 2986: loss = 3.1230 (0.742 sec/step)\n","I0908 16:06:17.678793 140650862335872 learning.py:512] global step 2986: loss = 3.1230 (0.742 sec/step)\n","INFO:tensorflow:global step 2987: loss = 1.9136 (0.757 sec/step)\n","I0908 16:06:18.437513 140650862335872 learning.py:512] global step 2987: loss = 1.9136 (0.757 sec/step)\n","INFO:tensorflow:global step 2988: loss = 2.3523 (0.749 sec/step)\n","I0908 16:06:19.188423 140650862335872 learning.py:512] global step 2988: loss = 2.3523 (0.749 sec/step)\n","INFO:tensorflow:global step 2989: loss = 2.0858 (0.748 sec/step)\n","I0908 16:06:19.938195 140650862335872 learning.py:512] global step 2989: loss = 2.0858 (0.748 sec/step)\n","INFO:tensorflow:global step 2990: loss = 2.3249 (0.759 sec/step)\n","I0908 16:06:20.698762 140650862335872 learning.py:512] global step 2990: loss = 2.3249 (0.759 sec/step)\n","INFO:tensorflow:global step 2991: loss = 1.9315 (0.762 sec/step)\n","I0908 16:06:21.462795 140650862335872 learning.py:512] global step 2991: loss = 1.9315 (0.762 sec/step)\n","INFO:tensorflow:global step 2992: loss = 2.0442 (0.758 sec/step)\n","I0908 16:06:22.222639 140650862335872 learning.py:512] global step 2992: loss = 2.0442 (0.758 sec/step)\n","INFO:tensorflow:global step 2993: loss = 1.9564 (0.763 sec/step)\n","I0908 16:06:22.987551 140650862335872 learning.py:512] global step 2993: loss = 1.9564 (0.763 sec/step)\n","INFO:tensorflow:global step 2994: loss = 1.8410 (0.775 sec/step)\n","I0908 16:06:23.764367 140650862335872 learning.py:512] global step 2994: loss = 1.8410 (0.775 sec/step)\n","INFO:tensorflow:global step 2995: loss = 2.2321 (0.771 sec/step)\n","I0908 16:06:24.536471 140650862335872 learning.py:512] global step 2995: loss = 2.2321 (0.771 sec/step)\n","INFO:tensorflow:global step 2996: loss = 1.9705 (0.772 sec/step)\n","I0908 16:06:25.309995 140650862335872 learning.py:512] global step 2996: loss = 1.9705 (0.772 sec/step)\n","INFO:tensorflow:global step 2997: loss = 2.1672 (0.757 sec/step)\n","I0908 16:06:26.068414 140650862335872 learning.py:512] global step 2997: loss = 2.1672 (0.757 sec/step)\n","INFO:tensorflow:global step 2998: loss = 2.0649 (0.744 sec/step)\n","I0908 16:06:26.814286 140650862335872 learning.py:512] global step 2998: loss = 2.0649 (0.744 sec/step)\n","INFO:tensorflow:global step 2999: loss = 1.9660 (0.739 sec/step)\n","I0908 16:06:27.555292 140650862335872 learning.py:512] global step 2999: loss = 1.9660 (0.739 sec/step)\n","INFO:tensorflow:global step 3000: loss = 2.1856 (0.741 sec/step)\n","I0908 16:06:28.297837 140650862335872 learning.py:512] global step 3000: loss = 2.1856 (0.741 sec/step)\n","INFO:tensorflow:global step 3001: loss = 2.0373 (0.761 sec/step)\n","I0908 16:06:29.060044 140650862335872 learning.py:512] global step 3001: loss = 2.0373 (0.761 sec/step)\n","INFO:tensorflow:global step 3002: loss = 2.1592 (0.758 sec/step)\n","I0908 16:06:29.819317 140650862335872 learning.py:512] global step 3002: loss = 2.1592 (0.758 sec/step)\n","INFO:tensorflow:global step 3003: loss = 2.6801 (0.770 sec/step)\n","I0908 16:06:30.591449 140650862335872 learning.py:512] global step 3003: loss = 2.6801 (0.770 sec/step)\n","INFO:tensorflow:global step 3004: loss = 2.1459 (0.749 sec/step)\n","I0908 16:06:31.341559 140650862335872 learning.py:512] global step 3004: loss = 2.1459 (0.749 sec/step)\n","INFO:tensorflow:global step 3005: loss = 2.0727 (0.770 sec/step)\n","I0908 16:06:32.112999 140650862335872 learning.py:512] global step 3005: loss = 2.0727 (0.770 sec/step)\n","INFO:tensorflow:global step 3006: loss = 1.8642 (0.751 sec/step)\n","I0908 16:06:32.865957 140650862335872 learning.py:512] global step 3006: loss = 1.8642 (0.751 sec/step)\n","INFO:tensorflow:global step 3007: loss = 2.1937 (0.779 sec/step)\n","I0908 16:06:33.646811 140650862335872 learning.py:512] global step 3007: loss = 2.1937 (0.779 sec/step)\n","INFO:tensorflow:global step 3008: loss = 1.8851 (0.762 sec/step)\n","I0908 16:06:34.411192 140650862335872 learning.py:512] global step 3008: loss = 1.8851 (0.762 sec/step)\n","INFO:tensorflow:global step 3009: loss = 2.3964 (0.760 sec/step)\n","I0908 16:06:35.173124 140650862335872 learning.py:512] global step 3009: loss = 2.3964 (0.760 sec/step)\n","INFO:tensorflow:global step 3010: loss = 1.8573 (0.775 sec/step)\n","I0908 16:06:35.949699 140650862335872 learning.py:512] global step 3010: loss = 1.8573 (0.775 sec/step)\n","INFO:tensorflow:global step 3011: loss = 2.4007 (0.758 sec/step)\n","I0908 16:06:36.709093 140650862335872 learning.py:512] global step 3011: loss = 2.4007 (0.758 sec/step)\n","INFO:tensorflow:global step 3012: loss = 2.2937 (0.739 sec/step)\n","I0908 16:06:37.450288 140650862335872 learning.py:512] global step 3012: loss = 2.2937 (0.739 sec/step)\n","INFO:tensorflow:global step 3013: loss = 2.2149 (0.779 sec/step)\n","I0908 16:06:38.230784 140650862335872 learning.py:512] global step 3013: loss = 2.2149 (0.779 sec/step)\n","INFO:tensorflow:global step 3014: loss = 2.4833 (0.788 sec/step)\n","I0908 16:06:39.020998 140650862335872 learning.py:512] global step 3014: loss = 2.4833 (0.788 sec/step)\n","INFO:tensorflow:global step 3015: loss = 2.0706 (0.737 sec/step)\n","I0908 16:06:39.759852 140650862335872 learning.py:512] global step 3015: loss = 2.0706 (0.737 sec/step)\n","INFO:tensorflow:global step 3016: loss = 2.1823 (0.759 sec/step)\n","I0908 16:06:40.520481 140650862335872 learning.py:512] global step 3016: loss = 2.1823 (0.759 sec/step)\n","INFO:tensorflow:global step 3017: loss = 2.8231 (0.771 sec/step)\n","I0908 16:06:41.293154 140650862335872 learning.py:512] global step 3017: loss = 2.8231 (0.771 sec/step)\n","INFO:tensorflow:global step 3018: loss = 2.1178 (0.746 sec/step)\n","I0908 16:06:42.040704 140650862335872 learning.py:512] global step 3018: loss = 2.1178 (0.746 sec/step)\n","INFO:tensorflow:global step 3019: loss = 2.4599 (0.747 sec/step)\n","I0908 16:06:42.789630 140650862335872 learning.py:512] global step 3019: loss = 2.4599 (0.747 sec/step)\n","INFO:tensorflow:global step 3020: loss = 2.4048 (0.759 sec/step)\n","I0908 16:06:43.550683 140650862335872 learning.py:512] global step 3020: loss = 2.4048 (0.759 sec/step)\n","INFO:tensorflow:global step 3021: loss = 2.1308 (0.759 sec/step)\n","I0908 16:06:44.311753 140650862335872 learning.py:512] global step 3021: loss = 2.1308 (0.759 sec/step)\n","INFO:tensorflow:global step 3022: loss = 2.0951 (0.768 sec/step)\n","I0908 16:06:45.080854 140650862335872 learning.py:512] global step 3022: loss = 2.0951 (0.768 sec/step)\n","INFO:tensorflow:global step 3023: loss = 2.7550 (0.754 sec/step)\n","I0908 16:06:45.836473 140650862335872 learning.py:512] global step 3023: loss = 2.7550 (0.754 sec/step)\n","INFO:tensorflow:global step 3024: loss = 2.0227 (0.737 sec/step)\n","I0908 16:06:46.574711 140650862335872 learning.py:512] global step 3024: loss = 2.0227 (0.737 sec/step)\n","INFO:tensorflow:global step 3025: loss = 2.2160 (0.766 sec/step)\n","I0908 16:06:47.342557 140650862335872 learning.py:512] global step 3025: loss = 2.2160 (0.766 sec/step)\n","INFO:tensorflow:global step 3026: loss = 2.0938 (0.761 sec/step)\n","I0908 16:06:48.105627 140650862335872 learning.py:512] global step 3026: loss = 2.0938 (0.761 sec/step)\n","INFO:tensorflow:global step 3027: loss = 3.1595 (0.775 sec/step)\n","I0908 16:06:48.882731 140650862335872 learning.py:512] global step 3027: loss = 3.1595 (0.775 sec/step)\n","INFO:tensorflow:global step 3028: loss = 2.3994 (0.761 sec/step)\n","I0908 16:06:49.645973 140650862335872 learning.py:512] global step 3028: loss = 2.3994 (0.761 sec/step)\n","INFO:tensorflow:global step 3029: loss = 2.4165 (0.765 sec/step)\n","I0908 16:06:50.412365 140650862335872 learning.py:512] global step 3029: loss = 2.4165 (0.765 sec/step)\n","INFO:tensorflow:global step 3030: loss = 1.8474 (0.764 sec/step)\n","I0908 16:06:51.178161 140650862335872 learning.py:512] global step 3030: loss = 1.8474 (0.764 sec/step)\n","INFO:tensorflow:global step 3031: loss = 1.9896 (0.751 sec/step)\n","I0908 16:06:51.931267 140650862335872 learning.py:512] global step 3031: loss = 1.9896 (0.751 sec/step)\n","INFO:tensorflow:global step 3032: loss = 1.8373 (0.765 sec/step)\n","I0908 16:06:52.697552 140650862335872 learning.py:512] global step 3032: loss = 1.8373 (0.765 sec/step)\n","INFO:tensorflow:global step 3033: loss = 2.0888 (0.762 sec/step)\n","I0908 16:06:53.461090 140650862335872 learning.py:512] global step 3033: loss = 2.0888 (0.762 sec/step)\n","INFO:tensorflow:global step 3034: loss = 1.7444 (0.776 sec/step)\n","I0908 16:06:54.238841 140650862335872 learning.py:512] global step 3034: loss = 1.7444 (0.776 sec/step)\n","INFO:tensorflow:global step 3035: loss = 1.9749 (0.753 sec/step)\n","I0908 16:06:54.993145 140650862335872 learning.py:512] global step 3035: loss = 1.9749 (0.753 sec/step)\n","INFO:tensorflow:global step 3036: loss = 2.2872 (0.762 sec/step)\n","I0908 16:06:55.756980 140650862335872 learning.py:512] global step 3036: loss = 2.2872 (0.762 sec/step)\n","INFO:tensorflow:global step 3037: loss = 2.0203 (0.764 sec/step)\n","I0908 16:06:56.523062 140650862335872 learning.py:512] global step 3037: loss = 2.0203 (0.764 sec/step)\n","INFO:tensorflow:global step 3038: loss = 2.0638 (0.743 sec/step)\n","I0908 16:06:57.267669 140650862335872 learning.py:512] global step 3038: loss = 2.0638 (0.743 sec/step)\n","INFO:tensorflow:global step 3039: loss = 2.3769 (0.749 sec/step)\n","I0908 16:06:58.018631 140650862335872 learning.py:512] global step 3039: loss = 2.3769 (0.749 sec/step)\n","INFO:tensorflow:global step 3040: loss = 2.1172 (0.771 sec/step)\n","I0908 16:06:58.791553 140650862335872 learning.py:512] global step 3040: loss = 2.1172 (0.771 sec/step)\n","INFO:tensorflow:global step 3041: loss = 2.4922 (0.761 sec/step)\n","I0908 16:06:59.554507 140650862335872 learning.py:512] global step 3041: loss = 2.4922 (0.761 sec/step)\n","INFO:tensorflow:global step 3042: loss = 1.7633 (0.751 sec/step)\n","I0908 16:07:00.307177 140650862335872 learning.py:512] global step 3042: loss = 1.7633 (0.751 sec/step)\n","INFO:tensorflow:global step 3043: loss = 2.0652 (0.765 sec/step)\n","I0908 16:07:01.074198 140650862335872 learning.py:512] global step 3043: loss = 2.0652 (0.765 sec/step)\n","INFO:tensorflow:global step 3044: loss = 2.3771 (0.764 sec/step)\n","I0908 16:07:01.839430 140650862335872 learning.py:512] global step 3044: loss = 2.3771 (0.764 sec/step)\n","INFO:tensorflow:global step 3045: loss = 2.4699 (0.767 sec/step)\n","I0908 16:07:02.607681 140650862335872 learning.py:512] global step 3045: loss = 2.4699 (0.767 sec/step)\n","INFO:tensorflow:global step 3046: loss = 1.8140 (0.753 sec/step)\n","I0908 16:07:03.362703 140650862335872 learning.py:512] global step 3046: loss = 1.8140 (0.753 sec/step)\n","INFO:tensorflow:global step 3047: loss = 2.2940 (0.753 sec/step)\n","I0908 16:07:04.117347 140650862335872 learning.py:512] global step 3047: loss = 2.2940 (0.753 sec/step)\n","INFO:tensorflow:global step 3048: loss = 1.6819 (0.762 sec/step)\n","I0908 16:07:04.881098 140650862335872 learning.py:512] global step 3048: loss = 1.6819 (0.762 sec/step)\n","INFO:tensorflow:global step 3049: loss = 2.3524 (0.770 sec/step)\n","I0908 16:07:05.652360 140650862335872 learning.py:512] global step 3049: loss = 2.3524 (0.770 sec/step)\n","INFO:tensorflow:global step 3050: loss = 2.2239 (0.760 sec/step)\n","I0908 16:07:06.413859 140650862335872 learning.py:512] global step 3050: loss = 2.2239 (0.760 sec/step)\n","INFO:tensorflow:global step 3051: loss = 2.2417 (0.758 sec/step)\n","I0908 16:07:07.174624 140650862335872 learning.py:512] global step 3051: loss = 2.2417 (0.758 sec/step)\n","INFO:tensorflow:global step 3052: loss = 2.2598 (0.765 sec/step)\n","I0908 16:07:07.941456 140650862335872 learning.py:512] global step 3052: loss = 2.2598 (0.765 sec/step)\n","INFO:tensorflow:global step 3053: loss = 1.9847 (0.778 sec/step)\n","I0908 16:07:08.721075 140650862335872 learning.py:512] global step 3053: loss = 1.9847 (0.778 sec/step)\n","INFO:tensorflow:global step 3054: loss = 2.2564 (0.770 sec/step)\n","I0908 16:07:09.492599 140650862335872 learning.py:512] global step 3054: loss = 2.2564 (0.770 sec/step)\n","INFO:tensorflow:global step 3055: loss = 2.0737 (0.775 sec/step)\n","I0908 16:07:10.269240 140650862335872 learning.py:512] global step 3055: loss = 2.0737 (0.775 sec/step)\n","INFO:tensorflow:global step 3056: loss = 1.9917 (0.776 sec/step)\n","I0908 16:07:11.046942 140650862335872 learning.py:512] global step 3056: loss = 1.9917 (0.776 sec/step)\n","INFO:tensorflow:global step 3057: loss = 2.2318 (0.761 sec/step)\n","I0908 16:07:11.809821 140650862335872 learning.py:512] global step 3057: loss = 2.2318 (0.761 sec/step)\n","INFO:tensorflow:global step 3058: loss = 1.9384 (0.898 sec/step)\n","I0908 16:07:12.709717 140650862335872 learning.py:512] global step 3058: loss = 1.9384 (0.898 sec/step)\n","INFO:tensorflow:global step 3059: loss = 2.0548 (0.783 sec/step)\n","I0908 16:07:13.495434 140650862335872 learning.py:512] global step 3059: loss = 2.0548 (0.783 sec/step)\n","INFO:tensorflow:global step 3060: loss = 2.1823 (0.777 sec/step)\n","I0908 16:07:14.273744 140650862335872 learning.py:512] global step 3060: loss = 2.1823 (0.777 sec/step)\n","INFO:tensorflow:global step 3061: loss = 1.8700 (0.747 sec/step)\n","I0908 16:07:15.022834 140650862335872 learning.py:512] global step 3061: loss = 1.8700 (0.747 sec/step)\n","INFO:tensorflow:global step 3062: loss = 1.8764 (0.756 sec/step)\n","I0908 16:07:15.780366 140650862335872 learning.py:512] global step 3062: loss = 1.8764 (0.756 sec/step)\n","INFO:tensorflow:global step 3063: loss = 1.8139 (0.770 sec/step)\n","I0908 16:07:16.551729 140650862335872 learning.py:512] global step 3063: loss = 1.8139 (0.770 sec/step)\n","INFO:tensorflow:global step 3064: loss = 1.7575 (0.765 sec/step)\n","I0908 16:07:17.318072 140650862335872 learning.py:512] global step 3064: loss = 1.7575 (0.765 sec/step)\n","INFO:tensorflow:global step 3065: loss = 2.3423 (0.757 sec/step)\n","I0908 16:07:18.077140 140650862335872 learning.py:512] global step 3065: loss = 2.3423 (0.757 sec/step)\n","INFO:tensorflow:global step 3066: loss = 2.1705 (0.772 sec/step)\n","I0908 16:07:18.850296 140650862335872 learning.py:512] global step 3066: loss = 2.1705 (0.772 sec/step)\n","INFO:tensorflow:global step 3067: loss = 1.9878 (0.749 sec/step)\n","I0908 16:07:19.601702 140650862335872 learning.py:512] global step 3067: loss = 1.9878 (0.749 sec/step)\n","INFO:tensorflow:global step 3068: loss = 2.5598 (0.734 sec/step)\n","I0908 16:07:20.337722 140650862335872 learning.py:512] global step 3068: loss = 2.5598 (0.734 sec/step)\n","INFO:tensorflow:global step 3069: loss = 2.7227 (0.760 sec/step)\n","I0908 16:07:21.099038 140650862335872 learning.py:512] global step 3069: loss = 2.7227 (0.760 sec/step)\n","INFO:tensorflow:global step 3070: loss = 1.8879 (0.769 sec/step)\n","I0908 16:07:21.870121 140650862335872 learning.py:512] global step 3070: loss = 1.8879 (0.769 sec/step)\n","INFO:tensorflow:global step 3071: loss = 2.1676 (0.772 sec/step)\n","I0908 16:07:22.644124 140650862335872 learning.py:512] global step 3071: loss = 2.1676 (0.772 sec/step)\n","INFO:tensorflow:global step 3072: loss = 1.9691 (0.763 sec/step)\n","I0908 16:07:23.408427 140650862335872 learning.py:512] global step 3072: loss = 1.9691 (0.763 sec/step)\n","INFO:tensorflow:global step 3073: loss = 2.2632 (0.761 sec/step)\n","I0908 16:07:24.171006 140650862335872 learning.py:512] global step 3073: loss = 2.2632 (0.761 sec/step)\n","INFO:tensorflow:global step 3074: loss = 2.2367 (0.768 sec/step)\n","I0908 16:07:24.940797 140650862335872 learning.py:512] global step 3074: loss = 2.2367 (0.768 sec/step)\n","INFO:tensorflow:global step 3075: loss = 1.7472 (0.753 sec/step)\n","I0908 16:07:25.695227 140650862335872 learning.py:512] global step 3075: loss = 1.7472 (0.753 sec/step)\n","INFO:tensorflow:global step 3076: loss = 1.9928 (0.746 sec/step)\n","I0908 16:07:26.442706 140650862335872 learning.py:512] global step 3076: loss = 1.9928 (0.746 sec/step)\n","INFO:tensorflow:global step 3077: loss = 2.0595 (0.770 sec/step)\n","I0908 16:07:27.214727 140650862335872 learning.py:512] global step 3077: loss = 2.0595 (0.770 sec/step)\n","INFO:tensorflow:global step 3078: loss = 1.9402 (0.754 sec/step)\n","I0908 16:07:27.969876 140650862335872 learning.py:512] global step 3078: loss = 1.9402 (0.754 sec/step)\n","INFO:tensorflow:global step 3079: loss = 2.1241 (0.773 sec/step)\n","I0908 16:07:28.744357 140650862335872 learning.py:512] global step 3079: loss = 2.1241 (0.773 sec/step)\n","INFO:tensorflow:global step 3080: loss = 1.6737 (0.760 sec/step)\n","I0908 16:07:29.505846 140650862335872 learning.py:512] global step 3080: loss = 1.6737 (0.760 sec/step)\n","INFO:tensorflow:global step 3081: loss = 2.1631 (0.769 sec/step)\n","I0908 16:07:30.276399 140650862335872 learning.py:512] global step 3081: loss = 2.1631 (0.769 sec/step)\n","INFO:tensorflow:global step 3082: loss = 1.9746 (0.771 sec/step)\n","I0908 16:07:31.048725 140650862335872 learning.py:512] global step 3082: loss = 1.9746 (0.771 sec/step)\n","INFO:tensorflow:global step 3083: loss = 2.0946 (0.749 sec/step)\n","I0908 16:07:31.799058 140650862335872 learning.py:512] global step 3083: loss = 2.0946 (0.749 sec/step)\n","INFO:tensorflow:global step 3084: loss = 1.8537 (0.767 sec/step)\n","I0908 16:07:32.567727 140650862335872 learning.py:512] global step 3084: loss = 1.8537 (0.767 sec/step)\n","INFO:tensorflow:global step 3085: loss = 2.4341 (0.765 sec/step)\n","I0908 16:07:33.334153 140650862335872 learning.py:512] global step 3085: loss = 2.4341 (0.765 sec/step)\n","INFO:tensorflow:global step 3086: loss = 2.2110 (0.761 sec/step)\n","I0908 16:07:34.097419 140650862335872 learning.py:512] global step 3086: loss = 2.2110 (0.761 sec/step)\n","INFO:tensorflow:global step 3087: loss = 2.2536 (0.749 sec/step)\n","I0908 16:07:34.848704 140650862335872 learning.py:512] global step 3087: loss = 2.2536 (0.749 sec/step)\n","INFO:tensorflow:global step 3088: loss = 2.0632 (0.758 sec/step)\n","I0908 16:07:35.607854 140650862335872 learning.py:512] global step 3088: loss = 2.0632 (0.758 sec/step)\n","INFO:tensorflow:global step 3089: loss = 1.7215 (0.781 sec/step)\n","I0908 16:07:36.390243 140650862335872 learning.py:512] global step 3089: loss = 1.7215 (0.781 sec/step)\n","INFO:tensorflow:global step 3090: loss = 1.8504 (0.781 sec/step)\n","I0908 16:07:37.173120 140650862335872 learning.py:512] global step 3090: loss = 1.8504 (0.781 sec/step)\n","INFO:tensorflow:global step 3091: loss = 1.9854 (0.763 sec/step)\n","I0908 16:07:37.938151 140650862335872 learning.py:512] global step 3091: loss = 1.9854 (0.763 sec/step)\n","INFO:tensorflow:global step 3092: loss = 2.0783 (0.755 sec/step)\n","I0908 16:07:38.695076 140650862335872 learning.py:512] global step 3092: loss = 2.0783 (0.755 sec/step)\n","INFO:tensorflow:global step 3093: loss = 1.9356 (0.762 sec/step)\n","I0908 16:07:39.458182 140650862335872 learning.py:512] global step 3093: loss = 1.9356 (0.762 sec/step)\n","INFO:tensorflow:global step 3094: loss = 1.9903 (0.752 sec/step)\n","I0908 16:07:40.212127 140650862335872 learning.py:512] global step 3094: loss = 1.9903 (0.752 sec/step)\n","INFO:tensorflow:global step 3095: loss = 2.0624 (0.762 sec/step)\n","I0908 16:07:40.976302 140650862335872 learning.py:512] global step 3095: loss = 2.0624 (0.762 sec/step)\n","INFO:tensorflow:global step 3096: loss = 2.2080 (0.748 sec/step)\n","I0908 16:07:41.726462 140650862335872 learning.py:512] global step 3096: loss = 2.2080 (0.748 sec/step)\n","INFO:tensorflow:global step 3097: loss = 1.9372 (0.768 sec/step)\n","I0908 16:07:42.496297 140650862335872 learning.py:512] global step 3097: loss = 1.9372 (0.768 sec/step)\n","INFO:tensorflow:global step 3098: loss = 2.4692 (0.785 sec/step)\n","I0908 16:07:43.282517 140650862335872 learning.py:512] global step 3098: loss = 2.4692 (0.785 sec/step)\n","INFO:tensorflow:global step 3099: loss = 2.2986 (0.761 sec/step)\n","I0908 16:07:44.044954 140650862335872 learning.py:512] global step 3099: loss = 2.2986 (0.761 sec/step)\n","INFO:tensorflow:global step 3100: loss = 2.0312 (0.756 sec/step)\n","I0908 16:07:44.802904 140650862335872 learning.py:512] global step 3100: loss = 2.0312 (0.756 sec/step)\n","INFO:tensorflow:global step 3101: loss = 2.4626 (0.750 sec/step)\n","I0908 16:07:45.554641 140650862335872 learning.py:512] global step 3101: loss = 2.4626 (0.750 sec/step)\n","INFO:tensorflow:Saving checkpoint to path /root/models/trained_v2/model.ckpt\n","I0908 16:07:46.273271 140646958036736 supervisor.py:1117] Saving checkpoint to path /root/models/trained_v2/model.ckpt\n","INFO:tensorflow:global step 3102: loss = 1.9633 (0.988 sec/step)\n","I0908 16:07:46.592406 140650862335872 learning.py:512] global step 3102: loss = 1.9633 (0.988 sec/step)\n","INFO:tensorflow:Recording summary at step 3102.\n","I0908 16:07:47.093275 140646941251328 supervisor.py:1050] Recording summary at step 3102.\n","INFO:tensorflow:global step 3103: loss = 2.0447 (1.084 sec/step)\n","I0908 16:07:48.175437 140650862335872 learning.py:512] global step 3103: loss = 2.0447 (1.084 sec/step)\n","INFO:tensorflow:global step 3104: loss = 1.9594 (0.946 sec/step)\n","I0908 16:07:49.282110 140650862335872 learning.py:512] global step 3104: loss = 1.9594 (0.946 sec/step)\n","INFO:tensorflow:global step 3105: loss = 1.7811 (0.746 sec/step)\n","I0908 16:07:50.153176 140650862335872 learning.py:512] global step 3105: loss = 1.7811 (0.746 sec/step)\n","INFO:tensorflow:global step 3106: loss = 2.2739 (0.757 sec/step)\n","I0908 16:07:50.911677 140650862335872 learning.py:512] global step 3106: loss = 2.2739 (0.757 sec/step)\n","INFO:tensorflow:global step 3107: loss = 2.2138 (0.769 sec/step)\n","I0908 16:07:51.682444 140650862335872 learning.py:512] global step 3107: loss = 2.2138 (0.769 sec/step)\n","INFO:tensorflow:global step 3108: loss = 2.4190 (0.766 sec/step)\n","I0908 16:07:52.449922 140650862335872 learning.py:512] global step 3108: loss = 2.4190 (0.766 sec/step)\n","INFO:tensorflow:global step 3109: loss = 1.8165 (0.765 sec/step)\n","I0908 16:07:53.216953 140650862335872 learning.py:512] global step 3109: loss = 1.8165 (0.765 sec/step)\n","INFO:tensorflow:global step 3110: loss = 2.2117 (0.755 sec/step)\n","I0908 16:07:53.973561 140650862335872 learning.py:512] global step 3110: loss = 2.2117 (0.755 sec/step)\n","INFO:tensorflow:global step 3111: loss = 2.3592 (0.758 sec/step)\n","I0908 16:07:54.732682 140650862335872 learning.py:512] global step 3111: loss = 2.3592 (0.758 sec/step)\n","INFO:tensorflow:global step 3112: loss = 2.0614 (0.748 sec/step)\n","I0908 16:07:55.482297 140650862335872 learning.py:512] global step 3112: loss = 2.0614 (0.748 sec/step)\n","INFO:tensorflow:global step 3113: loss = 1.9462 (0.772 sec/step)\n","I0908 16:07:56.255819 140650862335872 learning.py:512] global step 3113: loss = 1.9462 (0.772 sec/step)\n","INFO:tensorflow:global step 3114: loss = 1.8029 (0.736 sec/step)\n","I0908 16:07:56.993674 140650862335872 learning.py:512] global step 3114: loss = 1.8029 (0.736 sec/step)\n","INFO:tensorflow:global step 3115: loss = 1.8506 (0.765 sec/step)\n","I0908 16:07:57.760688 140650862335872 learning.py:512] global step 3115: loss = 1.8506 (0.765 sec/step)\n","INFO:tensorflow:global step 3116: loss = 2.6414 (0.760 sec/step)\n","I0908 16:07:58.521861 140650862335872 learning.py:512] global step 3116: loss = 2.6414 (0.760 sec/step)\n","INFO:tensorflow:global step 3117: loss = 2.2847 (0.741 sec/step)\n","I0908 16:07:59.263981 140650862335872 learning.py:512] global step 3117: loss = 2.2847 (0.741 sec/step)\n","INFO:tensorflow:global step 3118: loss = 1.7350 (0.771 sec/step)\n","I0908 16:08:00.036233 140650862335872 learning.py:512] global step 3118: loss = 1.7350 (0.771 sec/step)\n","INFO:tensorflow:global step 3119: loss = 1.5332 (0.781 sec/step)\n","I0908 16:08:00.819205 140650862335872 learning.py:512] global step 3119: loss = 1.5332 (0.781 sec/step)\n","INFO:tensorflow:global step 3120: loss = 2.0868 (0.765 sec/step)\n","I0908 16:08:01.585452 140650862335872 learning.py:512] global step 3120: loss = 2.0868 (0.765 sec/step)\n","INFO:tensorflow:global step 3121: loss = 1.8955 (0.760 sec/step)\n","I0908 16:08:02.347288 140650862335872 learning.py:512] global step 3121: loss = 1.8955 (0.760 sec/step)\n","INFO:tensorflow:global step 3122: loss = 2.0842 (0.770 sec/step)\n","I0908 16:08:03.119399 140650862335872 learning.py:512] global step 3122: loss = 2.0842 (0.770 sec/step)\n","INFO:tensorflow:global step 3123: loss = 1.9410 (0.756 sec/step)\n","I0908 16:08:03.877632 140650862335872 learning.py:512] global step 3123: loss = 1.9410 (0.756 sec/step)\n","INFO:tensorflow:global step 3124: loss = 2.1049 (0.763 sec/step)\n","I0908 16:08:04.642459 140650862335872 learning.py:512] global step 3124: loss = 2.1049 (0.763 sec/step)\n","INFO:tensorflow:global step 3125: loss = 2.0716 (0.764 sec/step)\n","I0908 16:08:05.407941 140650862335872 learning.py:512] global step 3125: loss = 2.0716 (0.764 sec/step)\n","INFO:tensorflow:global step 3126: loss = 2.3838 (0.757 sec/step)\n","I0908 16:08:06.166480 140650862335872 learning.py:512] global step 3126: loss = 2.3838 (0.757 sec/step)\n","INFO:tensorflow:global step 3127: loss = 2.0498 (0.774 sec/step)\n","I0908 16:08:06.941750 140650862335872 learning.py:512] global step 3127: loss = 2.0498 (0.774 sec/step)\n","INFO:tensorflow:global step 3128: loss = 1.6771 (0.768 sec/step)\n","I0908 16:08:07.711164 140650862335872 learning.py:512] global step 3128: loss = 1.6771 (0.768 sec/step)\n","INFO:tensorflow:global step 3129: loss = 2.2618 (0.760 sec/step)\n","I0908 16:08:08.472849 140650862335872 learning.py:512] global step 3129: loss = 2.2618 (0.760 sec/step)\n","INFO:tensorflow:global step 3130: loss = 1.9536 (0.753 sec/step)\n","I0908 16:08:09.227443 140650862335872 learning.py:512] global step 3130: loss = 1.9536 (0.753 sec/step)\n","INFO:tensorflow:global step 3131: loss = 2.0636 (0.745 sec/step)\n","I0908 16:08:09.974469 140650862335872 learning.py:512] global step 3131: loss = 2.0636 (0.745 sec/step)\n","INFO:tensorflow:global step 3132: loss = 2.2414 (0.762 sec/step)\n","I0908 16:08:10.738334 140650862335872 learning.py:512] global step 3132: loss = 2.2414 (0.762 sec/step)\n","INFO:tensorflow:global step 3133: loss = 2.0398 (0.765 sec/step)\n","I0908 16:08:11.505145 140650862335872 learning.py:512] global step 3133: loss = 2.0398 (0.765 sec/step)\n","INFO:tensorflow:global step 3134: loss = 2.3082 (0.767 sec/step)\n","I0908 16:08:12.274104 140650862335872 learning.py:512] global step 3134: loss = 2.3082 (0.767 sec/step)\n","INFO:tensorflow:global step 3135: loss = 2.3076 (0.747 sec/step)\n","I0908 16:08:13.022450 140650862335872 learning.py:512] global step 3135: loss = 2.3076 (0.747 sec/step)\n","INFO:tensorflow:global step 3136: loss = 1.9723 (0.780 sec/step)\n","I0908 16:08:13.803779 140650862335872 learning.py:512] global step 3136: loss = 1.9723 (0.780 sec/step)\n","INFO:tensorflow:global step 3137: loss = 1.9363 (0.761 sec/step)\n","I0908 16:08:14.566647 140650862335872 learning.py:512] global step 3137: loss = 1.9363 (0.761 sec/step)\n","INFO:tensorflow:global step 3138: loss = 2.0448 (0.759 sec/step)\n","I0908 16:08:15.326958 140650862335872 learning.py:512] global step 3138: loss = 2.0448 (0.759 sec/step)\n","INFO:tensorflow:global step 3139: loss = 1.9074 (0.750 sec/step)\n","I0908 16:08:16.079097 140650862335872 learning.py:512] global step 3139: loss = 1.9074 (0.750 sec/step)\n","INFO:tensorflow:global step 3140: loss = 1.9326 (0.760 sec/step)\n","I0908 16:08:16.840463 140650862335872 learning.py:512] global step 3140: loss = 1.9326 (0.760 sec/step)\n","INFO:tensorflow:global step 3141: loss = 2.0577 (0.759 sec/step)\n","I0908 16:08:17.601562 140650862335872 learning.py:512] global step 3141: loss = 2.0577 (0.759 sec/step)\n","INFO:tensorflow:global step 3142: loss = 2.1953 (0.750 sec/step)\n","I0908 16:08:18.353595 140650862335872 learning.py:512] global step 3142: loss = 2.1953 (0.750 sec/step)\n","INFO:tensorflow:global step 3143: loss = 1.9368 (0.779 sec/step)\n","I0908 16:08:19.133929 140650862335872 learning.py:512] global step 3143: loss = 1.9368 (0.779 sec/step)\n","INFO:tensorflow:global step 3144: loss = 1.8460 (0.753 sec/step)\n","I0908 16:08:19.888533 140650862335872 learning.py:512] global step 3144: loss = 1.8460 (0.753 sec/step)\n","INFO:tensorflow:global step 3145: loss = 2.7492 (0.767 sec/step)\n","I0908 16:08:20.657446 140650862335872 learning.py:512] global step 3145: loss = 2.7492 (0.767 sec/step)\n","INFO:tensorflow:global step 3146: loss = 2.2113 (0.759 sec/step)\n","I0908 16:08:21.418186 140650862335872 learning.py:512] global step 3146: loss = 2.2113 (0.759 sec/step)\n","INFO:tensorflow:global step 3147: loss = 2.2106 (0.750 sec/step)\n","I0908 16:08:22.169965 140650862335872 learning.py:512] global step 3147: loss = 2.2106 (0.750 sec/step)\n","INFO:tensorflow:global step 3148: loss = 2.1394 (0.753 sec/step)\n","I0908 16:08:22.924685 140650862335872 learning.py:512] global step 3148: loss = 2.1394 (0.753 sec/step)\n","INFO:tensorflow:global step 3149: loss = 2.1676 (0.769 sec/step)\n","I0908 16:08:23.695081 140650862335872 learning.py:512] global step 3149: loss = 2.1676 (0.769 sec/step)\n","INFO:tensorflow:global step 3150: loss = 2.3787 (0.760 sec/step)\n","I0908 16:08:24.456285 140650862335872 learning.py:512] global step 3150: loss = 2.3787 (0.760 sec/step)\n","INFO:tensorflow:global step 3151: loss = 2.2156 (0.754 sec/step)\n","I0908 16:08:25.211300 140650862335872 learning.py:512] global step 3151: loss = 2.2156 (0.754 sec/step)\n","INFO:tensorflow:global step 3152: loss = 2.0791 (0.748 sec/step)\n","I0908 16:08:25.960584 140650862335872 learning.py:512] global step 3152: loss = 2.0791 (0.748 sec/step)\n","INFO:tensorflow:global step 3153: loss = 2.2478 (0.779 sec/step)\n","I0908 16:08:26.740683 140650862335872 learning.py:512] global step 3153: loss = 2.2478 (0.779 sec/step)\n","INFO:tensorflow:global step 3154: loss = 2.4365 (0.746 sec/step)\n","I0908 16:08:27.488027 140650862335872 learning.py:512] global step 3154: loss = 2.4365 (0.746 sec/step)\n","INFO:tensorflow:global step 3155: loss = 2.0346 (0.761 sec/step)\n","I0908 16:08:28.250217 140650862335872 learning.py:512] global step 3155: loss = 2.0346 (0.761 sec/step)\n","INFO:tensorflow:global step 3156: loss = 1.8055 (0.759 sec/step)\n","I0908 16:08:29.011386 140650862335872 learning.py:512] global step 3156: loss = 1.8055 (0.759 sec/step)\n","INFO:tensorflow:global step 3157: loss = 2.0897 (0.746 sec/step)\n","I0908 16:08:29.759310 140650862335872 learning.py:512] global step 3157: loss = 2.0897 (0.746 sec/step)\n","INFO:tensorflow:global step 3158: loss = 1.8835 (0.752 sec/step)\n","I0908 16:08:30.512874 140650862335872 learning.py:512] global step 3158: loss = 1.8835 (0.752 sec/step)\n","INFO:tensorflow:global step 3159: loss = 1.8129 (0.760 sec/step)\n","I0908 16:08:31.274210 140650862335872 learning.py:512] global step 3159: loss = 1.8129 (0.760 sec/step)\n","INFO:tensorflow:global step 3160: loss = 1.8425 (0.761 sec/step)\n","I0908 16:08:32.036856 140650862335872 learning.py:512] global step 3160: loss = 1.8425 (0.761 sec/step)\n","INFO:tensorflow:global step 3161: loss = 1.9839 (0.752 sec/step)\n","I0908 16:08:32.790112 140650862335872 learning.py:512] global step 3161: loss = 1.9839 (0.752 sec/step)\n","INFO:tensorflow:global step 3162: loss = 2.0819 (0.758 sec/step)\n","I0908 16:08:33.549257 140650862335872 learning.py:512] global step 3162: loss = 2.0819 (0.758 sec/step)\n","INFO:tensorflow:global step 3163: loss = 1.9550 (0.763 sec/step)\n","I0908 16:08:34.314237 140650862335872 learning.py:512] global step 3163: loss = 1.9550 (0.763 sec/step)\n","INFO:tensorflow:global step 3164: loss = 2.4166 (0.747 sec/step)\n","I0908 16:08:35.062996 140650862335872 learning.py:512] global step 3164: loss = 2.4166 (0.747 sec/step)\n","INFO:tensorflow:global step 3165: loss = 2.2058 (0.771 sec/step)\n","I0908 16:08:35.836224 140650862335872 learning.py:512] global step 3165: loss = 2.2058 (0.771 sec/step)\n","INFO:tensorflow:global step 3166: loss = 2.0817 (0.762 sec/step)\n","I0908 16:08:36.599859 140650862335872 learning.py:512] global step 3166: loss = 2.0817 (0.762 sec/step)\n","INFO:tensorflow:global step 3167: loss = 2.1089 (0.765 sec/step)\n","I0908 16:08:37.366631 140650862335872 learning.py:512] global step 3167: loss = 2.1089 (0.765 sec/step)\n","INFO:tensorflow:global step 3168: loss = 1.6612 (0.761 sec/step)\n","I0908 16:08:38.129488 140650862335872 learning.py:512] global step 3168: loss = 1.6612 (0.761 sec/step)\n","INFO:tensorflow:global step 3169: loss = 2.4493 (0.752 sec/step)\n","I0908 16:08:38.883199 140650862335872 learning.py:512] global step 3169: loss = 2.4493 (0.752 sec/step)\n","INFO:tensorflow:global step 3170: loss = 2.1326 (0.782 sec/step)\n","I0908 16:08:39.666743 140650862335872 learning.py:512] global step 3170: loss = 2.1326 (0.782 sec/step)\n","INFO:tensorflow:global step 3171: loss = 2.0215 (0.779 sec/step)\n","I0908 16:08:40.447250 140650862335872 learning.py:512] global step 3171: loss = 2.0215 (0.779 sec/step)\n","INFO:tensorflow:global step 3172: loss = 2.4131 (0.769 sec/step)\n","I0908 16:08:41.218357 140650862335872 learning.py:512] global step 3172: loss = 2.4131 (0.769 sec/step)\n","INFO:tensorflow:global step 3173: loss = 1.8671 (0.762 sec/step)\n","I0908 16:08:41.981983 140650862335872 learning.py:512] global step 3173: loss = 1.8671 (0.762 sec/step)\n","INFO:tensorflow:global step 3174: loss = 2.1919 (0.744 sec/step)\n","I0908 16:08:42.727808 140650862335872 learning.py:512] global step 3174: loss = 2.1919 (0.744 sec/step)\n","INFO:tensorflow:global step 3175: loss = 1.8207 (0.770 sec/step)\n","I0908 16:08:43.499165 140650862335872 learning.py:512] global step 3175: loss = 1.8207 (0.770 sec/step)\n","INFO:tensorflow:global step 3176: loss = 2.4146 (0.772 sec/step)\n","I0908 16:08:44.272941 140650862335872 learning.py:512] global step 3176: loss = 2.4146 (0.772 sec/step)\n","INFO:tensorflow:global step 3177: loss = 2.3439 (0.742 sec/step)\n","I0908 16:08:45.016609 140650862335872 learning.py:512] global step 3177: loss = 2.3439 (0.742 sec/step)\n","INFO:tensorflow:global step 3178: loss = 1.7445 (0.746 sec/step)\n","I0908 16:08:45.764175 140650862335872 learning.py:512] global step 3178: loss = 1.7445 (0.746 sec/step)\n","INFO:tensorflow:global step 3179: loss = 1.9374 (0.760 sec/step)\n","I0908 16:08:46.525459 140650862335872 learning.py:512] global step 3179: loss = 1.9374 (0.760 sec/step)\n","INFO:tensorflow:global step 3180: loss = 2.0939 (0.747 sec/step)\n","I0908 16:08:47.273757 140650862335872 learning.py:512] global step 3180: loss = 2.0939 (0.747 sec/step)\n","INFO:tensorflow:global step 3181: loss = 2.1834 (0.730 sec/step)\n","I0908 16:08:48.005216 140650862335872 learning.py:512] global step 3181: loss = 2.1834 (0.730 sec/step)\n","INFO:tensorflow:global step 3182: loss = 1.9725 (0.768 sec/step)\n","I0908 16:08:48.774863 140650862335872 learning.py:512] global step 3182: loss = 1.9725 (0.768 sec/step)\n","INFO:tensorflow:global step 3183: loss = 2.2249 (0.749 sec/step)\n","I0908 16:08:49.525401 140650862335872 learning.py:512] global step 3183: loss = 2.2249 (0.749 sec/step)\n","INFO:tensorflow:global step 3184: loss = 1.8757 (0.758 sec/step)\n","I0908 16:08:50.284912 140650862335872 learning.py:512] global step 3184: loss = 1.8757 (0.758 sec/step)\n","INFO:tensorflow:global step 3185: loss = 1.8558 (0.755 sec/step)\n","I0908 16:08:51.041935 140650862335872 learning.py:512] global step 3185: loss = 1.8558 (0.755 sec/step)\n","INFO:tensorflow:global step 3186: loss = 2.2855 (0.771 sec/step)\n","I0908 16:08:51.815247 140650862335872 learning.py:512] global step 3186: loss = 2.2855 (0.771 sec/step)\n","INFO:tensorflow:global step 3187: loss = 1.8614 (0.764 sec/step)\n","I0908 16:08:52.580832 140650862335872 learning.py:512] global step 3187: loss = 1.8614 (0.764 sec/step)\n","INFO:tensorflow:global step 3188: loss = 2.1137 (0.771 sec/step)\n","I0908 16:08:53.353327 140650862335872 learning.py:512] global step 3188: loss = 2.1137 (0.771 sec/step)\n","INFO:tensorflow:global step 3189: loss = 1.8433 (0.760 sec/step)\n","I0908 16:08:54.114755 140650862335872 learning.py:512] global step 3189: loss = 1.8433 (0.760 sec/step)\n","INFO:tensorflow:global step 3190: loss = 1.8661 (0.763 sec/step)\n","I0908 16:08:54.879497 140650862335872 learning.py:512] global step 3190: loss = 1.8661 (0.763 sec/step)\n","INFO:tensorflow:global step 3191: loss = 2.1013 (0.765 sec/step)\n","I0908 16:08:55.645773 140650862335872 learning.py:512] global step 3191: loss = 2.1013 (0.765 sec/step)\n","INFO:tensorflow:global step 3192: loss = 1.9248 (0.765 sec/step)\n","I0908 16:08:56.412736 140650862335872 learning.py:512] global step 3192: loss = 1.9248 (0.765 sec/step)\n","INFO:tensorflow:global step 3193: loss = 2.3898 (0.761 sec/step)\n","I0908 16:08:57.175249 140650862335872 learning.py:512] global step 3193: loss = 2.3898 (0.761 sec/step)\n","INFO:tensorflow:global step 3194: loss = 2.1555 (0.764 sec/step)\n","I0908 16:08:57.940440 140650862335872 learning.py:512] global step 3194: loss = 2.1555 (0.764 sec/step)\n","INFO:tensorflow:global step 3195: loss = 1.6653 (0.765 sec/step)\n","I0908 16:08:58.707291 140650862335872 learning.py:512] global step 3195: loss = 1.6653 (0.765 sec/step)\n","INFO:tensorflow:global step 3196: loss = 2.0414 (0.757 sec/step)\n","I0908 16:08:59.466072 140650862335872 learning.py:512] global step 3196: loss = 2.0414 (0.757 sec/step)\n","INFO:tensorflow:global step 3197: loss = 2.1322 (0.751 sec/step)\n","I0908 16:09:00.219207 140650862335872 learning.py:512] global step 3197: loss = 2.1322 (0.751 sec/step)\n","INFO:tensorflow:global step 3198: loss = 2.1043 (0.768 sec/step)\n","I0908 16:09:00.988606 140650862335872 learning.py:512] global step 3198: loss = 2.1043 (0.768 sec/step)\n","INFO:tensorflow:global step 3199: loss = 2.3065 (0.755 sec/step)\n","I0908 16:09:01.744958 140650862335872 learning.py:512] global step 3199: loss = 2.3065 (0.755 sec/step)\n","INFO:tensorflow:global step 3200: loss = 2.3650 (0.773 sec/step)\n","I0908 16:09:02.519724 140650862335872 learning.py:512] global step 3200: loss = 2.3650 (0.773 sec/step)\n","INFO:tensorflow:global step 3201: loss = 2.1886 (0.767 sec/step)\n","I0908 16:09:03.288000 140650862335872 learning.py:512] global step 3201: loss = 2.1886 (0.767 sec/step)\n","INFO:tensorflow:global step 3202: loss = 1.9664 (0.741 sec/step)\n","I0908 16:09:04.030734 140650862335872 learning.py:512] global step 3202: loss = 1.9664 (0.741 sec/step)\n","INFO:tensorflow:global step 3203: loss = 2.2292 (0.758 sec/step)\n","I0908 16:09:04.790944 140650862335872 learning.py:512] global step 3203: loss = 2.2292 (0.758 sec/step)\n","INFO:tensorflow:global step 3204: loss = 2.1723 (0.751 sec/step)\n","I0908 16:09:05.543873 140650862335872 learning.py:512] global step 3204: loss = 2.1723 (0.751 sec/step)\n","INFO:tensorflow:global step 3205: loss = 2.0422 (0.767 sec/step)\n","I0908 16:09:06.312606 140650862335872 learning.py:512] global step 3205: loss = 2.0422 (0.767 sec/step)\n","INFO:tensorflow:global step 3206: loss = 2.2748 (0.738 sec/step)\n","I0908 16:09:07.052526 140650862335872 learning.py:512] global step 3206: loss = 2.2748 (0.738 sec/step)\n","INFO:tensorflow:global step 3207: loss = 2.0594 (0.770 sec/step)\n","I0908 16:09:07.824171 140650862335872 learning.py:512] global step 3207: loss = 2.0594 (0.770 sec/step)\n","INFO:tensorflow:global step 3208: loss = 2.1638 (0.749 sec/step)\n","I0908 16:09:08.574929 140650862335872 learning.py:512] global step 3208: loss = 2.1638 (0.749 sec/step)\n","INFO:tensorflow:global step 3209: loss = 2.9926 (0.767 sec/step)\n","I0908 16:09:09.343950 140650862335872 learning.py:512] global step 3209: loss = 2.9926 (0.767 sec/step)\n","INFO:tensorflow:global step 3210: loss = 2.3888 (0.765 sec/step)\n","I0908 16:09:10.110687 140650862335872 learning.py:512] global step 3210: loss = 2.3888 (0.765 sec/step)\n","INFO:tensorflow:global step 3211: loss = 2.3099 (0.740 sec/step)\n","I0908 16:09:10.852428 140650862335872 learning.py:512] global step 3211: loss = 2.3099 (0.740 sec/step)\n","INFO:tensorflow:global step 3212: loss = 1.8388 (0.779 sec/step)\n","I0908 16:09:11.632874 140650862335872 learning.py:512] global step 3212: loss = 1.8388 (0.779 sec/step)\n","INFO:tensorflow:global step 3213: loss = 2.5091 (0.763 sec/step)\n","I0908 16:09:12.397115 140650862335872 learning.py:512] global step 3213: loss = 2.5091 (0.763 sec/step)\n","INFO:tensorflow:global step 3214: loss = 2.0432 (0.761 sec/step)\n","I0908 16:09:13.159358 140650862335872 learning.py:512] global step 3214: loss = 2.0432 (0.761 sec/step)\n","INFO:tensorflow:global step 3215: loss = 2.1319 (0.745 sec/step)\n","I0908 16:09:13.906394 140650862335872 learning.py:512] global step 3215: loss = 2.1319 (0.745 sec/step)\n","INFO:tensorflow:global step 3216: loss = 2.1484 (0.763 sec/step)\n","I0908 16:09:14.671458 140650862335872 learning.py:512] global step 3216: loss = 2.1484 (0.763 sec/step)\n","INFO:tensorflow:global step 3217: loss = 2.8067 (0.773 sec/step)\n","I0908 16:09:15.446339 140650862335872 learning.py:512] global step 3217: loss = 2.8067 (0.773 sec/step)\n","INFO:tensorflow:global step 3218: loss = 2.0411 (0.743 sec/step)\n","I0908 16:09:16.190510 140650862335872 learning.py:512] global step 3218: loss = 2.0411 (0.743 sec/step)\n","INFO:tensorflow:global step 3219: loss = 2.1586 (0.745 sec/step)\n","I0908 16:09:16.937079 140650862335872 learning.py:512] global step 3219: loss = 2.1586 (0.745 sec/step)\n","INFO:tensorflow:global step 3220: loss = 1.9204 (0.758 sec/step)\n","I0908 16:09:17.697197 140650862335872 learning.py:512] global step 3220: loss = 1.9204 (0.758 sec/step)\n","INFO:tensorflow:global step 3221: loss = 2.6113 (0.739 sec/step)\n","I0908 16:09:18.438108 140650862335872 learning.py:512] global step 3221: loss = 2.6113 (0.739 sec/step)\n","INFO:tensorflow:global step 3222: loss = 2.1342 (0.748 sec/step)\n","I0908 16:09:19.188225 140650862335872 learning.py:512] global step 3222: loss = 2.1342 (0.748 sec/step)\n","INFO:tensorflow:global step 3223: loss = 2.6057 (0.751 sec/step)\n","I0908 16:09:19.941028 140650862335872 learning.py:512] global step 3223: loss = 2.6057 (0.751 sec/step)\n","INFO:tensorflow:global step 3224: loss = 1.8184 (0.760 sec/step)\n","I0908 16:09:20.702393 140650862335872 learning.py:512] global step 3224: loss = 1.8184 (0.760 sec/step)\n","INFO:tensorflow:global step 3225: loss = 2.2181 (0.745 sec/step)\n","I0908 16:09:21.448685 140650862335872 learning.py:512] global step 3225: loss = 2.2181 (0.745 sec/step)\n","INFO:tensorflow:global step 3226: loss = 1.8984 (0.743 sec/step)\n","I0908 16:09:22.193218 140650862335872 learning.py:512] global step 3226: loss = 1.8984 (0.743 sec/step)\n","INFO:tensorflow:global step 3227: loss = 2.4346 (0.766 sec/step)\n","I0908 16:09:22.960909 140650862335872 learning.py:512] global step 3227: loss = 2.4346 (0.766 sec/step)\n","INFO:tensorflow:global step 3228: loss = 1.6985 (0.756 sec/step)\n","I0908 16:09:23.718477 140650862335872 learning.py:512] global step 3228: loss = 1.6985 (0.756 sec/step)\n","INFO:tensorflow:global step 3229: loss = 2.2138 (0.755 sec/step)\n","I0908 16:09:24.475013 140650862335872 learning.py:512] global step 3229: loss = 2.2138 (0.755 sec/step)\n","INFO:tensorflow:global step 3230: loss = 2.4237 (0.744 sec/step)\n","I0908 16:09:25.220641 140650862335872 learning.py:512] global step 3230: loss = 2.4237 (0.744 sec/step)\n","INFO:tensorflow:global step 3231: loss = 2.4266 (0.764 sec/step)\n","I0908 16:09:25.985927 140650862335872 learning.py:512] global step 3231: loss = 2.4266 (0.764 sec/step)\n","INFO:tensorflow:global step 3232: loss = 2.0010 (0.753 sec/step)\n","I0908 16:09:26.740314 140650862335872 learning.py:512] global step 3232: loss = 2.0010 (0.753 sec/step)\n","INFO:tensorflow:global step 3233: loss = 2.0828 (0.771 sec/step)\n","I0908 16:09:27.512908 140650862335872 learning.py:512] global step 3233: loss = 2.0828 (0.771 sec/step)\n","INFO:tensorflow:global step 3234: loss = 2.2237 (0.766 sec/step)\n","I0908 16:09:28.280144 140650862335872 learning.py:512] global step 3234: loss = 2.2237 (0.766 sec/step)\n","INFO:tensorflow:global step 3235: loss = 2.2031 (0.773 sec/step)\n","I0908 16:09:29.055218 140650862335872 learning.py:512] global step 3235: loss = 2.2031 (0.773 sec/step)\n","INFO:tensorflow:global step 3236: loss = 1.9563 (0.770 sec/step)\n","I0908 16:09:29.826503 140650862335872 learning.py:512] global step 3236: loss = 1.9563 (0.770 sec/step)\n","INFO:tensorflow:global step 3237: loss = 2.1475 (0.752 sec/step)\n","I0908 16:09:30.580631 140650862335872 learning.py:512] global step 3237: loss = 2.1475 (0.752 sec/step)\n","INFO:tensorflow:global step 3238: loss = 2.4187 (0.761 sec/step)\n","I0908 16:09:31.343506 140650862335872 learning.py:512] global step 3238: loss = 2.4187 (0.761 sec/step)\n","INFO:tensorflow:global step 3239: loss = 1.6191 (0.778 sec/step)\n","I0908 16:09:32.122705 140650862335872 learning.py:512] global step 3239: loss = 1.6191 (0.778 sec/step)\n","INFO:tensorflow:global step 3240: loss = 2.4209 (0.767 sec/step)\n","I0908 16:09:32.891566 140650862335872 learning.py:512] global step 3240: loss = 2.4209 (0.767 sec/step)\n","INFO:tensorflow:global step 3241: loss = 1.8569 (0.742 sec/step)\n","I0908 16:09:33.635025 140650862335872 learning.py:512] global step 3241: loss = 1.8569 (0.742 sec/step)\n","INFO:tensorflow:global step 3242: loss = 1.9446 (0.758 sec/step)\n","I0908 16:09:34.394512 140650862335872 learning.py:512] global step 3242: loss = 1.9446 (0.758 sec/step)\n","INFO:tensorflow:global step 3243: loss = 2.2160 (0.765 sec/step)\n","I0908 16:09:35.161457 140650862335872 learning.py:512] global step 3243: loss = 2.2160 (0.765 sec/step)\n","INFO:tensorflow:global step 3244: loss = 1.9824 (0.755 sec/step)\n","I0908 16:09:35.918317 140650862335872 learning.py:512] global step 3244: loss = 1.9824 (0.755 sec/step)\n","INFO:tensorflow:global step 3245: loss = 2.1738 (0.761 sec/step)\n","I0908 16:09:36.680965 140650862335872 learning.py:512] global step 3245: loss = 2.1738 (0.761 sec/step)\n","INFO:tensorflow:global step 3246: loss = 2.0294 (0.773 sec/step)\n","I0908 16:09:37.455456 140650862335872 learning.py:512] global step 3246: loss = 2.0294 (0.773 sec/step)\n","INFO:tensorflow:global step 3247: loss = 1.6876 (0.764 sec/step)\n","I0908 16:09:38.221200 140650862335872 learning.py:512] global step 3247: loss = 1.6876 (0.764 sec/step)\n","INFO:tensorflow:global step 3248: loss = 2.1704 (0.755 sec/step)\n","I0908 16:09:38.978037 140650862335872 learning.py:512] global step 3248: loss = 2.1704 (0.755 sec/step)\n","INFO:tensorflow:global step 3249: loss = 2.0869 (0.766 sec/step)\n","I0908 16:09:39.745187 140650862335872 learning.py:512] global step 3249: loss = 2.0869 (0.766 sec/step)\n","INFO:tensorflow:global step 3250: loss = 1.9472 (0.763 sec/step)\n","I0908 16:09:40.510626 140650862335872 learning.py:512] global step 3250: loss = 1.9472 (0.763 sec/step)\n","INFO:tensorflow:global step 3251: loss = 2.1943 (0.764 sec/step)\n","I0908 16:09:41.276121 140650862335872 learning.py:512] global step 3251: loss = 2.1943 (0.764 sec/step)\n","INFO:tensorflow:global step 3252: loss = 1.8262 (0.755 sec/step)\n","I0908 16:09:42.032675 140650862335872 learning.py:512] global step 3252: loss = 1.8262 (0.755 sec/step)\n","INFO:tensorflow:global step 3253: loss = 1.6663 (0.767 sec/step)\n","I0908 16:09:42.801954 140650862335872 learning.py:512] global step 3253: loss = 1.6663 (0.767 sec/step)\n","INFO:tensorflow:global step 3254: loss = 2.1990 (0.769 sec/step)\n","I0908 16:09:43.572631 140650862335872 learning.py:512] global step 3254: loss = 2.1990 (0.769 sec/step)\n","INFO:tensorflow:global step 3255: loss = 2.3000 (0.763 sec/step)\n","I0908 16:09:44.337028 140650862335872 learning.py:512] global step 3255: loss = 2.3000 (0.763 sec/step)\n","INFO:tensorflow:global step 3256: loss = 1.8340 (0.761 sec/step)\n","I0908 16:09:45.099603 140650862335872 learning.py:512] global step 3256: loss = 1.8340 (0.761 sec/step)\n","INFO:tensorflow:global step 3257: loss = 1.7265 (0.755 sec/step)\n","I0908 16:09:45.855931 140650862335872 learning.py:512] global step 3257: loss = 1.7265 (0.755 sec/step)\n","INFO:tensorflow:global step 3258: loss = 2.6491 (0.870 sec/step)\n","I0908 16:09:46.728311 140650862335872 learning.py:512] global step 3258: loss = 2.6491 (0.870 sec/step)\n","INFO:tensorflow:Recording summary at step 3258.\n","I0908 16:09:47.693202 140646941251328 supervisor.py:1050] Recording summary at step 3258.\n","INFO:tensorflow:global step 3259: loss = 2.1872 (1.200 sec/step)\n","I0908 16:09:47.933843 140650862335872 learning.py:512] global step 3259: loss = 2.1872 (1.200 sec/step)\n","INFO:tensorflow:global step 3260: loss = 2.0919 (0.784 sec/step)\n","I0908 16:09:48.720088 140650862335872 learning.py:512] global step 3260: loss = 2.0919 (0.784 sec/step)\n","INFO:tensorflow:global step 3261: loss = 2.3120 (0.757 sec/step)\n","I0908 16:09:49.478591 140650862335872 learning.py:512] global step 3261: loss = 2.3120 (0.757 sec/step)\n","INFO:tensorflow:global step 3262: loss = 1.9537 (0.738 sec/step)\n","I0908 16:09:50.218280 140650862335872 learning.py:512] global step 3262: loss = 1.9537 (0.738 sec/step)\n","INFO:tensorflow:global step 3263: loss = 1.5919 (0.785 sec/step)\n","I0908 16:09:51.005113 140650862335872 learning.py:512] global step 3263: loss = 1.5919 (0.785 sec/step)\n","INFO:tensorflow:global step 3264: loss = 2.6394 (0.779 sec/step)\n","I0908 16:09:51.785404 140650862335872 learning.py:512] global step 3264: loss = 2.6394 (0.779 sec/step)\n","INFO:tensorflow:global step 3265: loss = 1.9863 (0.761 sec/step)\n","I0908 16:09:52.547519 140650862335872 learning.py:512] global step 3265: loss = 1.9863 (0.761 sec/step)\n","INFO:tensorflow:global step 3266: loss = 2.2266 (0.749 sec/step)\n","I0908 16:09:53.298462 140650862335872 learning.py:512] global step 3266: loss = 2.2266 (0.749 sec/step)\n","INFO:tensorflow:global step 3267: loss = 2.2365 (0.762 sec/step)\n","I0908 16:09:54.062839 140650862335872 learning.py:512] global step 3267: loss = 2.2365 (0.762 sec/step)\n","INFO:tensorflow:global step 3268: loss = 1.9966 (0.761 sec/step)\n","I0908 16:09:54.825264 140650862335872 learning.py:512] global step 3268: loss = 1.9966 (0.761 sec/step)\n","INFO:tensorflow:global step 3269: loss = 2.2902 (0.755 sec/step)\n","I0908 16:09:55.581900 140650862335872 learning.py:512] global step 3269: loss = 2.2902 (0.755 sec/step)\n","INFO:tensorflow:global step 3270: loss = 1.9819 (0.739 sec/step)\n","I0908 16:09:56.322562 140650862335872 learning.py:512] global step 3270: loss = 1.9819 (0.739 sec/step)\n","INFO:tensorflow:global step 3271: loss = 2.4289 (0.746 sec/step)\n","I0908 16:09:57.070414 140650862335872 learning.py:512] global step 3271: loss = 2.4289 (0.746 sec/step)\n","INFO:tensorflow:global step 3272: loss = 2.9549 (0.773 sec/step)\n","I0908 16:09:57.845241 140650862335872 learning.py:512] global step 3272: loss = 2.9549 (0.773 sec/step)\n","INFO:tensorflow:global step 3273: loss = 1.9550 (0.769 sec/step)\n","I0908 16:09:58.616175 140650862335872 learning.py:512] global step 3273: loss = 1.9550 (0.769 sec/step)\n","INFO:tensorflow:global step 3274: loss = 2.1408 (0.767 sec/step)\n","I0908 16:09:59.384869 140650862335872 learning.py:512] global step 3274: loss = 2.1408 (0.767 sec/step)\n","INFO:tensorflow:global step 3275: loss = 2.0431 (0.766 sec/step)\n","I0908 16:10:00.153090 140650862335872 learning.py:512] global step 3275: loss = 2.0431 (0.766 sec/step)\n","INFO:tensorflow:global step 3276: loss = 2.1429 (0.765 sec/step)\n","I0908 16:10:00.920170 140650862335872 learning.py:512] global step 3276: loss = 2.1429 (0.765 sec/step)\n","INFO:tensorflow:global step 3277: loss = 2.1719 (0.775 sec/step)\n","I0908 16:10:01.697021 140650862335872 learning.py:512] global step 3277: loss = 2.1719 (0.775 sec/step)\n","INFO:tensorflow:global step 3278: loss = 2.3854 (0.763 sec/step)\n","I0908 16:10:02.462142 140650862335872 learning.py:512] global step 3278: loss = 2.3854 (0.763 sec/step)\n","INFO:tensorflow:global step 3279: loss = 2.3275 (0.764 sec/step)\n","I0908 16:10:03.228076 140650862335872 learning.py:512] global step 3279: loss = 2.3275 (0.764 sec/step)\n","INFO:tensorflow:global step 3280: loss = 2.5365 (0.759 sec/step)\n","I0908 16:10:03.989315 140650862335872 learning.py:512] global step 3280: loss = 2.5365 (0.759 sec/step)\n","INFO:tensorflow:global step 3281: loss = 2.3119 (0.759 sec/step)\n","I0908 16:10:04.750082 140650862335872 learning.py:512] global step 3281: loss = 2.3119 (0.759 sec/step)\n","INFO:tensorflow:global step 3282: loss = 2.3987 (0.750 sec/step)\n","I0908 16:10:05.502060 140650862335872 learning.py:512] global step 3282: loss = 2.3987 (0.750 sec/step)\n","INFO:tensorflow:global step 3283: loss = 1.9043 (0.743 sec/step)\n","I0908 16:10:06.246581 140650862335872 learning.py:512] global step 3283: loss = 1.9043 (0.743 sec/step)\n","INFO:tensorflow:global step 3284: loss = 2.4419 (0.753 sec/step)\n","I0908 16:10:07.001577 140650862335872 learning.py:512] global step 3284: loss = 2.4419 (0.753 sec/step)\n","INFO:tensorflow:global step 3285: loss = 1.8367 (0.749 sec/step)\n","I0908 16:10:07.752515 140650862335872 learning.py:512] global step 3285: loss = 1.8367 (0.749 sec/step)\n","INFO:tensorflow:global step 3286: loss = 2.0462 (0.747 sec/step)\n","I0908 16:10:08.501071 140650862335872 learning.py:512] global step 3286: loss = 2.0462 (0.747 sec/step)\n","INFO:tensorflow:global step 3287: loss = 2.3273 (0.757 sec/step)\n","I0908 16:10:09.259298 140650862335872 learning.py:512] global step 3287: loss = 2.3273 (0.757 sec/step)\n","INFO:tensorflow:global step 3288: loss = 2.0057 (0.759 sec/step)\n","I0908 16:10:10.019697 140650862335872 learning.py:512] global step 3288: loss = 2.0057 (0.759 sec/step)\n","INFO:tensorflow:global step 3289: loss = 3.1361 (0.755 sec/step)\n","I0908 16:10:10.776346 140650862335872 learning.py:512] global step 3289: loss = 3.1361 (0.755 sec/step)\n","INFO:tensorflow:global step 3290: loss = 2.2203 (0.750 sec/step)\n","I0908 16:10:11.527848 140650862335872 learning.py:512] global step 3290: loss = 2.2203 (0.750 sec/step)\n","INFO:tensorflow:global step 3291: loss = 2.0812 (0.769 sec/step)\n","I0908 16:10:12.298668 140650862335872 learning.py:512] global step 3291: loss = 2.0812 (0.769 sec/step)\n","INFO:tensorflow:global step 3292: loss = 1.9629 (0.760 sec/step)\n","I0908 16:10:13.060599 140650862335872 learning.py:512] global step 3292: loss = 1.9629 (0.760 sec/step)\n","INFO:tensorflow:global step 3293: loss = 2.1741 (0.772 sec/step)\n","I0908 16:10:13.834092 140650862335872 learning.py:512] global step 3293: loss = 2.1741 (0.772 sec/step)\n","INFO:tensorflow:global step 3294: loss = 1.8126 (0.783 sec/step)\n","I0908 16:10:14.618477 140650862335872 learning.py:512] global step 3294: loss = 1.8126 (0.783 sec/step)\n","INFO:tensorflow:global step 3295: loss = 2.0327 (0.754 sec/step)\n","I0908 16:10:15.374253 140650862335872 learning.py:512] global step 3295: loss = 2.0327 (0.754 sec/step)\n","INFO:tensorflow:global step 3296: loss = 2.9078 (0.744 sec/step)\n","I0908 16:10:16.119814 140650862335872 learning.py:512] global step 3296: loss = 2.9078 (0.744 sec/step)\n","INFO:tensorflow:global step 3297: loss = 2.0641 (0.759 sec/step)\n","I0908 16:10:16.880755 140650862335872 learning.py:512] global step 3297: loss = 2.0641 (0.759 sec/step)\n","INFO:tensorflow:global step 3298: loss = 1.8856 (0.761 sec/step)\n","I0908 16:10:17.643123 140650862335872 learning.py:512] global step 3298: loss = 1.8856 (0.761 sec/step)\n","INFO:tensorflow:global step 3299: loss = 1.9076 (0.748 sec/step)\n","I0908 16:10:18.392837 140650862335872 learning.py:512] global step 3299: loss = 1.9076 (0.748 sec/step)\n","INFO:tensorflow:global step 3300: loss = 1.9651 (0.753 sec/step)\n","I0908 16:10:19.147207 140650862335872 learning.py:512] global step 3300: loss = 1.9651 (0.753 sec/step)\n","INFO:tensorflow:global step 3301: loss = 1.9832 (0.765 sec/step)\n","I0908 16:10:19.913822 140650862335872 learning.py:512] global step 3301: loss = 1.9832 (0.765 sec/step)\n","INFO:tensorflow:global step 3302: loss = 2.3449 (0.752 sec/step)\n","I0908 16:10:20.667141 140650862335872 learning.py:512] global step 3302: loss = 2.3449 (0.752 sec/step)\n","INFO:tensorflow:global step 3303: loss = 2.1500 (0.741 sec/step)\n","I0908 16:10:21.409640 140650862335872 learning.py:512] global step 3303: loss = 2.1500 (0.741 sec/step)\n","INFO:tensorflow:global step 3304: loss = 2.7634 (0.737 sec/step)\n","I0908 16:10:22.148288 140650862335872 learning.py:512] global step 3304: loss = 2.7634 (0.737 sec/step)\n","INFO:tensorflow:global step 3305: loss = 1.9554 (0.765 sec/step)\n","I0908 16:10:22.915129 140650862335872 learning.py:512] global step 3305: loss = 1.9554 (0.765 sec/step)\n","INFO:tensorflow:global step 3306: loss = 2.2159 (0.744 sec/step)\n","I0908 16:10:23.661427 140650862335872 learning.py:512] global step 3306: loss = 2.2159 (0.744 sec/step)\n","INFO:tensorflow:global step 3307: loss = 2.0994 (0.742 sec/step)\n","I0908 16:10:24.405310 140650862335872 learning.py:512] global step 3307: loss = 2.0994 (0.742 sec/step)\n","INFO:tensorflow:global step 3308: loss = 2.1066 (0.758 sec/step)\n","I0908 16:10:25.164735 140650862335872 learning.py:512] global step 3308: loss = 2.1066 (0.758 sec/step)\n","INFO:tensorflow:global step 3309: loss = 1.8859 (0.772 sec/step)\n","I0908 16:10:25.938118 140650862335872 learning.py:512] global step 3309: loss = 1.8859 (0.772 sec/step)\n","INFO:tensorflow:global step 3310: loss = 1.8121 (0.757 sec/step)\n","I0908 16:10:26.697113 140650862335872 learning.py:512] global step 3310: loss = 1.8121 (0.757 sec/step)\n","INFO:tensorflow:global step 3311: loss = 1.8285 (0.745 sec/step)\n","I0908 16:10:27.444159 140650862335872 learning.py:512] global step 3311: loss = 1.8285 (0.745 sec/step)\n","INFO:tensorflow:global step 3312: loss = 3.0625 (0.741 sec/step)\n","I0908 16:10:28.186606 140650862335872 learning.py:512] global step 3312: loss = 3.0625 (0.741 sec/step)\n","INFO:tensorflow:global step 3313: loss = 1.9085 (0.761 sec/step)\n","I0908 16:10:28.949730 140650862335872 learning.py:512] global step 3313: loss = 1.9085 (0.761 sec/step)\n","INFO:tensorflow:global step 3314: loss = 1.8552 (0.777 sec/step)\n","I0908 16:10:29.728179 140650862335872 learning.py:512] global step 3314: loss = 1.8552 (0.777 sec/step)\n","INFO:tensorflow:global step 3315: loss = 2.0699 (0.770 sec/step)\n","I0908 16:10:30.499910 140650862335872 learning.py:512] global step 3315: loss = 2.0699 (0.770 sec/step)\n","INFO:tensorflow:global step 3316: loss = 2.1025 (0.767 sec/step)\n","I0908 16:10:31.268806 140650862335872 learning.py:512] global step 3316: loss = 2.1025 (0.767 sec/step)\n","INFO:tensorflow:global step 3317: loss = 1.9451 (0.778 sec/step)\n","I0908 16:10:32.048445 140650862335872 learning.py:512] global step 3317: loss = 1.9451 (0.778 sec/step)\n","INFO:tensorflow:global step 3318: loss = 2.0097 (0.747 sec/step)\n","I0908 16:10:32.797685 140650862335872 learning.py:512] global step 3318: loss = 2.0097 (0.747 sec/step)\n","INFO:tensorflow:global step 3319: loss = 2.1978 (0.762 sec/step)\n","I0908 16:10:33.562262 140650862335872 learning.py:512] global step 3319: loss = 2.1978 (0.762 sec/step)\n","INFO:tensorflow:global step 3320: loss = 2.1354 (0.756 sec/step)\n","I0908 16:10:34.319954 140650862335872 learning.py:512] global step 3320: loss = 2.1354 (0.756 sec/step)\n","INFO:tensorflow:global step 3321: loss = 2.2450 (0.762 sec/step)\n","I0908 16:10:35.084503 140650862335872 learning.py:512] global step 3321: loss = 2.2450 (0.762 sec/step)\n","INFO:tensorflow:global step 3322: loss = 2.1275 (0.755 sec/step)\n","I0908 16:10:35.841545 140650862335872 learning.py:512] global step 3322: loss = 2.1275 (0.755 sec/step)\n","INFO:tensorflow:global step 3323: loss = 1.9336 (0.747 sec/step)\n","I0908 16:10:36.590355 140650862335872 learning.py:512] global step 3323: loss = 1.9336 (0.747 sec/step)\n","INFO:tensorflow:global step 3324: loss = 2.0834 (0.764 sec/step)\n","I0908 16:10:37.356355 140650862335872 learning.py:512] global step 3324: loss = 2.0834 (0.764 sec/step)\n","INFO:tensorflow:global step 3325: loss = 2.0000 (0.761 sec/step)\n","I0908 16:10:38.119296 140650862335872 learning.py:512] global step 3325: loss = 2.0000 (0.761 sec/step)\n","INFO:tensorflow:global step 3326: loss = 1.7717 (0.765 sec/step)\n","I0908 16:10:38.885483 140650862335872 learning.py:512] global step 3326: loss = 1.7717 (0.765 sec/step)\n","INFO:tensorflow:global step 3327: loss = 1.9969 (0.756 sec/step)\n","I0908 16:10:39.643679 140650862335872 learning.py:512] global step 3327: loss = 1.9969 (0.756 sec/step)\n","INFO:tensorflow:global step 3328: loss = 2.4074 (0.752 sec/step)\n","I0908 16:10:40.396681 140650862335872 learning.py:512] global step 3328: loss = 2.4074 (0.752 sec/step)\n","INFO:tensorflow:global step 3329: loss = 2.3331 (0.750 sec/step)\n","I0908 16:10:41.148444 140650862335872 learning.py:512] global step 3329: loss = 2.3331 (0.750 sec/step)\n","INFO:tensorflow:global step 3330: loss = 2.4079 (0.757 sec/step)\n","I0908 16:10:41.907147 140650862335872 learning.py:512] global step 3330: loss = 2.4079 (0.757 sec/step)\n","INFO:tensorflow:global step 3331: loss = 2.0619 (0.785 sec/step)\n","I0908 16:10:42.693464 140650862335872 learning.py:512] global step 3331: loss = 2.0619 (0.785 sec/step)\n","INFO:tensorflow:global step 3332: loss = 2.3842 (0.767 sec/step)\n","I0908 16:10:43.462292 140650862335872 learning.py:512] global step 3332: loss = 2.3842 (0.767 sec/step)\n","INFO:tensorflow:global step 3333: loss = 2.0033 (0.750 sec/step)\n","I0908 16:10:44.214029 140650862335872 learning.py:512] global step 3333: loss = 2.0033 (0.750 sec/step)\n","INFO:tensorflow:global step 3334: loss = 2.6591 (0.757 sec/step)\n","I0908 16:10:44.972405 140650862335872 learning.py:512] global step 3334: loss = 2.6591 (0.757 sec/step)\n","INFO:tensorflow:global step 3335: loss = 2.2343 (0.758 sec/step)\n","I0908 16:10:45.732188 140650862335872 learning.py:512] global step 3335: loss = 2.2343 (0.758 sec/step)\n","INFO:tensorflow:global step 3336: loss = 1.9563 (0.754 sec/step)\n","I0908 16:10:46.487325 140650862335872 learning.py:512] global step 3336: loss = 1.9563 (0.754 sec/step)\n","INFO:tensorflow:global step 3337: loss = 2.5166 (0.758 sec/step)\n","I0908 16:10:47.247123 140650862335872 learning.py:512] global step 3337: loss = 2.5166 (0.758 sec/step)\n","INFO:tensorflow:global step 3338: loss = 1.8533 (0.756 sec/step)\n","I0908 16:10:48.004816 140650862335872 learning.py:512] global step 3338: loss = 1.8533 (0.756 sec/step)\n","INFO:tensorflow:global step 3339: loss = 2.4709 (0.776 sec/step)\n","I0908 16:10:48.782360 140650862335872 learning.py:512] global step 3339: loss = 2.4709 (0.776 sec/step)\n","INFO:tensorflow:global step 3340: loss = 2.1877 (0.746 sec/step)\n","I0908 16:10:49.530068 140650862335872 learning.py:512] global step 3340: loss = 2.1877 (0.746 sec/step)\n","INFO:tensorflow:global step 3341: loss = 1.9019 (0.750 sec/step)\n","I0908 16:10:50.281483 140650862335872 learning.py:512] global step 3341: loss = 1.9019 (0.750 sec/step)\n","INFO:tensorflow:global step 3342: loss = 2.0733 (0.749 sec/step)\n","I0908 16:10:51.032125 140650862335872 learning.py:512] global step 3342: loss = 2.0733 (0.749 sec/step)\n","INFO:tensorflow:global step 3343: loss = 1.7332 (0.759 sec/step)\n","I0908 16:10:51.792533 140650862335872 learning.py:512] global step 3343: loss = 1.7332 (0.759 sec/step)\n","INFO:tensorflow:global step 3344: loss = 2.4729 (0.776 sec/step)\n","I0908 16:10:52.569763 140650862335872 learning.py:512] global step 3344: loss = 2.4729 (0.776 sec/step)\n","INFO:tensorflow:global step 3345: loss = 2.2781 (0.740 sec/step)\n","I0908 16:10:53.312055 140650862335872 learning.py:512] global step 3345: loss = 2.2781 (0.740 sec/step)\n","INFO:tensorflow:global step 3346: loss = 2.0700 (0.742 sec/step)\n","I0908 16:10:54.056287 140650862335872 learning.py:512] global step 3346: loss = 2.0700 (0.742 sec/step)\n","INFO:tensorflow:global step 3347: loss = 2.0479 (0.735 sec/step)\n","I0908 16:10:54.792811 140650862335872 learning.py:512] global step 3347: loss = 2.0479 (0.735 sec/step)\n","INFO:tensorflow:global step 3348: loss = 2.4835 (0.756 sec/step)\n","I0908 16:10:55.550524 140650862335872 learning.py:512] global step 3348: loss = 2.4835 (0.756 sec/step)\n","INFO:tensorflow:global step 3349: loss = 2.2219 (0.783 sec/step)\n","I0908 16:10:56.334962 140650862335872 learning.py:512] global step 3349: loss = 2.2219 (0.783 sec/step)\n","INFO:tensorflow:global step 3350: loss = 1.7639 (0.772 sec/step)\n","I0908 16:10:57.109058 140650862335872 learning.py:512] global step 3350: loss = 1.7639 (0.772 sec/step)\n","INFO:tensorflow:global step 3351: loss = 2.0720 (0.773 sec/step)\n","I0908 16:10:57.883340 140650862335872 learning.py:512] global step 3351: loss = 2.0720 (0.773 sec/step)\n","INFO:tensorflow:global step 3352: loss = 2.0260 (0.764 sec/step)\n","I0908 16:10:58.648613 140650862335872 learning.py:512] global step 3352: loss = 2.0260 (0.764 sec/step)\n","INFO:tensorflow:global step 3353: loss = 2.2322 (0.762 sec/step)\n","I0908 16:10:59.412412 140650862335872 learning.py:512] global step 3353: loss = 2.2322 (0.762 sec/step)\n","INFO:tensorflow:global step 3354: loss = 2.2161 (0.768 sec/step)\n","I0908 16:11:00.182177 140650862335872 learning.py:512] global step 3354: loss = 2.2161 (0.768 sec/step)\n","INFO:tensorflow:global step 3355: loss = 1.9677 (0.768 sec/step)\n","I0908 16:11:00.951939 140650862335872 learning.py:512] global step 3355: loss = 1.9677 (0.768 sec/step)\n","INFO:tensorflow:global step 3356: loss = 2.0478 (0.782 sec/step)\n","I0908 16:11:01.735618 140650862335872 learning.py:512] global step 3356: loss = 2.0478 (0.782 sec/step)\n","INFO:tensorflow:global step 3357: loss = 1.9544 (0.763 sec/step)\n","I0908 16:11:02.500668 140650862335872 learning.py:512] global step 3357: loss = 1.9544 (0.763 sec/step)\n","INFO:tensorflow:global step 3358: loss = 2.0877 (0.760 sec/step)\n","I0908 16:11:03.262650 140650862335872 learning.py:512] global step 3358: loss = 2.0877 (0.760 sec/step)\n","INFO:tensorflow:global step 3359: loss = 2.4476 (0.745 sec/step)\n","I0908 16:11:04.009355 140650862335872 learning.py:512] global step 3359: loss = 2.4476 (0.745 sec/step)\n","INFO:tensorflow:global step 3360: loss = 2.1752 (0.769 sec/step)\n","I0908 16:11:04.780156 140650862335872 learning.py:512] global step 3360: loss = 2.1752 (0.769 sec/step)\n","INFO:tensorflow:global step 3361: loss = 2.2382 (0.763 sec/step)\n","I0908 16:11:05.544503 140650862335872 learning.py:512] global step 3361: loss = 2.2382 (0.763 sec/step)\n","INFO:tensorflow:global step 3362: loss = 2.3443 (0.750 sec/step)\n","I0908 16:11:06.296206 140650862335872 learning.py:512] global step 3362: loss = 2.3443 (0.750 sec/step)\n","INFO:tensorflow:global step 3363: loss = 1.8510 (0.761 sec/step)\n","I0908 16:11:07.059839 140650862335872 learning.py:512] global step 3363: loss = 1.8510 (0.761 sec/step)\n","INFO:tensorflow:global step 3364: loss = 1.7243 (0.758 sec/step)\n","I0908 16:11:07.819816 140650862335872 learning.py:512] global step 3364: loss = 1.7243 (0.758 sec/step)\n","INFO:tensorflow:global step 3365: loss = 2.0339 (0.754 sec/step)\n","I0908 16:11:08.575386 140650862335872 learning.py:512] global step 3365: loss = 2.0339 (0.754 sec/step)\n","INFO:tensorflow:global step 3366: loss = 1.9541 (0.750 sec/step)\n","I0908 16:11:09.326754 140650862335872 learning.py:512] global step 3366: loss = 1.9541 (0.750 sec/step)\n","INFO:tensorflow:global step 3367: loss = 1.7478 (0.748 sec/step)\n","I0908 16:11:10.076275 140650862335872 learning.py:512] global step 3367: loss = 1.7478 (0.748 sec/step)\n","INFO:tensorflow:global step 3368: loss = 2.0314 (0.763 sec/step)\n","I0908 16:11:10.841120 140650862335872 learning.py:512] global step 3368: loss = 2.0314 (0.763 sec/step)\n","INFO:tensorflow:global step 3369: loss = 2.5361 (0.743 sec/step)\n","I0908 16:11:11.586011 140650862335872 learning.py:512] global step 3369: loss = 2.5361 (0.743 sec/step)\n","INFO:tensorflow:global step 3370: loss = 2.3340 (0.764 sec/step)\n","I0908 16:11:12.351292 140650862335872 learning.py:512] global step 3370: loss = 2.3340 (0.764 sec/step)\n","INFO:tensorflow:global step 3371: loss = 2.4621 (0.761 sec/step)\n","I0908 16:11:13.113708 140650862335872 learning.py:512] global step 3371: loss = 2.4621 (0.761 sec/step)\n","INFO:tensorflow:global step 3372: loss = 1.9331 (0.766 sec/step)\n","I0908 16:11:13.880998 140650862335872 learning.py:512] global step 3372: loss = 1.9331 (0.766 sec/step)\n","INFO:tensorflow:global step 3373: loss = 1.8827 (0.758 sec/step)\n","I0908 16:11:14.640757 140650862335872 learning.py:512] global step 3373: loss = 1.8827 (0.758 sec/step)\n","INFO:tensorflow:global step 3374: loss = 2.1985 (0.729 sec/step)\n","I0908 16:11:15.371589 140650862335872 learning.py:512] global step 3374: loss = 2.1985 (0.729 sec/step)\n","INFO:tensorflow:global step 3375: loss = 2.0213 (0.771 sec/step)\n","I0908 16:11:16.144279 140650862335872 learning.py:512] global step 3375: loss = 2.0213 (0.771 sec/step)\n","INFO:tensorflow:global step 3376: loss = 1.7111 (0.757 sec/step)\n","I0908 16:11:16.902813 140650862335872 learning.py:512] global step 3376: loss = 1.7111 (0.757 sec/step)\n","INFO:tensorflow:global step 3377: loss = 2.2228 (0.754 sec/step)\n","I0908 16:11:17.658591 140650862335872 learning.py:512] global step 3377: loss = 2.2228 (0.754 sec/step)\n","INFO:tensorflow:global step 3378: loss = 2.2203 (0.759 sec/step)\n","I0908 16:11:18.419143 140650862335872 learning.py:512] global step 3378: loss = 2.2203 (0.759 sec/step)\n","INFO:tensorflow:global step 3379: loss = 1.9837 (0.760 sec/step)\n","I0908 16:11:19.180556 140650862335872 learning.py:512] global step 3379: loss = 1.9837 (0.760 sec/step)\n","INFO:tensorflow:global step 3380: loss = 2.3408 (0.770 sec/step)\n","I0908 16:11:19.951913 140650862335872 learning.py:512] global step 3380: loss = 2.3408 (0.770 sec/step)\n","INFO:tensorflow:global step 3381: loss = 2.3528 (0.751 sec/step)\n","I0908 16:11:20.704581 140650862335872 learning.py:512] global step 3381: loss = 2.3528 (0.751 sec/step)\n","INFO:tensorflow:global step 3382: loss = 1.8301 (0.753 sec/step)\n","I0908 16:11:21.459411 140650862335872 learning.py:512] global step 3382: loss = 1.8301 (0.753 sec/step)\n","INFO:tensorflow:global step 3383: loss = 1.8616 (0.753 sec/step)\n","I0908 16:11:22.214245 140650862335872 learning.py:512] global step 3383: loss = 1.8616 (0.753 sec/step)\n","INFO:tensorflow:global step 3384: loss = 2.2224 (0.766 sec/step)\n","I0908 16:11:22.981716 140650862335872 learning.py:512] global step 3384: loss = 2.2224 (0.766 sec/step)\n","INFO:tensorflow:global step 3385: loss = 2.1649 (0.750 sec/step)\n","I0908 16:11:23.732955 140650862335872 learning.py:512] global step 3385: loss = 2.1649 (0.750 sec/step)\n","INFO:tensorflow:global step 3386: loss = 2.3749 (0.730 sec/step)\n","I0908 16:11:24.464200 140650862335872 learning.py:512] global step 3386: loss = 2.3749 (0.730 sec/step)\n","INFO:tensorflow:global step 3387: loss = 2.0035 (0.748 sec/step)\n","I0908 16:11:25.213455 140650862335872 learning.py:512] global step 3387: loss = 2.0035 (0.748 sec/step)\n","INFO:tensorflow:global step 3388: loss = 2.8666 (0.740 sec/step)\n","I0908 16:11:25.954657 140650862335872 learning.py:512] global step 3388: loss = 2.8666 (0.740 sec/step)\n","INFO:tensorflow:global step 3389: loss = 2.4278 (0.749 sec/step)\n","I0908 16:11:26.705121 140650862335872 learning.py:512] global step 3389: loss = 2.4278 (0.749 sec/step)\n","INFO:tensorflow:global step 3390: loss = 2.4409 (0.776 sec/step)\n","I0908 16:11:27.482326 140650862335872 learning.py:512] global step 3390: loss = 2.4409 (0.776 sec/step)\n","INFO:tensorflow:global step 3391: loss = 2.7644 (0.735 sec/step)\n","I0908 16:11:28.219028 140650862335872 learning.py:512] global step 3391: loss = 2.7644 (0.735 sec/step)\n","INFO:tensorflow:global step 3392: loss = 2.2980 (0.763 sec/step)\n","I0908 16:11:28.983460 140650862335872 learning.py:512] global step 3392: loss = 2.2980 (0.763 sec/step)\n","INFO:tensorflow:global step 3393: loss = 2.0121 (0.753 sec/step)\n","I0908 16:11:29.737723 140650862335872 learning.py:512] global step 3393: loss = 2.0121 (0.753 sec/step)\n","INFO:tensorflow:global step 3394: loss = 2.2801 (0.756 sec/step)\n","I0908 16:11:30.495553 140650862335872 learning.py:512] global step 3394: loss = 2.2801 (0.756 sec/step)\n","INFO:tensorflow:global step 3395: loss = 2.6826 (0.765 sec/step)\n","I0908 16:11:31.262278 140650862335872 learning.py:512] global step 3395: loss = 2.6826 (0.765 sec/step)\n","INFO:tensorflow:global step 3396: loss = 2.2618 (0.746 sec/step)\n","I0908 16:11:32.009769 140650862335872 learning.py:512] global step 3396: loss = 2.2618 (0.746 sec/step)\n","INFO:tensorflow:global step 3397: loss = 2.2652 (0.746 sec/step)\n","I0908 16:11:32.757872 140650862335872 learning.py:512] global step 3397: loss = 2.2652 (0.746 sec/step)\n","INFO:tensorflow:global step 3398: loss = 1.9571 (0.786 sec/step)\n","I0908 16:11:33.545855 140650862335872 learning.py:512] global step 3398: loss = 1.9571 (0.786 sec/step)\n","INFO:tensorflow:global step 3399: loss = 1.9821 (0.771 sec/step)\n","I0908 16:11:34.318845 140650862335872 learning.py:512] global step 3399: loss = 1.9821 (0.771 sec/step)\n","INFO:tensorflow:global step 3400: loss = 2.2260 (0.773 sec/step)\n","I0908 16:11:35.093097 140650862335872 learning.py:512] global step 3400: loss = 2.2260 (0.773 sec/step)\n","INFO:tensorflow:global step 3401: loss = 2.3526 (0.737 sec/step)\n","I0908 16:11:35.831974 140650862335872 learning.py:512] global step 3401: loss = 2.3526 (0.737 sec/step)\n","INFO:tensorflow:global step 3402: loss = 2.7922 (0.772 sec/step)\n","I0908 16:11:36.606001 140650862335872 learning.py:512] global step 3402: loss = 2.7922 (0.772 sec/step)\n","INFO:tensorflow:global step 3403: loss = 2.6436 (0.775 sec/step)\n","I0908 16:11:37.383057 140650862335872 learning.py:512] global step 3403: loss = 2.6436 (0.775 sec/step)\n","INFO:tensorflow:global step 3404: loss = 1.8083 (0.757 sec/step)\n","I0908 16:11:38.141777 140650862335872 learning.py:512] global step 3404: loss = 1.8083 (0.757 sec/step)\n","INFO:tensorflow:global step 3405: loss = 1.8568 (0.758 sec/step)\n","I0908 16:11:38.901300 140650862335872 learning.py:512] global step 3405: loss = 1.8568 (0.758 sec/step)\n","INFO:tensorflow:global step 3406: loss = 2.2345 (0.749 sec/step)\n","I0908 16:11:39.651761 140650862335872 learning.py:512] global step 3406: loss = 2.2345 (0.749 sec/step)\n","INFO:tensorflow:global step 3407: loss = 2.3249 (0.763 sec/step)\n","I0908 16:11:40.416441 140650862335872 learning.py:512] global step 3407: loss = 2.3249 (0.763 sec/step)\n","INFO:tensorflow:global step 3408: loss = 2.3703 (0.766 sec/step)\n","I0908 16:11:41.183792 140650862335872 learning.py:512] global step 3408: loss = 2.3703 (0.766 sec/step)\n","INFO:tensorflow:global step 3409: loss = 2.2448 (0.752 sec/step)\n","I0908 16:11:41.936959 140650862335872 learning.py:512] global step 3409: loss = 2.2448 (0.752 sec/step)\n","INFO:tensorflow:global step 3410: loss = 2.1194 (0.782 sec/step)\n","I0908 16:11:42.720218 140650862335872 learning.py:512] global step 3410: loss = 2.1194 (0.782 sec/step)\n","INFO:tensorflow:global step 3411: loss = 2.2363 (0.753 sec/step)\n","I0908 16:11:43.474892 140650862335872 learning.py:512] global step 3411: loss = 2.2363 (0.753 sec/step)\n","INFO:tensorflow:global step 3412: loss = 2.1686 (0.751 sec/step)\n","I0908 16:11:44.228158 140650862335872 learning.py:512] global step 3412: loss = 2.1686 (0.751 sec/step)\n","INFO:tensorflow:global step 3413: loss = 2.0032 (0.787 sec/step)\n","I0908 16:11:45.016800 140650862335872 learning.py:512] global step 3413: loss = 2.0032 (0.787 sec/step)\n","INFO:tensorflow:global step 3414: loss = 1.7859 (0.760 sec/step)\n","I0908 16:11:45.778470 140650862335872 learning.py:512] global step 3414: loss = 1.7859 (0.760 sec/step)\n","INFO:tensorflow:global step 3415: loss = 1.8911 (0.816 sec/step)\n","I0908 16:11:46.600591 140650862335872 learning.py:512] global step 3415: loss = 1.8911 (0.816 sec/step)\n","INFO:tensorflow:global step 3416: loss = 2.3534 (1.138 sec/step)\n","I0908 16:11:47.748226 140650862335872 learning.py:512] global step 3416: loss = 2.3534 (1.138 sec/step)\n","INFO:tensorflow:Recording summary at step 3416.\n","I0908 16:11:47.750260 140646941251328 supervisor.py:1050] Recording summary at step 3416.\n","INFO:tensorflow:global step 3417: loss = 1.8860 (0.746 sec/step)\n","I0908 16:11:48.496322 140650862335872 learning.py:512] global step 3417: loss = 1.8860 (0.746 sec/step)\n","INFO:tensorflow:global step 3418: loss = 2.0971 (0.750 sec/step)\n","I0908 16:11:49.247763 140650862335872 learning.py:512] global step 3418: loss = 2.0971 (0.750 sec/step)\n","INFO:tensorflow:global step 3419: loss = 2.0614 (0.763 sec/step)\n","I0908 16:11:50.012359 140650862335872 learning.py:512] global step 3419: loss = 2.0614 (0.763 sec/step)\n","INFO:tensorflow:global step 3420: loss = 1.8766 (0.757 sec/step)\n","I0908 16:11:50.770897 140650862335872 learning.py:512] global step 3420: loss = 1.8766 (0.757 sec/step)\n","INFO:tensorflow:global step 3421: loss = 1.9528 (0.771 sec/step)\n","I0908 16:11:51.543924 140650862335872 learning.py:512] global step 3421: loss = 1.9528 (0.771 sec/step)\n","INFO:tensorflow:global step 3422: loss = 2.1939 (0.765 sec/step)\n","I0908 16:11:52.310845 140650862335872 learning.py:512] global step 3422: loss = 2.1939 (0.765 sec/step)\n","INFO:tensorflow:global step 3423: loss = 2.4071 (0.767 sec/step)\n","I0908 16:11:53.080019 140650862335872 learning.py:512] global step 3423: loss = 2.4071 (0.767 sec/step)\n","INFO:tensorflow:global step 3424: loss = 2.5599 (0.757 sec/step)\n","I0908 16:11:53.838648 140650862335872 learning.py:512] global step 3424: loss = 2.5599 (0.757 sec/step)\n","INFO:tensorflow:global step 3425: loss = 2.2023 (0.770 sec/step)\n","I0908 16:11:54.609885 140650862335872 learning.py:512] global step 3425: loss = 2.2023 (0.770 sec/step)\n","INFO:tensorflow:global step 3426: loss = 1.7751 (0.769 sec/step)\n","I0908 16:11:55.380716 140650862335872 learning.py:512] global step 3426: loss = 1.7751 (0.769 sec/step)\n","INFO:tensorflow:global step 3427: loss = 2.1895 (0.762 sec/step)\n","I0908 16:11:56.144046 140650862335872 learning.py:512] global step 3427: loss = 2.1895 (0.762 sec/step)\n","INFO:tensorflow:global step 3428: loss = 1.9124 (0.743 sec/step)\n","I0908 16:11:56.888801 140650862335872 learning.py:512] global step 3428: loss = 1.9124 (0.743 sec/step)\n","INFO:tensorflow:global step 3429: loss = 2.1399 (0.738 sec/step)\n","I0908 16:11:57.628728 140650862335872 learning.py:512] global step 3429: loss = 2.1399 (0.738 sec/step)\n","INFO:tensorflow:global step 3430: loss = 2.0178 (0.755 sec/step)\n","I0908 16:11:58.385653 140650862335872 learning.py:512] global step 3430: loss = 2.0178 (0.755 sec/step)\n","INFO:tensorflow:global step 3431: loss = 1.9710 (0.757 sec/step)\n","I0908 16:11:59.144192 140650862335872 learning.py:512] global step 3431: loss = 1.9710 (0.757 sec/step)\n","INFO:tensorflow:global step 3432: loss = 2.0672 (0.776 sec/step)\n","I0908 16:11:59.921637 140650862335872 learning.py:512] global step 3432: loss = 2.0672 (0.776 sec/step)\n","INFO:tensorflow:global step 3433: loss = 2.0147 (0.766 sec/step)\n","I0908 16:12:00.690337 140650862335872 learning.py:512] global step 3433: loss = 2.0147 (0.766 sec/step)\n","INFO:tensorflow:global step 3434: loss = 2.3995 (0.779 sec/step)\n","I0908 16:12:01.471472 140650862335872 learning.py:512] global step 3434: loss = 2.3995 (0.779 sec/step)\n","INFO:tensorflow:global step 3435: loss = 2.1815 (0.756 sec/step)\n","I0908 16:12:02.228784 140650862335872 learning.py:512] global step 3435: loss = 2.1815 (0.756 sec/step)\n","INFO:tensorflow:global step 3436: loss = 2.4870 (0.755 sec/step)\n","I0908 16:12:02.985332 140650862335872 learning.py:512] global step 3436: loss = 2.4870 (0.755 sec/step)\n","INFO:tensorflow:global step 3437: loss = 1.9960 (0.766 sec/step)\n","I0908 16:12:03.752885 140650862335872 learning.py:512] global step 3437: loss = 1.9960 (0.766 sec/step)\n","INFO:tensorflow:global step 3438: loss = 1.7953 (0.766 sec/step)\n","I0908 16:12:04.521021 140650862335872 learning.py:512] global step 3438: loss = 1.7953 (0.766 sec/step)\n","INFO:tensorflow:global step 3439: loss = 1.8971 (0.769 sec/step)\n","I0908 16:12:05.291805 140650862335872 learning.py:512] global step 3439: loss = 1.8971 (0.769 sec/step)\n","INFO:tensorflow:global step 3440: loss = 1.5461 (0.739 sec/step)\n","I0908 16:12:06.032591 140650862335872 learning.py:512] global step 3440: loss = 1.5461 (0.739 sec/step)\n","INFO:tensorflow:global step 3441: loss = 2.2959 (0.774 sec/step)\n","I0908 16:12:06.808088 140650862335872 learning.py:512] global step 3441: loss = 2.2959 (0.774 sec/step)\n","INFO:tensorflow:global step 3442: loss = 2.0164 (0.785 sec/step)\n","I0908 16:12:07.595458 140650862335872 learning.py:512] global step 3442: loss = 2.0164 (0.785 sec/step)\n","INFO:tensorflow:global step 3443: loss = 2.2134 (0.741 sec/step)\n","I0908 16:12:08.338865 140650862335872 learning.py:512] global step 3443: loss = 2.2134 (0.741 sec/step)\n","INFO:tensorflow:global step 3444: loss = 2.1506 (0.776 sec/step)\n","I0908 16:12:09.116843 140650862335872 learning.py:512] global step 3444: loss = 2.1506 (0.776 sec/step)\n","INFO:tensorflow:global step 3445: loss = 1.9896 (0.775 sec/step)\n","I0908 16:12:09.893133 140650862335872 learning.py:512] global step 3445: loss = 1.9896 (0.775 sec/step)\n","INFO:tensorflow:global step 3446: loss = 2.0730 (0.766 sec/step)\n","I0908 16:12:10.661191 140650862335872 learning.py:512] global step 3446: loss = 2.0730 (0.766 sec/step)\n","INFO:tensorflow:global step 3447: loss = 2.2723 (0.760 sec/step)\n","I0908 16:12:11.423612 140650862335872 learning.py:512] global step 3447: loss = 2.2723 (0.760 sec/step)\n","INFO:tensorflow:global step 3448: loss = 2.0721 (0.755 sec/step)\n","I0908 16:12:12.180514 140650862335872 learning.py:512] global step 3448: loss = 2.0721 (0.755 sec/step)\n","INFO:tensorflow:global step 3449: loss = 1.9412 (0.770 sec/step)\n","I0908 16:12:12.952537 140650862335872 learning.py:512] global step 3449: loss = 1.9412 (0.770 sec/step)\n","INFO:tensorflow:global step 3450: loss = 1.9602 (0.752 sec/step)\n","I0908 16:12:13.705755 140650862335872 learning.py:512] global step 3450: loss = 1.9602 (0.752 sec/step)\n","INFO:tensorflow:global step 3451: loss = 2.2334 (0.730 sec/step)\n","I0908 16:12:14.437191 140650862335872 learning.py:512] global step 3451: loss = 2.2334 (0.730 sec/step)\n","INFO:tensorflow:global step 3452: loss = 2.3383 (0.760 sec/step)\n","I0908 16:12:15.198626 140650862335872 learning.py:512] global step 3452: loss = 2.3383 (0.760 sec/step)\n","INFO:tensorflow:global step 3453: loss = 2.2012 (0.769 sec/step)\n","I0908 16:12:15.969806 140650862335872 learning.py:512] global step 3453: loss = 2.2012 (0.769 sec/step)\n","INFO:tensorflow:global step 3454: loss = 1.9191 (0.784 sec/step)\n","I0908 16:12:16.755795 140650862335872 learning.py:512] global step 3454: loss = 1.9191 (0.784 sec/step)\n","INFO:tensorflow:global step 3455: loss = 1.9841 (0.761 sec/step)\n","I0908 16:12:17.518274 140650862335872 learning.py:512] global step 3455: loss = 1.9841 (0.761 sec/step)\n","INFO:tensorflow:global step 3456: loss = 1.7030 (0.756 sec/step)\n","I0908 16:12:18.275787 140650862335872 learning.py:512] global step 3456: loss = 1.7030 (0.756 sec/step)\n","INFO:tensorflow:global step 3457: loss = 1.6881 (0.766 sec/step)\n","I0908 16:12:19.043996 140650862335872 learning.py:512] global step 3457: loss = 1.6881 (0.766 sec/step)\n","INFO:tensorflow:global step 3458: loss = 2.6541 (0.760 sec/step)\n","I0908 16:12:19.805871 140650862335872 learning.py:512] global step 3458: loss = 2.6541 (0.760 sec/step)\n","INFO:tensorflow:global step 3459: loss = 2.2110 (0.765 sec/step)\n","I0908 16:12:20.572344 140650862335872 learning.py:512] global step 3459: loss = 2.2110 (0.765 sec/step)\n","INFO:tensorflow:global step 3460: loss = 2.4809 (0.753 sec/step)\n","I0908 16:12:21.327759 140650862335872 learning.py:512] global step 3460: loss = 2.4809 (0.753 sec/step)\n","INFO:tensorflow:global step 3461: loss = 1.7511 (0.781 sec/step)\n","I0908 16:12:22.110659 140650862335872 learning.py:512] global step 3461: loss = 1.7511 (0.781 sec/step)\n","INFO:tensorflow:global step 3462: loss = 1.9337 (0.773 sec/step)\n","I0908 16:12:22.885294 140650862335872 learning.py:512] global step 3462: loss = 1.9337 (0.773 sec/step)\n","INFO:tensorflow:global step 3463: loss = 2.4226 (0.761 sec/step)\n","I0908 16:12:23.648307 140650862335872 learning.py:512] global step 3463: loss = 2.4226 (0.761 sec/step)\n","INFO:tensorflow:global step 3464: loss = 1.8995 (0.765 sec/step)\n","I0908 16:12:24.415409 140650862335872 learning.py:512] global step 3464: loss = 1.8995 (0.765 sec/step)\n","INFO:tensorflow:global step 3465: loss = 2.0835 (0.761 sec/step)\n","I0908 16:12:25.178124 140650862335872 learning.py:512] global step 3465: loss = 2.0835 (0.761 sec/step)\n","INFO:tensorflow:global step 3466: loss = 1.9613 (0.760 sec/step)\n","I0908 16:12:25.939738 140650862335872 learning.py:512] global step 3466: loss = 1.9613 (0.760 sec/step)\n","INFO:tensorflow:global step 3467: loss = 1.8914 (0.756 sec/step)\n","I0908 16:12:26.697466 140650862335872 learning.py:512] global step 3467: loss = 1.8914 (0.756 sec/step)\n","INFO:tensorflow:global step 3468: loss = 1.9188 (0.763 sec/step)\n","I0908 16:12:27.462437 140650862335872 learning.py:512] global step 3468: loss = 1.9188 (0.763 sec/step)\n","INFO:tensorflow:global step 3469: loss = 2.3539 (0.758 sec/step)\n","I0908 16:12:28.222429 140650862335872 learning.py:512] global step 3469: loss = 2.3539 (0.758 sec/step)\n","INFO:tensorflow:global step 3470: loss = 2.3925 (0.758 sec/step)\n","I0908 16:12:28.982126 140650862335872 learning.py:512] global step 3470: loss = 2.3925 (0.758 sec/step)\n","INFO:tensorflow:global step 3471: loss = 2.2221 (0.769 sec/step)\n","I0908 16:12:29.752546 140650862335872 learning.py:512] global step 3471: loss = 2.2221 (0.769 sec/step)\n","INFO:tensorflow:global step 3472: loss = 2.0754 (0.776 sec/step)\n","I0908 16:12:30.529959 140650862335872 learning.py:512] global step 3472: loss = 2.0754 (0.776 sec/step)\n","INFO:tensorflow:global step 3473: loss = 1.9821 (0.766 sec/step)\n","I0908 16:12:31.297416 140650862335872 learning.py:512] global step 3473: loss = 1.9821 (0.766 sec/step)\n","INFO:tensorflow:global step 3474: loss = 2.0602 (0.774 sec/step)\n","I0908 16:12:32.074050 140650862335872 learning.py:512] global step 3474: loss = 2.0602 (0.774 sec/step)\n","INFO:tensorflow:global step 3475: loss = 2.7639 (0.771 sec/step)\n","I0908 16:12:32.846892 140650862335872 learning.py:512] global step 3475: loss = 2.7639 (0.771 sec/step)\n","INFO:tensorflow:global step 3476: loss = 1.6227 (0.774 sec/step)\n","I0908 16:12:33.622833 140650862335872 learning.py:512] global step 3476: loss = 1.6227 (0.774 sec/step)\n","INFO:tensorflow:global step 3477: loss = 1.6476 (0.748 sec/step)\n","I0908 16:12:34.372675 140650862335872 learning.py:512] global step 3477: loss = 1.6476 (0.748 sec/step)\n","INFO:tensorflow:global step 3478: loss = 1.9709 (0.765 sec/step)\n","I0908 16:12:35.139250 140650862335872 learning.py:512] global step 3478: loss = 1.9709 (0.765 sec/step)\n","INFO:tensorflow:global step 3479: loss = 1.7093 (0.762 sec/step)\n","I0908 16:12:35.903189 140650862335872 learning.py:512] global step 3479: loss = 1.7093 (0.762 sec/step)\n","INFO:tensorflow:global step 3480: loss = 1.9912 (0.766 sec/step)\n","I0908 16:12:36.671214 140650862335872 learning.py:512] global step 3480: loss = 1.9912 (0.766 sec/step)\n","INFO:tensorflow:global step 3481: loss = 2.9403 (0.758 sec/step)\n","I0908 16:12:37.431253 140650862335872 learning.py:512] global step 3481: loss = 2.9403 (0.758 sec/step)\n","INFO:tensorflow:global step 3482: loss = 2.3450 (0.774 sec/step)\n","I0908 16:12:38.206564 140650862335872 learning.py:512] global step 3482: loss = 2.3450 (0.774 sec/step)\n","INFO:tensorflow:global step 3483: loss = 2.0077 (0.762 sec/step)\n","I0908 16:12:38.970805 140650862335872 learning.py:512] global step 3483: loss = 2.0077 (0.762 sec/step)\n","INFO:tensorflow:global step 3484: loss = 2.4208 (0.756 sec/step)\n","I0908 16:12:39.728292 140650862335872 learning.py:512] global step 3484: loss = 2.4208 (0.756 sec/step)\n","INFO:tensorflow:global step 3485: loss = 1.8201 (0.760 sec/step)\n","I0908 16:12:40.490346 140650862335872 learning.py:512] global step 3485: loss = 1.8201 (0.760 sec/step)\n","INFO:tensorflow:global step 3486: loss = 2.4219 (0.769 sec/step)\n","I0908 16:12:41.261413 140650862335872 learning.py:512] global step 3486: loss = 2.4219 (0.769 sec/step)\n","INFO:tensorflow:global step 3487: loss = 2.0127 (0.784 sec/step)\n","I0908 16:12:42.047592 140650862335872 learning.py:512] global step 3487: loss = 2.0127 (0.784 sec/step)\n","INFO:tensorflow:global step 3488: loss = 2.0467 (0.770 sec/step)\n","I0908 16:12:42.818988 140650862335872 learning.py:512] global step 3488: loss = 2.0467 (0.770 sec/step)\n","INFO:tensorflow:global step 3489: loss = 1.7966 (0.758 sec/step)\n","I0908 16:12:43.579297 140650862335872 learning.py:512] global step 3489: loss = 1.7966 (0.758 sec/step)\n","INFO:tensorflow:global step 3490: loss = 2.2909 (0.770 sec/step)\n","I0908 16:12:44.350930 140650862335872 learning.py:512] global step 3490: loss = 2.2909 (0.770 sec/step)\n","INFO:tensorflow:global step 3491: loss = 2.2332 (0.771 sec/step)\n","I0908 16:12:45.123872 140650862335872 learning.py:512] global step 3491: loss = 2.2332 (0.771 sec/step)\n","INFO:tensorflow:global step 3492: loss = 1.9598 (0.756 sec/step)\n","I0908 16:12:45.881511 140650862335872 learning.py:512] global step 3492: loss = 1.9598 (0.756 sec/step)\n","INFO:tensorflow:global step 3493: loss = 1.9860 (0.758 sec/step)\n","I0908 16:12:46.641654 140650862335872 learning.py:512] global step 3493: loss = 1.9860 (0.758 sec/step)\n","INFO:tensorflow:global step 3494: loss = 2.2055 (0.749 sec/step)\n","I0908 16:12:47.392461 140650862335872 learning.py:512] global step 3494: loss = 2.2055 (0.749 sec/step)\n","INFO:tensorflow:global step 3495: loss = 2.5976 (0.772 sec/step)\n","I0908 16:12:48.165901 140650862335872 learning.py:512] global step 3495: loss = 2.5976 (0.772 sec/step)\n","INFO:tensorflow:global step 3496: loss = 1.9924 (0.745 sec/step)\n","I0908 16:12:48.913131 140650862335872 learning.py:512] global step 3496: loss = 1.9924 (0.745 sec/step)\n","INFO:tensorflow:global step 3497: loss = 2.5295 (0.773 sec/step)\n","I0908 16:12:49.688118 140650862335872 learning.py:512] global step 3497: loss = 2.5295 (0.773 sec/step)\n","INFO:tensorflow:global step 3498: loss = 1.8846 (0.755 sec/step)\n","I0908 16:12:50.445559 140650862335872 learning.py:512] global step 3498: loss = 1.8846 (0.755 sec/step)\n","INFO:tensorflow:global step 3499: loss = 2.0522 (0.764 sec/step)\n","I0908 16:12:51.211280 140650862335872 learning.py:512] global step 3499: loss = 2.0522 (0.764 sec/step)\n","INFO:tensorflow:global step 3500: loss = 1.9067 (0.756 sec/step)\n","I0908 16:12:51.969330 140650862335872 learning.py:512] global step 3500: loss = 1.9067 (0.756 sec/step)\n","INFO:tensorflow:global step 3501: loss = 2.1853 (0.775 sec/step)\n","I0908 16:12:52.746356 140650862335872 learning.py:512] global step 3501: loss = 2.1853 (0.775 sec/step)\n","INFO:tensorflow:global step 3502: loss = 1.9195 (0.764 sec/step)\n","I0908 16:12:53.512480 140650862335872 learning.py:512] global step 3502: loss = 1.9195 (0.764 sec/step)\n","INFO:tensorflow:global step 3503: loss = 2.1861 (0.775 sec/step)\n","I0908 16:12:54.289267 140650862335872 learning.py:512] global step 3503: loss = 2.1861 (0.775 sec/step)\n","INFO:tensorflow:global step 3504: loss = 1.8326 (0.765 sec/step)\n","I0908 16:12:55.055703 140650862335872 learning.py:512] global step 3504: loss = 1.8326 (0.765 sec/step)\n","INFO:tensorflow:global step 3505: loss = 1.9644 (0.762 sec/step)\n","I0908 16:12:55.819836 140650862335872 learning.py:512] global step 3505: loss = 1.9644 (0.762 sec/step)\n","INFO:tensorflow:global step 3506: loss = 2.0931 (0.754 sec/step)\n","I0908 16:12:56.575238 140650862335872 learning.py:512] global step 3506: loss = 2.0931 (0.754 sec/step)\n","INFO:tensorflow:global step 3507: loss = 1.9672 (0.769 sec/step)\n","I0908 16:12:57.345743 140650862335872 learning.py:512] global step 3507: loss = 1.9672 (0.769 sec/step)\n","INFO:tensorflow:global step 3508: loss = 2.0643 (0.784 sec/step)\n","I0908 16:12:58.131117 140650862335872 learning.py:512] global step 3508: loss = 2.0643 (0.784 sec/step)\n","INFO:tensorflow:global step 3509: loss = 2.6534 (0.777 sec/step)\n","I0908 16:12:58.910259 140650862335872 learning.py:512] global step 3509: loss = 2.6534 (0.777 sec/step)\n","INFO:tensorflow:global step 3510: loss = 2.4116 (0.755 sec/step)\n","I0908 16:12:59.667358 140650862335872 learning.py:512] global step 3510: loss = 2.4116 (0.755 sec/step)\n","INFO:tensorflow:global step 3511: loss = 1.6735 (0.772 sec/step)\n","I0908 16:13:00.440790 140650862335872 learning.py:512] global step 3511: loss = 1.6735 (0.772 sec/step)\n","INFO:tensorflow:global step 3512: loss = 2.1887 (0.771 sec/step)\n","I0908 16:13:01.213351 140650862335872 learning.py:512] global step 3512: loss = 2.1887 (0.771 sec/step)\n","INFO:tensorflow:global step 3513: loss = 2.0802 (0.755 sec/step)\n","I0908 16:13:01.970116 140650862335872 learning.py:512] global step 3513: loss = 2.0802 (0.755 sec/step)\n","INFO:tensorflow:global step 3514: loss = 2.3549 (0.763 sec/step)\n","I0908 16:13:02.734704 140650862335872 learning.py:512] global step 3514: loss = 2.3549 (0.763 sec/step)\n","INFO:tensorflow:global step 3515: loss = 2.1621 (0.757 sec/step)\n","I0908 16:13:03.493733 140650862335872 learning.py:512] global step 3515: loss = 2.1621 (0.757 sec/step)\n","INFO:tensorflow:global step 3516: loss = 1.9130 (0.775 sec/step)\n","I0908 16:13:04.270835 140650862335872 learning.py:512] global step 3516: loss = 1.9130 (0.775 sec/step)\n","INFO:tensorflow:global step 3517: loss = 1.9256 (0.757 sec/step)\n","I0908 16:13:05.029550 140650862335872 learning.py:512] global step 3517: loss = 1.9256 (0.757 sec/step)\n","INFO:tensorflow:global step 3518: loss = 2.0344 (0.766 sec/step)\n","I0908 16:13:05.797092 140650862335872 learning.py:512] global step 3518: loss = 2.0344 (0.766 sec/step)\n","INFO:tensorflow:global step 3519: loss = 2.0993 (0.760 sec/step)\n","I0908 16:13:06.558848 140650862335872 learning.py:512] global step 3519: loss = 2.0993 (0.760 sec/step)\n","INFO:tensorflow:global step 3520: loss = 2.0061 (0.761 sec/step)\n","I0908 16:13:07.321690 140650862335872 learning.py:512] global step 3520: loss = 2.0061 (0.761 sec/step)\n","INFO:tensorflow:global step 3521: loss = 2.1933 (0.743 sec/step)\n","I0908 16:13:08.066104 140650862335872 learning.py:512] global step 3521: loss = 2.1933 (0.743 sec/step)\n","INFO:tensorflow:global step 3522: loss = 1.6995 (0.744 sec/step)\n","I0908 16:13:08.811949 140650862335872 learning.py:512] global step 3522: loss = 1.6995 (0.744 sec/step)\n","INFO:tensorflow:global step 3523: loss = 1.7738 (0.771 sec/step)\n","I0908 16:13:09.584662 140650862335872 learning.py:512] global step 3523: loss = 1.7738 (0.771 sec/step)\n","INFO:tensorflow:global step 3524: loss = 1.9938 (0.758 sec/step)\n","I0908 16:13:10.344862 140650862335872 learning.py:512] global step 3524: loss = 1.9938 (0.758 sec/step)\n","INFO:tensorflow:global step 3525: loss = 1.9660 (0.766 sec/step)\n","I0908 16:13:11.113077 140650862335872 learning.py:512] global step 3525: loss = 1.9660 (0.766 sec/step)\n","INFO:tensorflow:global step 3526: loss = 2.4906 (0.761 sec/step)\n","I0908 16:13:11.875398 140650862335872 learning.py:512] global step 3526: loss = 2.4906 (0.761 sec/step)\n","INFO:tensorflow:global step 3527: loss = 2.5385 (0.773 sec/step)\n","I0908 16:13:12.649645 140650862335872 learning.py:512] global step 3527: loss = 2.5385 (0.773 sec/step)\n","INFO:tensorflow:global step 3528: loss = 1.9154 (0.761 sec/step)\n","I0908 16:13:13.411877 140650862335872 learning.py:512] global step 3528: loss = 1.9154 (0.761 sec/step)\n","INFO:tensorflow:global step 3529: loss = 2.0605 (0.772 sec/step)\n","I0908 16:13:14.186045 140650862335872 learning.py:512] global step 3529: loss = 2.0605 (0.772 sec/step)\n","INFO:tensorflow:global step 3530: loss = 2.0066 (0.752 sec/step)\n","I0908 16:13:14.939886 140650862335872 learning.py:512] global step 3530: loss = 2.0066 (0.752 sec/step)\n","INFO:tensorflow:global step 3531: loss = 2.1246 (0.759 sec/step)\n","I0908 16:13:15.700758 140650862335872 learning.py:512] global step 3531: loss = 2.1246 (0.759 sec/step)\n","INFO:tensorflow:global step 3532: loss = 2.2493 (0.736 sec/step)\n","I0908 16:13:16.437985 140650862335872 learning.py:512] global step 3532: loss = 2.2493 (0.736 sec/step)\n","INFO:tensorflow:global step 3533: loss = 2.8414 (0.769 sec/step)\n","I0908 16:13:17.209196 140650862335872 learning.py:512] global step 3533: loss = 2.8414 (0.769 sec/step)\n","INFO:tensorflow:global step 3534: loss = 2.2078 (0.750 sec/step)\n","I0908 16:13:17.960717 140650862335872 learning.py:512] global step 3534: loss = 2.2078 (0.750 sec/step)\n","INFO:tensorflow:global step 3535: loss = 1.8300 (0.768 sec/step)\n","I0908 16:13:18.731202 140650862335872 learning.py:512] global step 3535: loss = 1.8300 (0.768 sec/step)\n","INFO:tensorflow:global step 3536: loss = 1.7457 (0.769 sec/step)\n","I0908 16:13:19.502239 140650862335872 learning.py:512] global step 3536: loss = 1.7457 (0.769 sec/step)\n","INFO:tensorflow:global step 3537: loss = 1.8281 (0.788 sec/step)\n","I0908 16:13:20.291579 140650862335872 learning.py:512] global step 3537: loss = 1.8281 (0.788 sec/step)\n","INFO:tensorflow:global step 3538: loss = 2.5208 (0.751 sec/step)\n","I0908 16:13:21.044713 140650862335872 learning.py:512] global step 3538: loss = 2.5208 (0.751 sec/step)\n","INFO:tensorflow:global step 3539: loss = 2.1557 (0.762 sec/step)\n","I0908 16:13:21.808530 140650862335872 learning.py:512] global step 3539: loss = 2.1557 (0.762 sec/step)\n","INFO:tensorflow:global step 3540: loss = 2.3086 (0.764 sec/step)\n","I0908 16:13:22.573868 140650862335872 learning.py:512] global step 3540: loss = 2.3086 (0.764 sec/step)\n","INFO:tensorflow:global step 3541: loss = 1.8199 (0.767 sec/step)\n","I0908 16:13:23.342550 140650862335872 learning.py:512] global step 3541: loss = 1.8199 (0.767 sec/step)\n","INFO:tensorflow:global step 3542: loss = 2.1984 (0.769 sec/step)\n","I0908 16:13:24.112570 140650862335872 learning.py:512] global step 3542: loss = 2.1984 (0.769 sec/step)\n","INFO:tensorflow:global step 3543: loss = 2.0083 (0.748 sec/step)\n","I0908 16:13:24.862394 140650862335872 learning.py:512] global step 3543: loss = 2.0083 (0.748 sec/step)\n","INFO:tensorflow:global step 3544: loss = 2.6222 (0.760 sec/step)\n","I0908 16:13:25.624291 140650862335872 learning.py:512] global step 3544: loss = 2.6222 (0.760 sec/step)\n","INFO:tensorflow:global step 3545: loss = 1.8578 (0.770 sec/step)\n","I0908 16:13:26.396481 140650862335872 learning.py:512] global step 3545: loss = 1.8578 (0.770 sec/step)\n","INFO:tensorflow:global step 3546: loss = 2.1670 (0.759 sec/step)\n","I0908 16:13:27.157613 140650862335872 learning.py:512] global step 3546: loss = 2.1670 (0.759 sec/step)\n","INFO:tensorflow:global step 3547: loss = 1.7469 (0.763 sec/step)\n","I0908 16:13:27.922793 140650862335872 learning.py:512] global step 3547: loss = 1.7469 (0.763 sec/step)\n","INFO:tensorflow:global step 3548: loss = 2.0666 (0.769 sec/step)\n","I0908 16:13:28.695855 140650862335872 learning.py:512] global step 3548: loss = 2.0666 (0.769 sec/step)\n","INFO:tensorflow:global step 3549: loss = 2.0669 (0.765 sec/step)\n","I0908 16:13:29.463190 140650862335872 learning.py:512] global step 3549: loss = 2.0669 (0.765 sec/step)\n","INFO:tensorflow:global step 3550: loss = 2.2407 (0.779 sec/step)\n","I0908 16:13:30.243505 140650862335872 learning.py:512] global step 3550: loss = 2.2407 (0.779 sec/step)\n","INFO:tensorflow:global step 3551: loss = 1.6672 (0.755 sec/step)\n","I0908 16:13:31.000075 140650862335872 learning.py:512] global step 3551: loss = 1.6672 (0.755 sec/step)\n","INFO:tensorflow:global step 3552: loss = 2.0255 (0.756 sec/step)\n","I0908 16:13:31.757588 140650862335872 learning.py:512] global step 3552: loss = 2.0255 (0.756 sec/step)\n","INFO:tensorflow:global step 3553: loss = 1.9353 (0.758 sec/step)\n","I0908 16:13:32.517661 140650862335872 learning.py:512] global step 3553: loss = 1.9353 (0.758 sec/step)\n","INFO:tensorflow:global step 3554: loss = 2.4885 (0.765 sec/step)\n","I0908 16:13:33.284237 140650862335872 learning.py:512] global step 3554: loss = 2.4885 (0.765 sec/step)\n","INFO:tensorflow:global step 3555: loss = 2.2354 (0.746 sec/step)\n","I0908 16:13:34.031982 140650862335872 learning.py:512] global step 3555: loss = 2.2354 (0.746 sec/step)\n","INFO:tensorflow:global step 3556: loss = 1.8996 (0.786 sec/step)\n","I0908 16:13:34.820055 140650862335872 learning.py:512] global step 3556: loss = 1.8996 (0.786 sec/step)\n","INFO:tensorflow:global step 3557: loss = 2.0097 (0.762 sec/step)\n","I0908 16:13:35.583478 140650862335872 learning.py:512] global step 3557: loss = 2.0097 (0.762 sec/step)\n","INFO:tensorflow:global step 3558: loss = 2.1146 (0.762 sec/step)\n","I0908 16:13:36.347191 140650862335872 learning.py:512] global step 3558: loss = 2.1146 (0.762 sec/step)\n","INFO:tensorflow:global step 3559: loss = 2.2057 (0.748 sec/step)\n","I0908 16:13:37.096811 140650862335872 learning.py:512] global step 3559: loss = 2.2057 (0.748 sec/step)\n","INFO:tensorflow:global step 3560: loss = 1.8143 (0.775 sec/step)\n","I0908 16:13:37.873277 140650862335872 learning.py:512] global step 3560: loss = 1.8143 (0.775 sec/step)\n","INFO:tensorflow:global step 3561: loss = 1.7552 (0.768 sec/step)\n","I0908 16:13:38.642321 140650862335872 learning.py:512] global step 3561: loss = 1.7552 (0.768 sec/step)\n","INFO:tensorflow:global step 3562: loss = 2.3556 (0.752 sec/step)\n","I0908 16:13:39.395700 140650862335872 learning.py:512] global step 3562: loss = 2.3556 (0.752 sec/step)\n","INFO:tensorflow:global step 3563: loss = 1.6420 (0.758 sec/step)\n","I0908 16:13:40.154938 140650862335872 learning.py:512] global step 3563: loss = 1.6420 (0.758 sec/step)\n","INFO:tensorflow:global step 3564: loss = 2.2394 (0.746 sec/step)\n","I0908 16:13:40.902978 140650862335872 learning.py:512] global step 3564: loss = 2.2394 (0.746 sec/step)\n","INFO:tensorflow:global step 3565: loss = 1.5436 (0.767 sec/step)\n","I0908 16:13:41.671729 140650862335872 learning.py:512] global step 3565: loss = 1.5436 (0.767 sec/step)\n","INFO:tensorflow:global step 3566: loss = 1.9321 (0.738 sec/step)\n","I0908 16:13:42.412450 140650862335872 learning.py:512] global step 3566: loss = 1.9321 (0.738 sec/step)\n","INFO:tensorflow:global step 3567: loss = 2.0577 (0.770 sec/step)\n","I0908 16:13:43.184135 140650862335872 learning.py:512] global step 3567: loss = 2.0577 (0.770 sec/step)\n","INFO:tensorflow:global step 3568: loss = 2.0466 (0.763 sec/step)\n","I0908 16:13:43.949304 140650862335872 learning.py:512] global step 3568: loss = 2.0466 (0.763 sec/step)\n","INFO:tensorflow:global step 3569: loss = 1.9121 (0.773 sec/step)\n","I0908 16:13:44.724520 140650862335872 learning.py:512] global step 3569: loss = 1.9121 (0.773 sec/step)\n","INFO:tensorflow:global step 3570: loss = 1.9125 (0.750 sec/step)\n","I0908 16:13:45.476143 140650862335872 learning.py:512] global step 3570: loss = 1.9125 (0.750 sec/step)\n","INFO:tensorflow:global step 3571: loss = 2.2407 (0.755 sec/step)\n","I0908 16:13:46.232933 140650862335872 learning.py:512] global step 3571: loss = 2.2407 (0.755 sec/step)\n","INFO:tensorflow:global step 3572: loss = 2.8461 (1.251 sec/step)\n","I0908 16:13:47.485061 140650862335872 learning.py:512] global step 3572: loss = 2.8461 (1.251 sec/step)\n","INFO:tensorflow:Recording summary at step 3572.\n","I0908 16:13:47.488097 140646941251328 supervisor.py:1050] Recording summary at step 3572.\n","INFO:tensorflow:global step 3573: loss = 1.8789 (0.762 sec/step)\n","I0908 16:13:48.249363 140650862335872 learning.py:512] global step 3573: loss = 1.8789 (0.762 sec/step)\n","INFO:tensorflow:global step 3574: loss = 2.1729 (0.746 sec/step)\n","I0908 16:13:48.997079 140650862335872 learning.py:512] global step 3574: loss = 2.1729 (0.746 sec/step)\n","INFO:tensorflow:global step 3575: loss = 2.4247 (0.759 sec/step)\n","I0908 16:13:49.758352 140650862335872 learning.py:512] global step 3575: loss = 2.4247 (0.759 sec/step)\n","INFO:tensorflow:global step 3576: loss = 2.2616 (0.753 sec/step)\n","I0908 16:13:50.513319 140650862335872 learning.py:512] global step 3576: loss = 2.2616 (0.753 sec/step)\n","INFO:tensorflow:global step 3577: loss = 1.9091 (0.764 sec/step)\n","I0908 16:13:51.278729 140650862335872 learning.py:512] global step 3577: loss = 1.9091 (0.764 sec/step)\n","INFO:tensorflow:global step 3578: loss = 2.4956 (0.760 sec/step)\n","I0908 16:13:52.040405 140650862335872 learning.py:512] global step 3578: loss = 2.4956 (0.760 sec/step)\n","INFO:tensorflow:global step 3579: loss = 1.8653 (0.758 sec/step)\n","I0908 16:13:52.800603 140650862335872 learning.py:512] global step 3579: loss = 1.8653 (0.758 sec/step)\n","INFO:tensorflow:global step 3580: loss = 1.9425 (0.766 sec/step)\n","I0908 16:13:53.568335 140650862335872 learning.py:512] global step 3580: loss = 1.9425 (0.766 sec/step)\n","INFO:tensorflow:global step 3581: loss = 2.0380 (0.774 sec/step)\n","I0908 16:13:54.344473 140650862335872 learning.py:512] global step 3581: loss = 2.0380 (0.774 sec/step)\n","INFO:tensorflow:global step 3582: loss = 2.1831 (0.768 sec/step)\n","I0908 16:13:55.114310 140650862335872 learning.py:512] global step 3582: loss = 2.1831 (0.768 sec/step)\n","INFO:tensorflow:global step 3583: loss = 1.9503 (0.745 sec/step)\n","I0908 16:13:55.860735 140650862335872 learning.py:512] global step 3583: loss = 1.9503 (0.745 sec/step)\n","INFO:tensorflow:global step 3584: loss = 2.2197 (0.746 sec/step)\n","I0908 16:13:56.608816 140650862335872 learning.py:512] global step 3584: loss = 2.2197 (0.746 sec/step)\n","INFO:tensorflow:global step 3585: loss = 2.2736 (0.759 sec/step)\n","I0908 16:13:57.369284 140650862335872 learning.py:512] global step 3585: loss = 2.2736 (0.759 sec/step)\n","INFO:tensorflow:global step 3586: loss = 2.1208 (0.764 sec/step)\n","I0908 16:13:58.135020 140650862335872 learning.py:512] global step 3586: loss = 2.1208 (0.764 sec/step)\n","INFO:tensorflow:global step 3587: loss = 2.3266 (0.752 sec/step)\n","I0908 16:13:58.888808 140650862335872 learning.py:512] global step 3587: loss = 2.3266 (0.752 sec/step)\n","INFO:tensorflow:global step 3588: loss = 2.0762 (0.769 sec/step)\n","I0908 16:13:59.659812 140650862335872 learning.py:512] global step 3588: loss = 2.0762 (0.769 sec/step)\n","INFO:tensorflow:global step 3589: loss = 2.0647 (0.760 sec/step)\n","I0908 16:14:00.421859 140650862335872 learning.py:512] global step 3589: loss = 2.0647 (0.760 sec/step)\n","INFO:tensorflow:global step 3590: loss = 2.0417 (0.752 sec/step)\n","I0908 16:14:01.175718 140650862335872 learning.py:512] global step 3590: loss = 2.0417 (0.752 sec/step)\n","INFO:tensorflow:global step 3591: loss = 1.7918 (0.764 sec/step)\n","I0908 16:14:01.941314 140650862335872 learning.py:512] global step 3591: loss = 1.7918 (0.764 sec/step)\n","INFO:tensorflow:global step 3592: loss = 2.1033 (0.771 sec/step)\n","I0908 16:14:02.714700 140650862335872 learning.py:512] global step 3592: loss = 2.1033 (0.771 sec/step)\n","INFO:tensorflow:global step 3593: loss = 2.3634 (0.752 sec/step)\n","I0908 16:14:03.467959 140650862335872 learning.py:512] global step 3593: loss = 2.3634 (0.752 sec/step)\n","INFO:tensorflow:global step 3594: loss = 2.2936 (0.753 sec/step)\n","I0908 16:14:04.223144 140650862335872 learning.py:512] global step 3594: loss = 2.2936 (0.753 sec/step)\n","INFO:tensorflow:global step 3595: loss = 2.3798 (0.759 sec/step)\n","I0908 16:14:04.985079 140650862335872 learning.py:512] global step 3595: loss = 2.3798 (0.759 sec/step)\n","INFO:tensorflow:global step 3596: loss = 2.1459 (0.766 sec/step)\n","I0908 16:14:05.753085 140650862335872 learning.py:512] global step 3596: loss = 2.1459 (0.766 sec/step)\n","INFO:tensorflow:global step 3597: loss = 2.6303 (0.765 sec/step)\n","I0908 16:14:06.519553 140650862335872 learning.py:512] global step 3597: loss = 2.6303 (0.765 sec/step)\n","INFO:tensorflow:global step 3598: loss = 1.8970 (0.768 sec/step)\n","I0908 16:14:07.288787 140650862335872 learning.py:512] global step 3598: loss = 1.8970 (0.768 sec/step)\n","INFO:tensorflow:global step 3599: loss = 2.2762 (0.774 sec/step)\n","I0908 16:14:08.064164 140650862335872 learning.py:512] global step 3599: loss = 2.2762 (0.774 sec/step)\n","INFO:tensorflow:global step 3600: loss = 2.1376 (0.760 sec/step)\n","I0908 16:14:08.826532 140650862335872 learning.py:512] global step 3600: loss = 2.1376 (0.760 sec/step)\n","INFO:tensorflow:global step 3601: loss = 2.2310 (0.773 sec/step)\n","I0908 16:14:09.601744 140650862335872 learning.py:512] global step 3601: loss = 2.2310 (0.773 sec/step)\n","INFO:tensorflow:global step 3602: loss = 1.8953 (0.773 sec/step)\n","I0908 16:14:10.375930 140650862335872 learning.py:512] global step 3602: loss = 1.8953 (0.773 sec/step)\n","INFO:tensorflow:global step 3603: loss = 1.9022 (0.772 sec/step)\n","I0908 16:14:11.149783 140650862335872 learning.py:512] global step 3603: loss = 1.9022 (0.772 sec/step)\n","INFO:tensorflow:global step 3604: loss = 2.4610 (0.754 sec/step)\n","I0908 16:14:11.905507 140650862335872 learning.py:512] global step 3604: loss = 2.4610 (0.754 sec/step)\n","INFO:tensorflow:global step 3605: loss = 2.3098 (0.769 sec/step)\n","I0908 16:14:12.675731 140650862335872 learning.py:512] global step 3605: loss = 2.3098 (0.769 sec/step)\n","INFO:tensorflow:global step 3606: loss = 2.2433 (0.753 sec/step)\n","I0908 16:14:13.430796 140650862335872 learning.py:512] global step 3606: loss = 2.2433 (0.753 sec/step)\n","INFO:tensorflow:global step 3607: loss = 2.0986 (0.765 sec/step)\n","I0908 16:14:14.197464 140650862335872 learning.py:512] global step 3607: loss = 2.0986 (0.765 sec/step)\n","INFO:tensorflow:global step 3608: loss = 2.0419 (0.758 sec/step)\n","I0908 16:14:14.957051 140650862335872 learning.py:512] global step 3608: loss = 2.0419 (0.758 sec/step)\n","INFO:tensorflow:global step 3609: loss = 2.1025 (0.743 sec/step)\n","I0908 16:14:15.701734 140650862335872 learning.py:512] global step 3609: loss = 2.1025 (0.743 sec/step)\n","INFO:tensorflow:global step 3610: loss = 2.0792 (0.751 sec/step)\n","I0908 16:14:16.454568 140650862335872 learning.py:512] global step 3610: loss = 2.0792 (0.751 sec/step)\n","INFO:tensorflow:global step 3611: loss = 2.2018 (0.770 sec/step)\n","I0908 16:14:17.226678 140650862335872 learning.py:512] global step 3611: loss = 2.2018 (0.770 sec/step)\n","INFO:tensorflow:global step 3612: loss = 2.1365 (0.768 sec/step)\n","I0908 16:14:17.996743 140650862335872 learning.py:512] global step 3612: loss = 2.1365 (0.768 sec/step)\n","INFO:tensorflow:global step 3613: loss = 2.0237 (0.750 sec/step)\n","I0908 16:14:18.748433 140650862335872 learning.py:512] global step 3613: loss = 2.0237 (0.750 sec/step)\n","INFO:tensorflow:global step 3614: loss = 2.1506 (0.761 sec/step)\n","I0908 16:14:19.511273 140650862335872 learning.py:512] global step 3614: loss = 2.1506 (0.761 sec/step)\n","INFO:tensorflow:global step 3615: loss = 1.7208 (0.750 sec/step)\n","I0908 16:14:20.263300 140650862335872 learning.py:512] global step 3615: loss = 1.7208 (0.750 sec/step)\n","INFO:tensorflow:global step 3616: loss = 2.1948 (0.765 sec/step)\n","I0908 16:14:21.030272 140650862335872 learning.py:512] global step 3616: loss = 2.1948 (0.765 sec/step)\n","INFO:tensorflow:global step 3617: loss = 2.2890 (0.751 sec/step)\n","I0908 16:14:21.782355 140650862335872 learning.py:512] global step 3617: loss = 2.2890 (0.751 sec/step)\n","INFO:tensorflow:global step 3618: loss = 1.8711 (0.791 sec/step)\n","I0908 16:14:22.575108 140650862335872 learning.py:512] global step 3618: loss = 1.8711 (0.791 sec/step)\n","INFO:tensorflow:global step 3619: loss = 2.2252 (0.766 sec/step)\n","I0908 16:14:23.343247 140650862335872 learning.py:512] global step 3619: loss = 2.2252 (0.766 sec/step)\n","INFO:tensorflow:global step 3620: loss = 2.2389 (0.738 sec/step)\n","I0908 16:14:24.082490 140650862335872 learning.py:512] global step 3620: loss = 2.2389 (0.738 sec/step)\n","INFO:tensorflow:global step 3621: loss = 1.8280 (0.752 sec/step)\n","I0908 16:14:24.836148 140650862335872 learning.py:512] global step 3621: loss = 1.8280 (0.752 sec/step)\n","INFO:tensorflow:global step 3622: loss = 2.4285 (0.765 sec/step)\n","I0908 16:14:25.602467 140650862335872 learning.py:512] global step 3622: loss = 2.4285 (0.765 sec/step)\n","INFO:tensorflow:global step 3623: loss = 2.0273 (0.770 sec/step)\n","I0908 16:14:26.374325 140650862335872 learning.py:512] global step 3623: loss = 2.0273 (0.770 sec/step)\n","INFO:tensorflow:global step 3624: loss = 2.2586 (0.760 sec/step)\n","I0908 16:14:27.135735 140650862335872 learning.py:512] global step 3624: loss = 2.2586 (0.760 sec/step)\n","INFO:tensorflow:global step 3625: loss = 1.9695 (0.760 sec/step)\n","I0908 16:14:27.897668 140650862335872 learning.py:512] global step 3625: loss = 1.9695 (0.760 sec/step)\n","INFO:tensorflow:global step 3626: loss = 1.9583 (0.777 sec/step)\n","I0908 16:14:28.676566 140650862335872 learning.py:512] global step 3626: loss = 1.9583 (0.777 sec/step)\n","INFO:tensorflow:global step 3627: loss = 2.2144 (0.763 sec/step)\n","I0908 16:14:29.440950 140650862335872 learning.py:512] global step 3627: loss = 2.2144 (0.763 sec/step)\n","INFO:tensorflow:global step 3628: loss = 1.8450 (0.769 sec/step)\n","I0908 16:14:30.211460 140650862335872 learning.py:512] global step 3628: loss = 1.8450 (0.769 sec/step)\n","INFO:tensorflow:global step 3629: loss = 1.9733 (0.734 sec/step)\n","I0908 16:14:30.947224 140650862335872 learning.py:512] global step 3629: loss = 1.9733 (0.734 sec/step)\n","INFO:tensorflow:global step 3630: loss = 2.1590 (0.767 sec/step)\n","I0908 16:14:31.716120 140650862335872 learning.py:512] global step 3630: loss = 2.1590 (0.767 sec/step)\n","INFO:tensorflow:global step 3631: loss = 2.2402 (0.765 sec/step)\n","I0908 16:14:32.483063 140650862335872 learning.py:512] global step 3631: loss = 2.2402 (0.765 sec/step)\n","INFO:tensorflow:global step 3632: loss = 2.0194 (0.757 sec/step)\n","I0908 16:14:33.241631 140650862335872 learning.py:512] global step 3632: loss = 2.0194 (0.757 sec/step)\n","INFO:tensorflow:global step 3633: loss = 1.6307 (0.750 sec/step)\n","I0908 16:14:33.992879 140650862335872 learning.py:512] global step 3633: loss = 1.6307 (0.750 sec/step)\n","INFO:tensorflow:global step 3634: loss = 1.7918 (0.765 sec/step)\n","I0908 16:14:34.759989 140650862335872 learning.py:512] global step 3634: loss = 1.7918 (0.765 sec/step)\n","INFO:tensorflow:global step 3635: loss = 2.1862 (0.770 sec/step)\n","I0908 16:14:35.532063 140650862335872 learning.py:512] global step 3635: loss = 2.1862 (0.770 sec/step)\n","INFO:tensorflow:global step 3636: loss = 2.0725 (0.745 sec/step)\n","I0908 16:14:36.278966 140650862335872 learning.py:512] global step 3636: loss = 2.0725 (0.745 sec/step)\n","INFO:tensorflow:global step 3637: loss = 2.4071 (0.748 sec/step)\n","I0908 16:14:37.028401 140650862335872 learning.py:512] global step 3637: loss = 2.4071 (0.748 sec/step)\n","INFO:tensorflow:global step 3638: loss = 1.9048 (0.764 sec/step)\n","I0908 16:14:37.794243 140650862335872 learning.py:512] global step 3638: loss = 1.9048 (0.764 sec/step)\n","INFO:tensorflow:global step 3639: loss = 2.1156 (0.749 sec/step)\n","I0908 16:14:38.545245 140650862335872 learning.py:512] global step 3639: loss = 2.1156 (0.749 sec/step)\n","INFO:tensorflow:global step 3640: loss = 2.3369 (0.752 sec/step)\n","I0908 16:14:39.298770 140650862335872 learning.py:512] global step 3640: loss = 2.3369 (0.752 sec/step)\n","INFO:tensorflow:global step 3641: loss = 1.8992 (0.745 sec/step)\n","I0908 16:14:40.045823 140650862335872 learning.py:512] global step 3641: loss = 1.8992 (0.745 sec/step)\n","INFO:tensorflow:global step 3642: loss = 2.2646 (0.762 sec/step)\n","I0908 16:14:40.809624 140650862335872 learning.py:512] global step 3642: loss = 2.2646 (0.762 sec/step)\n","INFO:tensorflow:global step 3643: loss = 1.9517 (0.766 sec/step)\n","I0908 16:14:41.577711 140650862335872 learning.py:512] global step 3643: loss = 1.9517 (0.766 sec/step)\n","INFO:tensorflow:global step 3644: loss = 3.0924 (0.776 sec/step)\n","I0908 16:14:42.355540 140650862335872 learning.py:512] global step 3644: loss = 3.0924 (0.776 sec/step)\n","INFO:tensorflow:global step 3645: loss = 2.3507 (0.757 sec/step)\n","I0908 16:14:43.114752 140650862335872 learning.py:512] global step 3645: loss = 2.3507 (0.757 sec/step)\n","INFO:tensorflow:global step 3646: loss = 1.7571 (0.757 sec/step)\n","I0908 16:14:43.873991 140650862335872 learning.py:512] global step 3646: loss = 1.7571 (0.757 sec/step)\n","INFO:tensorflow:global step 3647: loss = 2.1201 (0.743 sec/step)\n","I0908 16:14:44.618669 140650862335872 learning.py:512] global step 3647: loss = 2.1201 (0.743 sec/step)\n","INFO:tensorflow:global step 3648: loss = 1.8959 (0.748 sec/step)\n","I0908 16:14:45.368863 140650862335872 learning.py:512] global step 3648: loss = 1.8959 (0.748 sec/step)\n","INFO:tensorflow:global step 3649: loss = 2.0223 (0.754 sec/step)\n","I0908 16:14:46.124418 140650862335872 learning.py:512] global step 3649: loss = 2.0223 (0.754 sec/step)\n","INFO:tensorflow:global step 3650: loss = 1.9967 (0.763 sec/step)\n","I0908 16:14:46.888746 140650862335872 learning.py:512] global step 3650: loss = 1.9967 (0.763 sec/step)\n","INFO:tensorflow:global step 3651: loss = 2.3110 (0.741 sec/step)\n","I0908 16:14:47.631793 140650862335872 learning.py:512] global step 3651: loss = 2.3110 (0.741 sec/step)\n","INFO:tensorflow:global step 3652: loss = 2.1035 (0.751 sec/step)\n","I0908 16:14:48.384312 140650862335872 learning.py:512] global step 3652: loss = 2.1035 (0.751 sec/step)\n","INFO:tensorflow:global step 3653: loss = 2.1190 (0.775 sec/step)\n","I0908 16:14:49.160970 140650862335872 learning.py:512] global step 3653: loss = 2.1190 (0.775 sec/step)\n","INFO:tensorflow:global step 3654: loss = 1.8785 (0.756 sec/step)\n","I0908 16:14:49.918624 140650862335872 learning.py:512] global step 3654: loss = 1.8785 (0.756 sec/step)\n","INFO:tensorflow:global step 3655: loss = 2.0110 (0.774 sec/step)\n","I0908 16:14:50.694476 140650862335872 learning.py:512] global step 3655: loss = 2.0110 (0.774 sec/step)\n","INFO:tensorflow:global step 3656: loss = 1.9533 (0.769 sec/step)\n","I0908 16:14:51.465224 140650862335872 learning.py:512] global step 3656: loss = 1.9533 (0.769 sec/step)\n","INFO:tensorflow:global step 3657: loss = 2.2786 (0.759 sec/step)\n","I0908 16:14:52.226212 140650862335872 learning.py:512] global step 3657: loss = 2.2786 (0.759 sec/step)\n","INFO:tensorflow:global step 3658: loss = 1.9128 (0.771 sec/step)\n","I0908 16:14:52.998600 140650862335872 learning.py:512] global step 3658: loss = 1.9128 (0.771 sec/step)\n","INFO:tensorflow:global step 3659: loss = 1.8146 (0.765 sec/step)\n","I0908 16:14:53.765455 140650862335872 learning.py:512] global step 3659: loss = 1.8146 (0.765 sec/step)\n","INFO:tensorflow:global step 3660: loss = 2.2877 (0.768 sec/step)\n","I0908 16:14:54.535208 140650862335872 learning.py:512] global step 3660: loss = 2.2877 (0.768 sec/step)\n","INFO:tensorflow:global step 3661: loss = 1.7476 (0.750 sec/step)\n","I0908 16:14:55.286898 140650862335872 learning.py:512] global step 3661: loss = 1.7476 (0.750 sec/step)\n","INFO:tensorflow:global step 3662: loss = 3.0657 (0.757 sec/step)\n","I0908 16:14:56.046462 140650862335872 learning.py:512] global step 3662: loss = 3.0657 (0.757 sec/step)\n","INFO:tensorflow:global step 3663: loss = 1.7317 (0.746 sec/step)\n","I0908 16:14:56.794138 140650862335872 learning.py:512] global step 3663: loss = 1.7317 (0.746 sec/step)\n","INFO:tensorflow:global step 3664: loss = 2.1817 (0.743 sec/step)\n","I0908 16:14:57.539514 140650862335872 learning.py:512] global step 3664: loss = 2.1817 (0.743 sec/step)\n","INFO:tensorflow:global step 3665: loss = 2.1505 (0.770 sec/step)\n","I0908 16:14:58.311403 140650862335872 learning.py:512] global step 3665: loss = 2.1505 (0.770 sec/step)\n","INFO:tensorflow:global step 3666: loss = 2.0963 (0.744 sec/step)\n","I0908 16:14:59.057139 140650862335872 learning.py:512] global step 3666: loss = 2.0963 (0.744 sec/step)\n","INFO:tensorflow:global step 3667: loss = 2.0894 (0.764 sec/step)\n","I0908 16:14:59.824055 140650862335872 learning.py:512] global step 3667: loss = 2.0894 (0.764 sec/step)\n","INFO:tensorflow:global step 3668: loss = 1.6065 (0.762 sec/step)\n","I0908 16:15:00.588159 140650862335872 learning.py:512] global step 3668: loss = 1.6065 (0.762 sec/step)\n","INFO:tensorflow:global step 3669: loss = 2.1107 (0.737 sec/step)\n","I0908 16:15:01.327235 140650862335872 learning.py:512] global step 3669: loss = 2.1107 (0.737 sec/step)\n","INFO:tensorflow:global step 3670: loss = 2.2839 (0.771 sec/step)\n","I0908 16:15:02.099692 140650862335872 learning.py:512] global step 3670: loss = 2.2839 (0.771 sec/step)\n","INFO:tensorflow:global step 3671: loss = 2.4351 (0.780 sec/step)\n","I0908 16:15:02.881900 140650862335872 learning.py:512] global step 3671: loss = 2.4351 (0.780 sec/step)\n","INFO:tensorflow:global step 3672: loss = 1.7776 (0.773 sec/step)\n","I0908 16:15:03.656916 140650862335872 learning.py:512] global step 3672: loss = 1.7776 (0.773 sec/step)\n","INFO:tensorflow:global step 3673: loss = 2.0957 (0.766 sec/step)\n","I0908 16:15:04.424861 140650862335872 learning.py:512] global step 3673: loss = 2.0957 (0.766 sec/step)\n","INFO:tensorflow:global step 3674: loss = 2.0699 (0.746 sec/step)\n","I0908 16:15:05.172694 140650862335872 learning.py:512] global step 3674: loss = 2.0699 (0.746 sec/step)\n","INFO:tensorflow:global step 3675: loss = 2.4188 (0.790 sec/step)\n","I0908 16:15:05.964112 140650862335872 learning.py:512] global step 3675: loss = 2.4188 (0.790 sec/step)\n","INFO:tensorflow:global step 3676: loss = 2.0847 (0.766 sec/step)\n","I0908 16:15:06.732764 140650862335872 learning.py:512] global step 3676: loss = 2.0847 (0.766 sec/step)\n","INFO:tensorflow:global step 3677: loss = 1.9233 (0.753 sec/step)\n","I0908 16:15:07.487206 140650862335872 learning.py:512] global step 3677: loss = 1.9233 (0.753 sec/step)\n","INFO:tensorflow:global step 3678: loss = 2.0260 (0.765 sec/step)\n","I0908 16:15:08.254002 140650862335872 learning.py:512] global step 3678: loss = 2.0260 (0.765 sec/step)\n","INFO:tensorflow:global step 3679: loss = 2.3196 (0.769 sec/step)\n","I0908 16:15:09.024404 140650862335872 learning.py:512] global step 3679: loss = 2.3196 (0.769 sec/step)\n","INFO:tensorflow:global step 3680: loss = 2.0097 (0.758 sec/step)\n","I0908 16:15:09.784346 140650862335872 learning.py:512] global step 3680: loss = 2.0097 (0.758 sec/step)\n","INFO:tensorflow:global step 3681: loss = 2.2252 (0.762 sec/step)\n","I0908 16:15:10.548591 140650862335872 learning.py:512] global step 3681: loss = 2.2252 (0.762 sec/step)\n","INFO:tensorflow:global step 3682: loss = 2.2697 (0.749 sec/step)\n","I0908 16:15:11.299953 140650862335872 learning.py:512] global step 3682: loss = 2.2697 (0.749 sec/step)\n","INFO:tensorflow:global step 3683: loss = 2.2822 (0.783 sec/step)\n","I0908 16:15:12.085111 140650862335872 learning.py:512] global step 3683: loss = 2.2822 (0.783 sec/step)\n","INFO:tensorflow:global step 3684: loss = 1.8647 (0.780 sec/step)\n","I0908 16:15:12.867015 140650862335872 learning.py:512] global step 3684: loss = 1.8647 (0.780 sec/step)\n","INFO:tensorflow:global step 3685: loss = 2.1758 (0.772 sec/step)\n","I0908 16:15:13.640700 140650862335872 learning.py:512] global step 3685: loss = 2.1758 (0.772 sec/step)\n","INFO:tensorflow:global step 3686: loss = 2.4427 (0.769 sec/step)\n","I0908 16:15:14.411257 140650862335872 learning.py:512] global step 3686: loss = 2.4427 (0.769 sec/step)\n","INFO:tensorflow:global step 3687: loss = 2.2325 (0.776 sec/step)\n","I0908 16:15:15.189552 140650862335872 learning.py:512] global step 3687: loss = 2.2325 (0.776 sec/step)\n","INFO:tensorflow:global step 3688: loss = 1.8158 (0.774 sec/step)\n","I0908 16:15:15.965433 140650862335872 learning.py:512] global step 3688: loss = 1.8158 (0.774 sec/step)\n","INFO:tensorflow:global step 3689: loss = 1.9983 (0.756 sec/step)\n","I0908 16:15:16.723647 140650862335872 learning.py:512] global step 3689: loss = 1.9983 (0.756 sec/step)\n","INFO:tensorflow:global step 3690: loss = 1.8847 (0.742 sec/step)\n","I0908 16:15:17.466971 140650862335872 learning.py:512] global step 3690: loss = 1.8847 (0.742 sec/step)\n","INFO:tensorflow:global step 3691: loss = 2.0791 (0.759 sec/step)\n","I0908 16:15:18.228106 140650862335872 learning.py:512] global step 3691: loss = 2.0791 (0.759 sec/step)\n","INFO:tensorflow:global step 3692: loss = 2.0110 (0.753 sec/step)\n","I0908 16:15:18.982662 140650862335872 learning.py:512] global step 3692: loss = 2.0110 (0.753 sec/step)\n","INFO:tensorflow:global step 3693: loss = 1.9891 (0.756 sec/step)\n","I0908 16:15:19.740619 140650862335872 learning.py:512] global step 3693: loss = 1.9891 (0.756 sec/step)\n","INFO:tensorflow:global step 3694: loss = 1.9393 (0.756 sec/step)\n","I0908 16:15:20.498782 140650862335872 learning.py:512] global step 3694: loss = 1.9393 (0.756 sec/step)\n","INFO:tensorflow:global step 3695: loss = 1.9469 (0.763 sec/step)\n","I0908 16:15:21.263605 140650862335872 learning.py:512] global step 3695: loss = 1.9469 (0.763 sec/step)\n","INFO:tensorflow:global step 3696: loss = 2.2211 (0.770 sec/step)\n","I0908 16:15:22.035452 140650862335872 learning.py:512] global step 3696: loss = 2.2211 (0.770 sec/step)\n","INFO:tensorflow:global step 3697: loss = 2.0958 (0.759 sec/step)\n","I0908 16:15:22.796262 140650862335872 learning.py:512] global step 3697: loss = 2.0958 (0.759 sec/step)\n","INFO:tensorflow:global step 3698: loss = 1.8756 (0.781 sec/step)\n","I0908 16:15:23.579082 140650862335872 learning.py:512] global step 3698: loss = 1.8756 (0.781 sec/step)\n","INFO:tensorflow:global step 3699: loss = 2.0889 (0.765 sec/step)\n","I0908 16:15:24.345669 140650862335872 learning.py:512] global step 3699: loss = 2.0889 (0.765 sec/step)\n","INFO:tensorflow:global step 3700: loss = 1.8410 (0.766 sec/step)\n","I0908 16:15:25.113691 140650862335872 learning.py:512] global step 3700: loss = 1.8410 (0.766 sec/step)\n","INFO:tensorflow:global step 3701: loss = 1.9066 (0.767 sec/step)\n","I0908 16:15:25.882558 140650862335872 learning.py:512] global step 3701: loss = 1.9066 (0.767 sec/step)\n","INFO:tensorflow:global step 3702: loss = 1.8753 (0.778 sec/step)\n","I0908 16:15:26.662173 140650862335872 learning.py:512] global step 3702: loss = 1.8753 (0.778 sec/step)\n","INFO:tensorflow:global step 3703: loss = 1.9061 (0.775 sec/step)\n","I0908 16:15:27.439415 140650862335872 learning.py:512] global step 3703: loss = 1.9061 (0.775 sec/step)\n","INFO:tensorflow:global step 3704: loss = 2.5220 (0.747 sec/step)\n","I0908 16:15:28.187816 140650862335872 learning.py:512] global step 3704: loss = 2.5220 (0.747 sec/step)\n","INFO:tensorflow:global step 3705: loss = 2.0877 (0.769 sec/step)\n","I0908 16:15:28.958075 140650862335872 learning.py:512] global step 3705: loss = 2.0877 (0.769 sec/step)\n","INFO:tensorflow:global step 3706: loss = 2.3544 (0.771 sec/step)\n","I0908 16:15:29.731095 140650862335872 learning.py:512] global step 3706: loss = 2.3544 (0.771 sec/step)\n","INFO:tensorflow:global step 3707: loss = 1.9593 (0.766 sec/step)\n","I0908 16:15:30.498822 140650862335872 learning.py:512] global step 3707: loss = 1.9593 (0.766 sec/step)\n","INFO:tensorflow:global step 3708: loss = 2.1783 (0.760 sec/step)\n","I0908 16:15:31.260344 140650862335872 learning.py:512] global step 3708: loss = 2.1783 (0.760 sec/step)\n","INFO:tensorflow:global step 3709: loss = 2.2354 (0.765 sec/step)\n","I0908 16:15:32.027384 140650862335872 learning.py:512] global step 3709: loss = 2.2354 (0.765 sec/step)\n","INFO:tensorflow:global step 3710: loss = 1.9655 (0.764 sec/step)\n","I0908 16:15:32.793526 140650862335872 learning.py:512] global step 3710: loss = 1.9655 (0.764 sec/step)\n","INFO:tensorflow:global step 3711: loss = 2.2100 (0.744 sec/step)\n","I0908 16:15:33.539534 140650862335872 learning.py:512] global step 3711: loss = 2.2100 (0.744 sec/step)\n","INFO:tensorflow:global step 3712: loss = 1.7122 (0.750 sec/step)\n","I0908 16:15:34.291476 140650862335872 learning.py:512] global step 3712: loss = 1.7122 (0.750 sec/step)\n","INFO:tensorflow:global step 3713: loss = 2.3644 (0.765 sec/step)\n","I0908 16:15:35.058345 140650862335872 learning.py:512] global step 3713: loss = 2.3644 (0.765 sec/step)\n","INFO:tensorflow:global step 3714: loss = 1.7837 (0.781 sec/step)\n","I0908 16:15:35.841020 140650862335872 learning.py:512] global step 3714: loss = 1.7837 (0.781 sec/step)\n","INFO:tensorflow:global step 3715: loss = 1.9069 (0.771 sec/step)\n","I0908 16:15:36.614078 140650862335872 learning.py:512] global step 3715: loss = 1.9069 (0.771 sec/step)\n","INFO:tensorflow:global step 3716: loss = 2.1697 (0.765 sec/step)\n","I0908 16:15:37.380934 140650862335872 learning.py:512] global step 3716: loss = 2.1697 (0.765 sec/step)\n","INFO:tensorflow:global step 3717: loss = 2.0198 (0.756 sec/step)\n","I0908 16:15:38.139176 140650862335872 learning.py:512] global step 3717: loss = 2.0198 (0.756 sec/step)\n","INFO:tensorflow:global step 3718: loss = 2.0307 (0.763 sec/step)\n","I0908 16:15:38.904581 140650862335872 learning.py:512] global step 3718: loss = 2.0307 (0.763 sec/step)\n","INFO:tensorflow:global step 3719: loss = 1.8738 (0.744 sec/step)\n","I0908 16:15:39.651076 140650862335872 learning.py:512] global step 3719: loss = 1.8738 (0.744 sec/step)\n","INFO:tensorflow:global step 3720: loss = 2.2241 (0.772 sec/step)\n","I0908 16:15:40.424566 140650862335872 learning.py:512] global step 3720: loss = 2.2241 (0.772 sec/step)\n","INFO:tensorflow:global step 3721: loss = 2.1889 (0.769 sec/step)\n","I0908 16:15:41.195008 140650862335872 learning.py:512] global step 3721: loss = 2.1889 (0.769 sec/step)\n","INFO:tensorflow:global step 3722: loss = 2.4474 (0.757 sec/step)\n","I0908 16:15:41.953257 140650862335872 learning.py:512] global step 3722: loss = 2.4474 (0.757 sec/step)\n","INFO:tensorflow:global step 3723: loss = 2.3068 (0.739 sec/step)\n","I0908 16:15:42.694497 140650862335872 learning.py:512] global step 3723: loss = 2.3068 (0.739 sec/step)\n","INFO:tensorflow:global step 3724: loss = 2.3795 (0.738 sec/step)\n","I0908 16:15:43.433957 140650862335872 learning.py:512] global step 3724: loss = 2.3795 (0.738 sec/step)\n","INFO:tensorflow:global step 3725: loss = 2.0043 (0.774 sec/step)\n","I0908 16:15:44.209298 140650862335872 learning.py:512] global step 3725: loss = 2.0043 (0.774 sec/step)\n","INFO:tensorflow:global step 3726: loss = 2.4963 (0.759 sec/step)\n","I0908 16:15:44.970149 140650862335872 learning.py:512] global step 3726: loss = 2.4963 (0.759 sec/step)\n","INFO:tensorflow:global step 3727: loss = 2.1342 (0.749 sec/step)\n","I0908 16:15:45.721151 140650862335872 learning.py:512] global step 3727: loss = 2.1342 (0.749 sec/step)\n","INFO:tensorflow:global step 3728: loss = 2.2257 (0.867 sec/step)\n","I0908 16:15:46.590520 140650862335872 learning.py:512] global step 3728: loss = 2.2257 (0.867 sec/step)\n","INFO:tensorflow:Recording summary at step 3728.\n","I0908 16:15:47.548002 140646941251328 supervisor.py:1050] Recording summary at step 3728.\n","INFO:tensorflow:global step 3729: loss = 1.9687 (1.162 sec/step)\n","I0908 16:15:47.762755 140650862335872 learning.py:512] global step 3729: loss = 1.9687 (1.162 sec/step)\n","INFO:tensorflow:global step 3730: loss = 1.8746 (0.772 sec/step)\n","I0908 16:15:48.536314 140650862335872 learning.py:512] global step 3730: loss = 1.8746 (0.772 sec/step)\n","INFO:tensorflow:global step 3731: loss = 2.8882 (0.760 sec/step)\n","I0908 16:15:49.297812 140650862335872 learning.py:512] global step 3731: loss = 2.8882 (0.760 sec/step)\n","INFO:tensorflow:global step 3732: loss = 2.1783 (0.771 sec/step)\n","I0908 16:15:50.070429 140650862335872 learning.py:512] global step 3732: loss = 2.1783 (0.771 sec/step)\n","INFO:tensorflow:global step 3733: loss = 2.0132 (0.749 sec/step)\n","I0908 16:15:50.821433 140650862335872 learning.py:512] global step 3733: loss = 2.0132 (0.749 sec/step)\n","INFO:tensorflow:global step 3734: loss = 1.7255 (0.769 sec/step)\n","I0908 16:15:51.591848 140650862335872 learning.py:512] global step 3734: loss = 1.7255 (0.769 sec/step)\n","INFO:tensorflow:global step 3735: loss = 2.2992 (0.767 sec/step)\n","I0908 16:15:52.360511 140650862335872 learning.py:512] global step 3735: loss = 2.2992 (0.767 sec/step)\n","INFO:tensorflow:global step 3736: loss = 1.6942 (0.755 sec/step)\n","I0908 16:15:53.116890 140650862335872 learning.py:512] global step 3736: loss = 1.6942 (0.755 sec/step)\n","INFO:tensorflow:global step 3737: loss = 1.9698 (0.752 sec/step)\n","I0908 16:15:53.870488 140650862335872 learning.py:512] global step 3737: loss = 1.9698 (0.752 sec/step)\n","INFO:tensorflow:global step 3738: loss = 1.7764 (0.765 sec/step)\n","I0908 16:15:54.637147 140650862335872 learning.py:512] global step 3738: loss = 1.7764 (0.765 sec/step)\n","INFO:tensorflow:global step 3739: loss = 2.3041 (0.773 sec/step)\n","I0908 16:15:55.411432 140650862335872 learning.py:512] global step 3739: loss = 2.3041 (0.773 sec/step)\n","INFO:tensorflow:global step 3740: loss = 2.3561 (0.749 sec/step)\n","I0908 16:15:56.161706 140650862335872 learning.py:512] global step 3740: loss = 2.3561 (0.749 sec/step)\n","INFO:tensorflow:global step 3741: loss = 2.0734 (0.759 sec/step)\n","I0908 16:15:56.922481 140650862335872 learning.py:512] global step 3741: loss = 2.0734 (0.759 sec/step)\n","INFO:tensorflow:global step 3742: loss = 1.9979 (0.769 sec/step)\n","I0908 16:15:57.692639 140650862335872 learning.py:512] global step 3742: loss = 1.9979 (0.769 sec/step)\n","INFO:tensorflow:global step 3743: loss = 2.2045 (0.771 sec/step)\n","I0908 16:15:58.465169 140650862335872 learning.py:512] global step 3743: loss = 2.2045 (0.771 sec/step)\n","INFO:tensorflow:global step 3744: loss = 2.3583 (0.738 sec/step)\n","I0908 16:15:59.205051 140650862335872 learning.py:512] global step 3744: loss = 2.3583 (0.738 sec/step)\n","INFO:tensorflow:global step 3745: loss = 1.8936 (0.771 sec/step)\n","I0908 16:15:59.978053 140650862335872 learning.py:512] global step 3745: loss = 1.8936 (0.771 sec/step)\n","INFO:tensorflow:global step 3746: loss = 2.2482 (0.758 sec/step)\n","I0908 16:16:00.738322 140650862335872 learning.py:512] global step 3746: loss = 2.2482 (0.758 sec/step)\n","INFO:tensorflow:global step 3747: loss = 1.8741 (0.771 sec/step)\n","I0908 16:16:01.511212 140650862335872 learning.py:512] global step 3747: loss = 1.8741 (0.771 sec/step)\n","INFO:tensorflow:global step 3748: loss = 1.8767 (0.752 sec/step)\n","I0908 16:16:02.265018 140650862335872 learning.py:512] global step 3748: loss = 1.8767 (0.752 sec/step)\n","INFO:tensorflow:global step 3749: loss = 1.8488 (0.754 sec/step)\n","I0908 16:16:03.020509 140650862335872 learning.py:512] global step 3749: loss = 1.8488 (0.754 sec/step)\n","INFO:tensorflow:global step 3750: loss = 1.6994 (0.750 sec/step)\n","I0908 16:16:03.771789 140650862335872 learning.py:512] global step 3750: loss = 1.6994 (0.750 sec/step)\n","INFO:tensorflow:global step 3751: loss = 1.9004 (0.754 sec/step)\n","I0908 16:16:04.527865 140650862335872 learning.py:512] global step 3751: loss = 1.9004 (0.754 sec/step)\n","INFO:tensorflow:global step 3752: loss = 1.8420 (0.745 sec/step)\n","I0908 16:16:05.274973 140650862335872 learning.py:512] global step 3752: loss = 1.8420 (0.745 sec/step)\n","INFO:tensorflow:global step 3753: loss = 2.0409 (0.767 sec/step)\n","I0908 16:16:06.043676 140650862335872 learning.py:512] global step 3753: loss = 2.0409 (0.767 sec/step)\n","INFO:tensorflow:global step 3754: loss = 1.7550 (0.745 sec/step)\n","I0908 16:16:06.790320 140650862335872 learning.py:512] global step 3754: loss = 1.7550 (0.745 sec/step)\n","INFO:tensorflow:global step 3755: loss = 2.0787 (0.780 sec/step)\n","I0908 16:16:07.571985 140650862335872 learning.py:512] global step 3755: loss = 2.0787 (0.780 sec/step)\n","INFO:tensorflow:global step 3756: loss = 2.1024 (0.773 sec/step)\n","I0908 16:16:08.346786 140650862335872 learning.py:512] global step 3756: loss = 2.1024 (0.773 sec/step)\n","INFO:tensorflow:global step 3757: loss = 1.9741 (0.766 sec/step)\n","I0908 16:16:09.114697 140650862335872 learning.py:512] global step 3757: loss = 1.9741 (0.766 sec/step)\n","INFO:tensorflow:global step 3758: loss = 1.9811 (0.759 sec/step)\n","I0908 16:16:09.875087 140650862335872 learning.py:512] global step 3758: loss = 1.9811 (0.759 sec/step)\n","INFO:tensorflow:global step 3759: loss = 2.2371 (0.770 sec/step)\n","I0908 16:16:10.646246 140650862335872 learning.py:512] global step 3759: loss = 2.2371 (0.770 sec/step)\n","INFO:tensorflow:global step 3760: loss = 2.6721 (0.776 sec/step)\n","I0908 16:16:11.424002 140650862335872 learning.py:512] global step 3760: loss = 2.6721 (0.776 sec/step)\n","INFO:tensorflow:global step 3761: loss = 2.7633 (0.753 sec/step)\n","I0908 16:16:12.178228 140650862335872 learning.py:512] global step 3761: loss = 2.7633 (0.753 sec/step)\n","INFO:tensorflow:global step 3762: loss = 2.0994 (0.767 sec/step)\n","I0908 16:16:12.946617 140650862335872 learning.py:512] global step 3762: loss = 2.0994 (0.767 sec/step)\n","INFO:tensorflow:global step 3763: loss = 1.7925 (0.753 sec/step)\n","I0908 16:16:13.701597 140650862335872 learning.py:512] global step 3763: loss = 1.7925 (0.753 sec/step)\n","INFO:tensorflow:global step 3764: loss = 1.8979 (0.752 sec/step)\n","I0908 16:16:14.455249 140650862335872 learning.py:512] global step 3764: loss = 1.8979 (0.752 sec/step)\n","INFO:tensorflow:global step 3765: loss = 2.4622 (0.752 sec/step)\n","I0908 16:16:15.208870 140650862335872 learning.py:512] global step 3765: loss = 2.4622 (0.752 sec/step)\n","INFO:tensorflow:global step 3766: loss = 1.7527 (0.758 sec/step)\n","I0908 16:16:15.969090 140650862335872 learning.py:512] global step 3766: loss = 1.7527 (0.758 sec/step)\n","INFO:tensorflow:global step 3767: loss = 1.6365 (0.782 sec/step)\n","I0908 16:16:16.752624 140650862335872 learning.py:512] global step 3767: loss = 1.6365 (0.782 sec/step)\n","INFO:tensorflow:global step 3768: loss = 1.8499 (0.749 sec/step)\n","I0908 16:16:17.503538 140650862335872 learning.py:512] global step 3768: loss = 1.8499 (0.749 sec/step)\n","INFO:tensorflow:global step 3769: loss = 2.0240 (0.761 sec/step)\n","I0908 16:16:18.266103 140650862335872 learning.py:512] global step 3769: loss = 2.0240 (0.761 sec/step)\n","INFO:tensorflow:global step 3770: loss = 2.3080 (0.758 sec/step)\n","I0908 16:16:19.026415 140650862335872 learning.py:512] global step 3770: loss = 2.3080 (0.758 sec/step)\n","INFO:tensorflow:global step 3771: loss = 1.7313 (0.750 sec/step)\n","I0908 16:16:19.777716 140650862335872 learning.py:512] global step 3771: loss = 1.7313 (0.750 sec/step)\n","INFO:tensorflow:global step 3772: loss = 2.2556 (0.761 sec/step)\n","I0908 16:16:20.540678 140650862335872 learning.py:512] global step 3772: loss = 2.2556 (0.761 sec/step)\n","INFO:tensorflow:global step 3773: loss = 2.0052 (0.766 sec/step)\n","I0908 16:16:21.308407 140650862335872 learning.py:512] global step 3773: loss = 2.0052 (0.766 sec/step)\n","INFO:tensorflow:global step 3774: loss = 1.9323 (0.762 sec/step)\n","I0908 16:16:22.071599 140650862335872 learning.py:512] global step 3774: loss = 1.9323 (0.762 sec/step)\n","INFO:tensorflow:global step 3775: loss = 1.8818 (0.763 sec/step)\n","I0908 16:16:22.836533 140650862335872 learning.py:512] global step 3775: loss = 1.8818 (0.763 sec/step)\n","INFO:tensorflow:global step 3776: loss = 2.4283 (0.747 sec/step)\n","I0908 16:16:23.584837 140650862335872 learning.py:512] global step 3776: loss = 2.4283 (0.747 sec/step)\n","INFO:tensorflow:global step 3777: loss = 1.8557 (0.758 sec/step)\n","I0908 16:16:24.344712 140650862335872 learning.py:512] global step 3777: loss = 1.8557 (0.758 sec/step)\n","INFO:tensorflow:global step 3778: loss = 1.6635 (0.744 sec/step)\n","I0908 16:16:25.090487 140650862335872 learning.py:512] global step 3778: loss = 1.6635 (0.744 sec/step)\n","INFO:tensorflow:global step 3779: loss = 1.4646 (0.774 sec/step)\n","I0908 16:16:25.866129 140650862335872 learning.py:512] global step 3779: loss = 1.4646 (0.774 sec/step)\n","INFO:tensorflow:global step 3780: loss = 2.0742 (0.770 sec/step)\n","I0908 16:16:26.637254 140650862335872 learning.py:512] global step 3780: loss = 2.0742 (0.770 sec/step)\n","INFO:tensorflow:global step 3781: loss = 1.9446 (0.750 sec/step)\n","I0908 16:16:27.389431 140650862335872 learning.py:512] global step 3781: loss = 1.9446 (0.750 sec/step)\n","INFO:tensorflow:global step 3782: loss = 1.5973 (0.747 sec/step)\n","I0908 16:16:28.137816 140650862335872 learning.py:512] global step 3782: loss = 1.5973 (0.747 sec/step)\n","INFO:tensorflow:global step 3783: loss = 1.6156 (0.761 sec/step)\n","I0908 16:16:28.900652 140650862335872 learning.py:512] global step 3783: loss = 1.6156 (0.761 sec/step)\n","INFO:tensorflow:global step 3784: loss = 2.4389 (0.762 sec/step)\n","I0908 16:16:29.663863 140650862335872 learning.py:512] global step 3784: loss = 2.4389 (0.762 sec/step)\n","INFO:tensorflow:global step 3785: loss = 1.7047 (0.759 sec/step)\n","I0908 16:16:30.424566 140650862335872 learning.py:512] global step 3785: loss = 1.7047 (0.759 sec/step)\n","INFO:tensorflow:global step 3786: loss = 1.7990 (0.747 sec/step)\n","I0908 16:16:31.173672 140650862335872 learning.py:512] global step 3786: loss = 1.7990 (0.747 sec/step)\n","INFO:tensorflow:global step 3787: loss = 2.1163 (0.796 sec/step)\n","I0908 16:16:31.971339 140650862335872 learning.py:512] global step 3787: loss = 2.1163 (0.796 sec/step)\n","INFO:tensorflow:global step 3788: loss = 2.0982 (0.762 sec/step)\n","I0908 16:16:32.734681 140650862335872 learning.py:512] global step 3788: loss = 2.0982 (0.762 sec/step)\n","INFO:tensorflow:global step 3789: loss = 1.7718 (0.762 sec/step)\n","I0908 16:16:33.499360 140650862335872 learning.py:512] global step 3789: loss = 1.7718 (0.762 sec/step)\n","INFO:tensorflow:global step 3790: loss = 1.9013 (0.758 sec/step)\n","I0908 16:16:34.259247 140650862335872 learning.py:512] global step 3790: loss = 1.9013 (0.758 sec/step)\n","INFO:tensorflow:global step 3791: loss = 2.5245 (0.763 sec/step)\n","I0908 16:16:35.023552 140650862335872 learning.py:512] global step 3791: loss = 2.5245 (0.763 sec/step)\n","INFO:tensorflow:global step 3792: loss = 1.8558 (0.758 sec/step)\n","I0908 16:16:35.783804 140650862335872 learning.py:512] global step 3792: loss = 1.8558 (0.758 sec/step)\n","INFO:tensorflow:global step 3793: loss = 1.9765 (0.753 sec/step)\n","I0908 16:16:36.538893 140650862335872 learning.py:512] global step 3793: loss = 1.9765 (0.753 sec/step)\n","INFO:tensorflow:global step 3794: loss = 1.6968 (0.748 sec/step)\n","I0908 16:16:37.288404 140650862335872 learning.py:512] global step 3794: loss = 1.6968 (0.748 sec/step)\n","INFO:tensorflow:global step 3795: loss = 2.1301 (0.757 sec/step)\n","I0908 16:16:38.047433 140650862335872 learning.py:512] global step 3795: loss = 2.1301 (0.757 sec/step)\n","INFO:tensorflow:global step 3796: loss = 2.0533 (0.758 sec/step)\n","I0908 16:16:38.807048 140650862335872 learning.py:512] global step 3796: loss = 2.0533 (0.758 sec/step)\n","INFO:tensorflow:global step 3797: loss = 2.0147 (0.737 sec/step)\n","I0908 16:16:39.547151 140650862335872 learning.py:512] global step 3797: loss = 2.0147 (0.737 sec/step)\n","INFO:tensorflow:global step 3798: loss = 1.5564 (0.765 sec/step)\n","I0908 16:16:40.313729 140650862335872 learning.py:512] global step 3798: loss = 1.5564 (0.765 sec/step)\n","INFO:tensorflow:global step 3799: loss = 1.8257 (0.756 sec/step)\n","I0908 16:16:41.071979 140650862335872 learning.py:512] global step 3799: loss = 1.8257 (0.756 sec/step)\n","INFO:tensorflow:global step 3800: loss = 1.9231 (0.773 sec/step)\n","I0908 16:16:41.847005 140650862335872 learning.py:512] global step 3800: loss = 1.9231 (0.773 sec/step)\n","INFO:tensorflow:global step 3801: loss = 2.2005 (0.770 sec/step)\n","I0908 16:16:42.619015 140650862335872 learning.py:512] global step 3801: loss = 2.2005 (0.770 sec/step)\n","INFO:tensorflow:global step 3802: loss = 2.4024 (0.783 sec/step)\n","I0908 16:16:43.403669 140650862335872 learning.py:512] global step 3802: loss = 2.4024 (0.783 sec/step)\n","INFO:tensorflow:global step 3803: loss = 1.8957 (0.768 sec/step)\n","I0908 16:16:44.173569 140650862335872 learning.py:512] global step 3803: loss = 1.8957 (0.768 sec/step)\n","INFO:tensorflow:global step 3804: loss = 1.6922 (0.761 sec/step)\n","I0908 16:16:44.935785 140650862335872 learning.py:512] global step 3804: loss = 1.6922 (0.761 sec/step)\n","INFO:tensorflow:global step 3805: loss = 2.7833 (0.748 sec/step)\n","I0908 16:16:45.685595 140650862335872 learning.py:512] global step 3805: loss = 2.7833 (0.748 sec/step)\n","INFO:tensorflow:global step 3806: loss = 2.0226 (0.773 sec/step)\n","I0908 16:16:46.460481 140650862335872 learning.py:512] global step 3806: loss = 2.0226 (0.773 sec/step)\n","INFO:tensorflow:global step 3807: loss = 2.1753 (0.755 sec/step)\n","I0908 16:16:47.216661 140650862335872 learning.py:512] global step 3807: loss = 2.1753 (0.755 sec/step)\n","INFO:tensorflow:global step 3808: loss = 1.9207 (0.760 sec/step)\n","I0908 16:16:47.978644 140650862335872 learning.py:512] global step 3808: loss = 1.9207 (0.760 sec/step)\n","INFO:tensorflow:global step 3809: loss = 2.5092 (0.729 sec/step)\n","I0908 16:16:48.710059 140650862335872 learning.py:512] global step 3809: loss = 2.5092 (0.729 sec/step)\n","INFO:tensorflow:global step 3810: loss = 2.0929 (0.764 sec/step)\n","I0908 16:16:49.475813 140650862335872 learning.py:512] global step 3810: loss = 2.0929 (0.764 sec/step)\n","INFO:tensorflow:global step 3811: loss = 2.1351 (0.777 sec/step)\n","I0908 16:16:50.254023 140650862335872 learning.py:512] global step 3811: loss = 2.1351 (0.777 sec/step)\n","INFO:tensorflow:global step 3812: loss = 2.0160 (0.759 sec/step)\n","I0908 16:16:51.014450 140650862335872 learning.py:512] global step 3812: loss = 2.0160 (0.759 sec/step)\n","INFO:tensorflow:global step 3813: loss = 1.8423 (0.752 sec/step)\n","I0908 16:16:51.768201 140650862335872 learning.py:512] global step 3813: loss = 1.8423 (0.752 sec/step)\n","INFO:tensorflow:global step 3814: loss = 1.8527 (0.764 sec/step)\n","I0908 16:16:52.533810 140650862335872 learning.py:512] global step 3814: loss = 1.8527 (0.764 sec/step)\n","INFO:tensorflow:global step 3815: loss = 1.8365 (0.775 sec/step)\n","I0908 16:16:53.311079 140650862335872 learning.py:512] global step 3815: loss = 1.8365 (0.775 sec/step)\n","INFO:tensorflow:global step 3816: loss = 2.3690 (0.744 sec/step)\n","I0908 16:16:54.056643 140650862335872 learning.py:512] global step 3816: loss = 2.3690 (0.744 sec/step)\n","INFO:tensorflow:global step 3817: loss = 2.3093 (0.760 sec/step)\n","I0908 16:16:54.821523 140650862335872 learning.py:512] global step 3817: loss = 2.3093 (0.760 sec/step)\n","INFO:tensorflow:global step 3818: loss = 2.0074 (0.758 sec/step)\n","I0908 16:16:55.581098 140650862335872 learning.py:512] global step 3818: loss = 2.0074 (0.758 sec/step)\n","INFO:tensorflow:global step 3819: loss = 2.3093 (0.758 sec/step)\n","I0908 16:16:56.340434 140650862335872 learning.py:512] global step 3819: loss = 2.3093 (0.758 sec/step)\n","INFO:tensorflow:global step 3820: loss = 2.0521 (0.758 sec/step)\n","I0908 16:16:57.099675 140650862335872 learning.py:512] global step 3820: loss = 2.0521 (0.758 sec/step)\n","INFO:tensorflow:global step 3821: loss = 1.6090 (0.752 sec/step)\n","I0908 16:16:57.853082 140650862335872 learning.py:512] global step 3821: loss = 1.6090 (0.752 sec/step)\n","INFO:tensorflow:global step 3822: loss = 1.8149 (0.767 sec/step)\n","I0908 16:16:58.622188 140650862335872 learning.py:512] global step 3822: loss = 1.8149 (0.767 sec/step)\n","INFO:tensorflow:global step 3823: loss = 2.2598 (0.753 sec/step)\n","I0908 16:16:59.377192 140650862335872 learning.py:512] global step 3823: loss = 2.2598 (0.753 sec/step)\n","INFO:tensorflow:global step 3824: loss = 2.0055 (0.757 sec/step)\n","I0908 16:17:00.137313 140650862335872 learning.py:512] global step 3824: loss = 2.0055 (0.757 sec/step)\n","INFO:tensorflow:global step 3825: loss = 1.6516 (0.778 sec/step)\n","I0908 16:17:00.917142 140650862335872 learning.py:512] global step 3825: loss = 1.6516 (0.778 sec/step)\n","INFO:tensorflow:global step 3826: loss = 2.2760 (0.775 sec/step)\n","I0908 16:17:01.694141 140650862335872 learning.py:512] global step 3826: loss = 2.2760 (0.775 sec/step)\n","INFO:tensorflow:global step 3827: loss = 2.1913 (0.765 sec/step)\n","I0908 16:17:02.461097 140650862335872 learning.py:512] global step 3827: loss = 2.1913 (0.765 sec/step)\n","INFO:tensorflow:global step 3828: loss = 1.9896 (0.766 sec/step)\n","I0908 16:17:03.228265 140650862335872 learning.py:512] global step 3828: loss = 1.9896 (0.766 sec/step)\n","INFO:tensorflow:global step 3829: loss = 2.0839 (0.758 sec/step)\n","I0908 16:17:03.988465 140650862335872 learning.py:512] global step 3829: loss = 2.0839 (0.758 sec/step)\n","INFO:tensorflow:global step 3830: loss = 1.9009 (0.757 sec/step)\n","I0908 16:17:04.747078 140650862335872 learning.py:512] global step 3830: loss = 1.9009 (0.757 sec/step)\n","INFO:tensorflow:global step 3831: loss = 1.9914 (0.747 sec/step)\n","I0908 16:17:05.495929 140650862335872 learning.py:512] global step 3831: loss = 1.9914 (0.747 sec/step)\n","INFO:tensorflow:global step 3832: loss = 1.6634 (0.766 sec/step)\n","I0908 16:17:06.263440 140650862335872 learning.py:512] global step 3832: loss = 1.6634 (0.766 sec/step)\n","INFO:tensorflow:global step 3833: loss = 2.5088 (0.748 sec/step)\n","I0908 16:17:07.013334 140650862335872 learning.py:512] global step 3833: loss = 2.5088 (0.748 sec/step)\n","INFO:tensorflow:global step 3834: loss = 2.3629 (0.746 sec/step)\n","I0908 16:17:07.761019 140650862335872 learning.py:512] global step 3834: loss = 2.3629 (0.746 sec/step)\n","INFO:tensorflow:global step 3835: loss = 2.1005 (0.746 sec/step)\n","I0908 16:17:08.508442 140650862335872 learning.py:512] global step 3835: loss = 2.1005 (0.746 sec/step)\n","INFO:tensorflow:global step 3836: loss = 1.8861 (0.742 sec/step)\n","I0908 16:17:09.252537 140650862335872 learning.py:512] global step 3836: loss = 1.8861 (0.742 sec/step)\n","INFO:tensorflow:global step 3837: loss = 2.0804 (0.757 sec/step)\n","I0908 16:17:10.011703 140650862335872 learning.py:512] global step 3837: loss = 2.0804 (0.757 sec/step)\n","INFO:tensorflow:global step 3838: loss = 1.9882 (0.743 sec/step)\n","I0908 16:17:10.756666 140650862335872 learning.py:512] global step 3838: loss = 1.9882 (0.743 sec/step)\n","INFO:tensorflow:global step 3839: loss = 1.8927 (0.741 sec/step)\n","I0908 16:17:11.498890 140650862335872 learning.py:512] global step 3839: loss = 1.8927 (0.741 sec/step)\n","INFO:tensorflow:global step 3840: loss = 2.4331 (0.757 sec/step)\n","I0908 16:17:12.257123 140650862335872 learning.py:512] global step 3840: loss = 2.4331 (0.757 sec/step)\n","INFO:tensorflow:global step 3841: loss = 2.1947 (0.763 sec/step)\n","I0908 16:17:13.022268 140650862335872 learning.py:512] global step 3841: loss = 2.1947 (0.763 sec/step)\n","INFO:tensorflow:global step 3842: loss = 1.9892 (0.771 sec/step)\n","I0908 16:17:13.795230 140650862335872 learning.py:512] global step 3842: loss = 1.9892 (0.771 sec/step)\n","INFO:tensorflow:global step 3843: loss = 2.2896 (0.774 sec/step)\n","I0908 16:17:14.571295 140650862335872 learning.py:512] global step 3843: loss = 2.2896 (0.774 sec/step)\n","INFO:tensorflow:global step 3844: loss = 2.0338 (0.759 sec/step)\n","I0908 16:17:15.331877 140650862335872 learning.py:512] global step 3844: loss = 2.0338 (0.759 sec/step)\n","INFO:tensorflow:global step 3845: loss = 2.0999 (0.759 sec/step)\n","I0908 16:17:16.092859 140650862335872 learning.py:512] global step 3845: loss = 2.0999 (0.759 sec/step)\n","INFO:tensorflow:global step 3846: loss = 2.1544 (0.750 sec/step)\n","I0908 16:17:16.844549 140650862335872 learning.py:512] global step 3846: loss = 2.1544 (0.750 sec/step)\n","INFO:tensorflow:global step 3847: loss = 1.9855 (0.767 sec/step)\n","I0908 16:17:17.613572 140650862335872 learning.py:512] global step 3847: loss = 1.9855 (0.767 sec/step)\n","INFO:tensorflow:global step 3848: loss = 2.3030 (0.756 sec/step)\n","I0908 16:17:18.371615 140650862335872 learning.py:512] global step 3848: loss = 2.3030 (0.756 sec/step)\n","INFO:tensorflow:global step 3849: loss = 2.1086 (0.748 sec/step)\n","I0908 16:17:19.121457 140650862335872 learning.py:512] global step 3849: loss = 2.1086 (0.748 sec/step)\n","INFO:tensorflow:global step 3850: loss = 2.0295 (0.742 sec/step)\n","I0908 16:17:19.865167 140650862335872 learning.py:512] global step 3850: loss = 2.0295 (0.742 sec/step)\n","INFO:tensorflow:global step 3851: loss = 2.3335 (0.764 sec/step)\n","I0908 16:17:20.631119 140650862335872 learning.py:512] global step 3851: loss = 2.3335 (0.764 sec/step)\n","INFO:tensorflow:global step 3852: loss = 2.9259 (0.759 sec/step)\n","I0908 16:17:21.392110 140650862335872 learning.py:512] global step 3852: loss = 2.9259 (0.759 sec/step)\n","INFO:tensorflow:global step 3853: loss = 2.1342 (0.755 sec/step)\n","I0908 16:17:22.148526 140650862335872 learning.py:512] global step 3853: loss = 2.1342 (0.755 sec/step)\n","INFO:tensorflow:global step 3854: loss = 2.5281 (0.753 sec/step)\n","I0908 16:17:22.903720 140650862335872 learning.py:512] global step 3854: loss = 2.5281 (0.753 sec/step)\n","INFO:tensorflow:global step 3855: loss = 2.2673 (0.777 sec/step)\n","I0908 16:17:23.682230 140650862335872 learning.py:512] global step 3855: loss = 2.2673 (0.777 sec/step)\n","INFO:tensorflow:global step 3856: loss = 2.0628 (0.776 sec/step)\n","I0908 16:17:24.460087 140650862335872 learning.py:512] global step 3856: loss = 2.0628 (0.776 sec/step)\n","INFO:tensorflow:global step 3857: loss = 2.2219 (0.766 sec/step)\n","I0908 16:17:25.227838 140650862335872 learning.py:512] global step 3857: loss = 2.2219 (0.766 sec/step)\n","INFO:tensorflow:global step 3858: loss = 1.9156 (0.758 sec/step)\n","I0908 16:17:25.987604 140650862335872 learning.py:512] global step 3858: loss = 1.9156 (0.758 sec/step)\n","INFO:tensorflow:global step 3859: loss = 1.8431 (0.769 sec/step)\n","I0908 16:17:26.758219 140650862335872 learning.py:512] global step 3859: loss = 1.8431 (0.769 sec/step)\n","INFO:tensorflow:global step 3860: loss = 2.4242 (0.788 sec/step)\n","I0908 16:17:27.547739 140650862335872 learning.py:512] global step 3860: loss = 2.4242 (0.788 sec/step)\n","INFO:tensorflow:global step 3861: loss = 2.1674 (0.748 sec/step)\n","I0908 16:17:28.297111 140650862335872 learning.py:512] global step 3861: loss = 2.1674 (0.748 sec/step)\n","INFO:tensorflow:global step 3862: loss = 2.2135 (0.773 sec/step)\n","I0908 16:17:29.072007 140650862335872 learning.py:512] global step 3862: loss = 2.2135 (0.773 sec/step)\n","INFO:tensorflow:global step 3863: loss = 2.4287 (0.755 sec/step)\n","I0908 16:17:29.828451 140650862335872 learning.py:512] global step 3863: loss = 2.4287 (0.755 sec/step)\n","INFO:tensorflow:global step 3864: loss = 1.9851 (0.758 sec/step)\n","I0908 16:17:30.588553 140650862335872 learning.py:512] global step 3864: loss = 1.9851 (0.758 sec/step)\n","INFO:tensorflow:global step 3865: loss = 1.9453 (0.729 sec/step)\n","I0908 16:17:31.319762 140650862335872 learning.py:512] global step 3865: loss = 1.9453 (0.729 sec/step)\n","INFO:tensorflow:global step 3866: loss = 2.0419 (0.758 sec/step)\n","I0908 16:17:32.079407 140650862335872 learning.py:512] global step 3866: loss = 2.0419 (0.758 sec/step)\n","INFO:tensorflow:global step 3867: loss = 2.1925 (0.786 sec/step)\n","I0908 16:17:32.866726 140650862335872 learning.py:512] global step 3867: loss = 2.1925 (0.786 sec/step)\n","INFO:tensorflow:global step 3868: loss = 2.2259 (0.756 sec/step)\n","I0908 16:17:33.624865 140650862335872 learning.py:512] global step 3868: loss = 2.2259 (0.756 sec/step)\n","INFO:tensorflow:global step 3869: loss = 1.9674 (0.760 sec/step)\n","I0908 16:17:34.386459 140650862335872 learning.py:512] global step 3869: loss = 1.9674 (0.760 sec/step)\n","INFO:tensorflow:global step 3870: loss = 1.7597 (0.759 sec/step)\n","I0908 16:17:35.147169 140650862335872 learning.py:512] global step 3870: loss = 1.7597 (0.759 sec/step)\n","INFO:tensorflow:global step 3871: loss = 2.4520 (0.759 sec/step)\n","I0908 16:17:35.908216 140650862335872 learning.py:512] global step 3871: loss = 2.4520 (0.759 sec/step)\n","INFO:tensorflow:global step 3872: loss = 1.9329 (0.757 sec/step)\n","I0908 16:17:36.667788 140650862335872 learning.py:512] global step 3872: loss = 1.9329 (0.757 sec/step)\n","INFO:tensorflow:global step 3873: loss = 2.0707 (0.760 sec/step)\n","I0908 16:17:37.429895 140650862335872 learning.py:512] global step 3873: loss = 2.0707 (0.760 sec/step)\n","INFO:tensorflow:global step 3874: loss = 1.6317 (0.777 sec/step)\n","I0908 16:17:38.208890 140650862335872 learning.py:512] global step 3874: loss = 1.6317 (0.777 sec/step)\n","INFO:tensorflow:global step 3875: loss = 2.3947 (0.778 sec/step)\n","I0908 16:17:38.988683 140650862335872 learning.py:512] global step 3875: loss = 2.3947 (0.778 sec/step)\n","INFO:tensorflow:global step 3876: loss = 1.7792 (0.757 sec/step)\n","I0908 16:17:39.749758 140650862335872 learning.py:512] global step 3876: loss = 1.7792 (0.757 sec/step)\n","INFO:tensorflow:global step 3877: loss = 3.0084 (0.769 sec/step)\n","I0908 16:17:40.520045 140650862335872 learning.py:512] global step 3877: loss = 3.0084 (0.769 sec/step)\n","INFO:tensorflow:global step 3878: loss = 1.9383 (0.774 sec/step)\n","I0908 16:17:41.296097 140650862335872 learning.py:512] global step 3878: loss = 1.9383 (0.774 sec/step)\n","INFO:tensorflow:global step 3879: loss = 2.3527 (0.751 sec/step)\n","I0908 16:17:42.048499 140650862335872 learning.py:512] global step 3879: loss = 2.3527 (0.751 sec/step)\n","INFO:tensorflow:global step 3880: loss = 1.8824 (0.742 sec/step)\n","I0908 16:17:42.792323 140650862335872 learning.py:512] global step 3880: loss = 1.8824 (0.742 sec/step)\n","INFO:tensorflow:global step 3881: loss = 1.8527 (0.757 sec/step)\n","I0908 16:17:43.551421 140650862335872 learning.py:512] global step 3881: loss = 1.8527 (0.757 sec/step)\n","INFO:tensorflow:global step 3882: loss = 1.9117 (0.763 sec/step)\n","I0908 16:17:44.315898 140650862335872 learning.py:512] global step 3882: loss = 1.9117 (0.763 sec/step)\n","INFO:tensorflow:global step 3883: loss = 2.0344 (0.732 sec/step)\n","I0908 16:17:45.050059 140650862335872 learning.py:512] global step 3883: loss = 2.0344 (0.732 sec/step)\n","INFO:tensorflow:global step 3884: loss = 1.9700 (0.759 sec/step)\n","I0908 16:17:45.810484 140650862335872 learning.py:512] global step 3884: loss = 1.9700 (0.759 sec/step)\n","INFO:tensorflow:Saving checkpoint to path /root/models/trained_v2/model.ckpt\n","I0908 16:17:46.273395 140646958036736 supervisor.py:1117] Saving checkpoint to path /root/models/trained_v2/model.ckpt\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to delete files with this prefix.\n","W0908 16:17:46.412406 140646958036736 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to delete files with this prefix.\n","INFO:tensorflow:global step 3885: loss = 2.3995 (1.227 sec/step)\n","I0908 16:17:47.211951 140650862335872 learning.py:512] global step 3885: loss = 2.3995 (1.227 sec/step)\n","INFO:tensorflow:Recording summary at step 3885.\n","I0908 16:17:47.525922 140646941251328 supervisor.py:1050] Recording summary at step 3885.\n","INFO:tensorflow:global step 3886: loss = 1.9971 (1.023 sec/step)\n","I0908 16:17:48.374009 140650862335872 learning.py:512] global step 3886: loss = 1.9971 (1.023 sec/step)\n","INFO:tensorflow:global step 3887: loss = 2.0682 (0.899 sec/step)\n","I0908 16:17:49.284591 140650862335872 learning.py:512] global step 3887: loss = 2.0682 (0.899 sec/step)\n","INFO:tensorflow:global step 3888: loss = 1.9891 (0.839 sec/step)\n","I0908 16:17:50.307932 140650862335872 learning.py:512] global step 3888: loss = 1.9891 (0.839 sec/step)\n","INFO:tensorflow:global step 3889: loss = 2.1431 (0.753 sec/step)\n","I0908 16:17:51.062880 140650862335872 learning.py:512] global step 3889: loss = 2.1431 (0.753 sec/step)\n","INFO:tensorflow:global step 3890: loss = 1.7157 (0.753 sec/step)\n","I0908 16:17:51.817440 140650862335872 learning.py:512] global step 3890: loss = 1.7157 (0.753 sec/step)\n","INFO:tensorflow:global step 3891: loss = 2.0732 (0.764 sec/step)\n","I0908 16:17:52.583101 140650862335872 learning.py:512] global step 3891: loss = 2.0732 (0.764 sec/step)\n","INFO:tensorflow:global step 3892: loss = 2.1372 (0.774 sec/step)\n","I0908 16:17:53.358419 140650862335872 learning.py:512] global step 3892: loss = 2.1372 (0.774 sec/step)\n","INFO:tensorflow:global step 3893: loss = 1.8217 (0.778 sec/step)\n","I0908 16:17:54.138586 140650862335872 learning.py:512] global step 3893: loss = 1.8217 (0.778 sec/step)\n","INFO:tensorflow:global step 3894: loss = 1.9244 (0.744 sec/step)\n","I0908 16:17:54.884506 140650862335872 learning.py:512] global step 3894: loss = 1.9244 (0.744 sec/step)\n","INFO:tensorflow:global step 3895: loss = 2.1902 (0.757 sec/step)\n","I0908 16:17:55.643272 140650862335872 learning.py:512] global step 3895: loss = 2.1902 (0.757 sec/step)\n","INFO:tensorflow:global step 3896: loss = 2.7392 (0.755 sec/step)\n","I0908 16:17:56.400454 140650862335872 learning.py:512] global step 3896: loss = 2.7392 (0.755 sec/step)\n","INFO:tensorflow:global step 3897: loss = 1.9302 (0.762 sec/step)\n","I0908 16:17:57.164607 140650862335872 learning.py:512] global step 3897: loss = 1.9302 (0.762 sec/step)\n","INFO:tensorflow:global step 3898: loss = 2.0512 (0.753 sec/step)\n","I0908 16:17:57.919798 140650862335872 learning.py:512] global step 3898: loss = 2.0512 (0.753 sec/step)\n","INFO:tensorflow:global step 3899: loss = 1.9297 (0.772 sec/step)\n","I0908 16:17:58.693365 140650862335872 learning.py:512] global step 3899: loss = 1.9297 (0.772 sec/step)\n","INFO:tensorflow:global step 3900: loss = 1.7522 (0.745 sec/step)\n","I0908 16:17:59.440456 140650862335872 learning.py:512] global step 3900: loss = 1.7522 (0.745 sec/step)\n","INFO:tensorflow:global step 3901: loss = 2.3741 (0.756 sec/step)\n","I0908 16:18:00.197977 140650862335872 learning.py:512] global step 3901: loss = 2.3741 (0.756 sec/step)\n","INFO:tensorflow:global step 3902: loss = 2.0052 (0.764 sec/step)\n","I0908 16:18:00.963446 140650862335872 learning.py:512] global step 3902: loss = 2.0052 (0.764 sec/step)\n","INFO:tensorflow:global step 3903: loss = 1.9437 (0.765 sec/step)\n","I0908 16:18:01.730805 140650862335872 learning.py:512] global step 3903: loss = 1.9437 (0.765 sec/step)\n","INFO:tensorflow:global step 3904: loss = 2.1972 (0.752 sec/step)\n","I0908 16:18:02.484434 140650862335872 learning.py:512] global step 3904: loss = 2.1972 (0.752 sec/step)\n","INFO:tensorflow:global step 3905: loss = 2.0343 (0.759 sec/step)\n","I0908 16:18:03.244783 140650862335872 learning.py:512] global step 3905: loss = 2.0343 (0.759 sec/step)\n","INFO:tensorflow:global step 3906: loss = 2.3022 (0.741 sec/step)\n","I0908 16:18:03.987659 140650862335872 learning.py:512] global step 3906: loss = 2.3022 (0.741 sec/step)\n","INFO:tensorflow:global step 3907: loss = 1.8304 (0.776 sec/step)\n","I0908 16:18:04.766273 140650862335872 learning.py:512] global step 3907: loss = 1.8304 (0.776 sec/step)\n","INFO:tensorflow:global step 3908: loss = 1.7902 (0.756 sec/step)\n","I0908 16:18:05.524187 140650862335872 learning.py:512] global step 3908: loss = 1.7902 (0.756 sec/step)\n","INFO:tensorflow:global step 3909: loss = 2.8213 (0.770 sec/step)\n","I0908 16:18:06.295391 140650862335872 learning.py:512] global step 3909: loss = 2.8213 (0.770 sec/step)\n","INFO:tensorflow:global step 3910: loss = 2.1407 (0.760 sec/step)\n","I0908 16:18:07.056881 140650862335872 learning.py:512] global step 3910: loss = 2.1407 (0.760 sec/step)\n","INFO:tensorflow:global step 3911: loss = 2.4037 (0.761 sec/step)\n","I0908 16:18:07.819061 140650862335872 learning.py:512] global step 3911: loss = 2.4037 (0.761 sec/step)\n","INFO:tensorflow:global step 3912: loss = 1.9288 (0.769 sec/step)\n","I0908 16:18:08.589994 140650862335872 learning.py:512] global step 3912: loss = 1.9288 (0.769 sec/step)\n","INFO:tensorflow:global step 3913: loss = 1.7455 (0.758 sec/step)\n","I0908 16:18:09.349694 140650862335872 learning.py:512] global step 3913: loss = 1.7455 (0.758 sec/step)\n","INFO:tensorflow:global step 3914: loss = 1.7188 (0.752 sec/step)\n","I0908 16:18:10.103410 140650862335872 learning.py:512] global step 3914: loss = 1.7188 (0.752 sec/step)\n","INFO:tensorflow:global step 3915: loss = 2.0105 (0.764 sec/step)\n","I0908 16:18:10.868929 140650862335872 learning.py:512] global step 3915: loss = 2.0105 (0.764 sec/step)\n","INFO:tensorflow:global step 3916: loss = 1.7057 (0.781 sec/step)\n","I0908 16:18:11.651781 140650862335872 learning.py:512] global step 3916: loss = 1.7057 (0.781 sec/step)\n","INFO:tensorflow:global step 3917: loss = 1.9634 (0.762 sec/step)\n","I0908 16:18:12.415815 140650862335872 learning.py:512] global step 3917: loss = 1.9634 (0.762 sec/step)\n","INFO:tensorflow:global step 3918: loss = 1.8046 (0.774 sec/step)\n","I0908 16:18:13.191759 140650862335872 learning.py:512] global step 3918: loss = 1.8046 (0.774 sec/step)\n","INFO:tensorflow:global step 3919: loss = 1.8825 (0.742 sec/step)\n","I0908 16:18:13.935205 140650862335872 learning.py:512] global step 3919: loss = 1.8825 (0.742 sec/step)\n","INFO:tensorflow:global step 3920: loss = 1.9355 (0.744 sec/step)\n","I0908 16:18:14.681066 140650862335872 learning.py:512] global step 3920: loss = 1.9355 (0.744 sec/step)\n","INFO:tensorflow:global step 3921: loss = 1.8249 (0.751 sec/step)\n","I0908 16:18:15.434273 140650862335872 learning.py:512] global step 3921: loss = 1.8249 (0.751 sec/step)\n","INFO:tensorflow:global step 3922: loss = 2.3052 (0.769 sec/step)\n","I0908 16:18:16.205062 140650862335872 learning.py:512] global step 3922: loss = 2.3052 (0.769 sec/step)\n","INFO:tensorflow:global step 3923: loss = 1.7365 (0.760 sec/step)\n","I0908 16:18:16.967130 140650862335872 learning.py:512] global step 3923: loss = 1.7365 (0.760 sec/step)\n","INFO:tensorflow:global step 3924: loss = 1.9584 (0.747 sec/step)\n","I0908 16:18:17.716223 140650862335872 learning.py:512] global step 3924: loss = 1.9584 (0.747 sec/step)\n","INFO:tensorflow:global step 3925: loss = 1.8895 (0.738 sec/step)\n","I0908 16:18:18.455718 140650862335872 learning.py:512] global step 3925: loss = 1.8895 (0.738 sec/step)\n","INFO:tensorflow:global step 3926: loss = 1.9723 (0.751 sec/step)\n","I0908 16:18:19.207913 140650862335872 learning.py:512] global step 3926: loss = 1.9723 (0.751 sec/step)\n","INFO:tensorflow:global step 3927: loss = 1.9968 (0.747 sec/step)\n","I0908 16:18:19.956692 140650862335872 learning.py:512] global step 3927: loss = 1.9968 (0.747 sec/step)\n","INFO:tensorflow:global step 3928: loss = 1.9006 (0.764 sec/step)\n","I0908 16:18:20.721987 140650862335872 learning.py:512] global step 3928: loss = 1.9006 (0.764 sec/step)\n","INFO:tensorflow:global step 3929: loss = 2.4310 (0.753 sec/step)\n","I0908 16:18:21.476935 140650862335872 learning.py:512] global step 3929: loss = 2.4310 (0.753 sec/step)\n","INFO:tensorflow:global step 3930: loss = 2.2556 (0.746 sec/step)\n","I0908 16:18:22.225170 140650862335872 learning.py:512] global step 3930: loss = 2.2556 (0.746 sec/step)\n","INFO:tensorflow:global step 3931: loss = 1.9036 (0.758 sec/step)\n","I0908 16:18:22.984844 140650862335872 learning.py:512] global step 3931: loss = 1.9036 (0.758 sec/step)\n","INFO:tensorflow:global step 3932: loss = 2.5421 (0.760 sec/step)\n","I0908 16:18:23.746204 140650862335872 learning.py:512] global step 3932: loss = 2.5421 (0.760 sec/step)\n","INFO:tensorflow:global step 3933: loss = 2.5715 (0.749 sec/step)\n","I0908 16:18:24.497470 140650862335872 learning.py:512] global step 3933: loss = 2.5715 (0.749 sec/step)\n","INFO:tensorflow:global step 3934: loss = 2.4258 (0.755 sec/step)\n","I0908 16:18:25.253883 140650862335872 learning.py:512] global step 3934: loss = 2.4258 (0.755 sec/step)\n","INFO:tensorflow:global step 3935: loss = 1.6760 (0.746 sec/step)\n","I0908 16:18:26.001749 140650862335872 learning.py:512] global step 3935: loss = 1.6760 (0.746 sec/step)\n","INFO:tensorflow:global step 3936: loss = 2.1597 (0.766 sec/step)\n","I0908 16:18:26.769057 140650862335872 learning.py:512] global step 3936: loss = 2.1597 (0.766 sec/step)\n","INFO:tensorflow:global step 3937: loss = 2.9126 (0.758 sec/step)\n","I0908 16:18:27.529205 140650862335872 learning.py:512] global step 3937: loss = 2.9126 (0.758 sec/step)\n","INFO:tensorflow:global step 3938: loss = 2.0253 (0.741 sec/step)\n","I0908 16:18:28.271736 140650862335872 learning.py:512] global step 3938: loss = 2.0253 (0.741 sec/step)\n","INFO:tensorflow:global step 3939: loss = 1.9146 (0.772 sec/step)\n","I0908 16:18:29.045855 140650862335872 learning.py:512] global step 3939: loss = 1.9146 (0.772 sec/step)\n","INFO:tensorflow:global step 3940: loss = 2.1675 (0.765 sec/step)\n","I0908 16:18:29.812728 140650862335872 learning.py:512] global step 3940: loss = 2.1675 (0.765 sec/step)\n","INFO:tensorflow:global step 3941: loss = 2.0662 (0.758 sec/step)\n","I0908 16:18:30.572693 140650862335872 learning.py:512] global step 3941: loss = 2.0662 (0.758 sec/step)\n","INFO:tensorflow:global step 3942: loss = 2.1654 (0.752 sec/step)\n","I0908 16:18:31.326545 140650862335872 learning.py:512] global step 3942: loss = 2.1654 (0.752 sec/step)\n","INFO:tensorflow:global step 3943: loss = 1.9638 (0.774 sec/step)\n","I0908 16:18:32.102414 140650862335872 learning.py:512] global step 3943: loss = 1.9638 (0.774 sec/step)\n","INFO:tensorflow:global step 3944: loss = 2.2139 (0.768 sec/step)\n","I0908 16:18:32.871710 140650862335872 learning.py:512] global step 3944: loss = 2.2139 (0.768 sec/step)\n","INFO:tensorflow:global step 3945: loss = 1.9369 (0.719 sec/step)\n","I0908 16:18:33.592595 140650862335872 learning.py:512] global step 3945: loss = 1.9369 (0.719 sec/step)\n","INFO:tensorflow:global step 3946: loss = 2.0453 (0.744 sec/step)\n","I0908 16:18:34.338210 140650862335872 learning.py:512] global step 3946: loss = 2.0453 (0.744 sec/step)\n","INFO:tensorflow:global step 3947: loss = 2.0012 (0.766 sec/step)\n","I0908 16:18:35.105662 140650862335872 learning.py:512] global step 3947: loss = 2.0012 (0.766 sec/step)\n","INFO:tensorflow:global step 3948: loss = 1.9464 (0.767 sec/step)\n","I0908 16:18:35.874702 140650862335872 learning.py:512] global step 3948: loss = 1.9464 (0.767 sec/step)\n","INFO:tensorflow:global step 3949: loss = 2.3616 (0.762 sec/step)\n","I0908 16:18:36.638478 140650862335872 learning.py:512] global step 3949: loss = 2.3616 (0.762 sec/step)\n","INFO:tensorflow:global step 3950: loss = 2.3908 (0.771 sec/step)\n","I0908 16:18:37.411123 140650862335872 learning.py:512] global step 3950: loss = 2.3908 (0.771 sec/step)\n","INFO:tensorflow:global step 3951: loss = 1.8742 (0.752 sec/step)\n","I0908 16:18:38.164798 140650862335872 learning.py:512] global step 3951: loss = 1.8742 (0.752 sec/step)\n","INFO:tensorflow:global step 3952: loss = 1.7426 (0.753 sec/step)\n","I0908 16:18:38.919767 140650862335872 learning.py:512] global step 3952: loss = 1.7426 (0.753 sec/step)\n","INFO:tensorflow:global step 3953: loss = 2.1044 (0.741 sec/step)\n","I0908 16:18:39.662469 140650862335872 learning.py:512] global step 3953: loss = 2.1044 (0.741 sec/step)\n","INFO:tensorflow:global step 3954: loss = 1.9893 (0.776 sec/step)\n","I0908 16:18:40.440628 140650862335872 learning.py:512] global step 3954: loss = 1.9893 (0.776 sec/step)\n","INFO:tensorflow:global step 3955: loss = 2.1909 (0.764 sec/step)\n","I0908 16:18:41.206511 140650862335872 learning.py:512] global step 3955: loss = 2.1909 (0.764 sec/step)\n","INFO:tensorflow:global step 3956: loss = 1.9809 (0.738 sec/step)\n","I0908 16:18:41.946185 140650862335872 learning.py:512] global step 3956: loss = 1.9809 (0.738 sec/step)\n","INFO:tensorflow:global step 3957: loss = 2.2086 (0.757 sec/step)\n","I0908 16:18:42.704880 140650862335872 learning.py:512] global step 3957: loss = 2.2086 (0.757 sec/step)\n","INFO:tensorflow:global step 3958: loss = 2.4921 (0.756 sec/step)\n","I0908 16:18:43.462945 140650862335872 learning.py:512] global step 3958: loss = 2.4921 (0.756 sec/step)\n","INFO:tensorflow:global step 3959: loss = 2.0259 (0.762 sec/step)\n","I0908 16:18:44.226750 140650862335872 learning.py:512] global step 3959: loss = 2.0259 (0.762 sec/step)\n","INFO:tensorflow:global step 3960: loss = 1.9814 (0.761 sec/step)\n","I0908 16:18:44.991036 140650862335872 learning.py:512] global step 3960: loss = 1.9814 (0.761 sec/step)\n","INFO:tensorflow:global step 3961: loss = 1.7327 (0.754 sec/step)\n","I0908 16:18:45.747054 140650862335872 learning.py:512] global step 3961: loss = 1.7327 (0.754 sec/step)\n","INFO:tensorflow:global step 3962: loss = 2.0710 (0.764 sec/step)\n","I0908 16:18:46.512922 140650862335872 learning.py:512] global step 3962: loss = 2.0710 (0.764 sec/step)\n","INFO:tensorflow:global step 3963: loss = 2.3043 (0.758 sec/step)\n","I0908 16:18:47.273043 140650862335872 learning.py:512] global step 3963: loss = 2.3043 (0.758 sec/step)\n","INFO:tensorflow:global step 3964: loss = 2.0474 (0.730 sec/step)\n","I0908 16:18:48.004817 140650862335872 learning.py:512] global step 3964: loss = 2.0474 (0.730 sec/step)\n","INFO:tensorflow:global step 3965: loss = 2.3293 (0.764 sec/step)\n","I0908 16:18:48.770029 140650862335872 learning.py:512] global step 3965: loss = 2.3293 (0.764 sec/step)\n","INFO:tensorflow:global step 3966: loss = 1.8594 (0.777 sec/step)\n","I0908 16:18:49.548447 140650862335872 learning.py:512] global step 3966: loss = 1.8594 (0.777 sec/step)\n","INFO:tensorflow:global step 3967: loss = 1.8183 (0.747 sec/step)\n","I0908 16:18:50.297143 140650862335872 learning.py:512] global step 3967: loss = 1.8183 (0.747 sec/step)\n","INFO:tensorflow:global step 3968: loss = 1.9868 (0.750 sec/step)\n","I0908 16:18:51.048490 140650862335872 learning.py:512] global step 3968: loss = 1.9868 (0.750 sec/step)\n","INFO:tensorflow:global step 3969: loss = 2.3908 (0.762 sec/step)\n","I0908 16:18:51.812318 140650862335872 learning.py:512] global step 3969: loss = 2.3908 (0.762 sec/step)\n","INFO:tensorflow:global step 3970: loss = 2.0687 (0.765 sec/step)\n","I0908 16:18:52.579195 140650862335872 learning.py:512] global step 3970: loss = 2.0687 (0.765 sec/step)\n","INFO:tensorflow:global step 3971: loss = 2.0307 (0.750 sec/step)\n","I0908 16:18:53.331005 140650862335872 learning.py:512] global step 3971: loss = 2.0307 (0.750 sec/step)\n","INFO:tensorflow:global step 3972: loss = 1.8084 (0.752 sec/step)\n","I0908 16:18:54.084461 140650862335872 learning.py:512] global step 3972: loss = 1.8084 (0.752 sec/step)\n","INFO:tensorflow:global step 3973: loss = 1.9310 (0.765 sec/step)\n","I0908 16:18:54.851114 140650862335872 learning.py:512] global step 3973: loss = 1.9310 (0.765 sec/step)\n","INFO:tensorflow:global step 3974: loss = 2.0110 (0.766 sec/step)\n","I0908 16:18:55.618946 140650862335872 learning.py:512] global step 3974: loss = 2.0110 (0.766 sec/step)\n","INFO:tensorflow:global step 3975: loss = 2.1498 (0.766 sec/step)\n","I0908 16:18:56.386750 140650862335872 learning.py:512] global step 3975: loss = 2.1498 (0.766 sec/step)\n","INFO:tensorflow:global step 3976: loss = 1.8936 (0.748 sec/step)\n","I0908 16:18:57.135939 140650862335872 learning.py:512] global step 3976: loss = 1.8936 (0.748 sec/step)\n","INFO:tensorflow:global step 3977: loss = 2.1283 (0.746 sec/step)\n","I0908 16:18:57.883202 140650862335872 learning.py:512] global step 3977: loss = 2.1283 (0.746 sec/step)\n","INFO:tensorflow:global step 3978: loss = 2.1038 (0.755 sec/step)\n","I0908 16:18:58.639697 140650862335872 learning.py:512] global step 3978: loss = 2.1038 (0.755 sec/step)\n","INFO:tensorflow:global step 3979: loss = 2.1652 (0.757 sec/step)\n","I0908 16:18:59.398194 140650862335872 learning.py:512] global step 3979: loss = 2.1652 (0.757 sec/step)\n","INFO:tensorflow:global step 3980: loss = 1.8813 (0.760 sec/step)\n","I0908 16:19:00.159471 140650862335872 learning.py:512] global step 3980: loss = 1.8813 (0.760 sec/step)\n","INFO:tensorflow:global step 3981: loss = 2.5918 (0.763 sec/step)\n","I0908 16:19:00.924334 140650862335872 learning.py:512] global step 3981: loss = 2.5918 (0.763 sec/step)\n","INFO:tensorflow:global step 3982: loss = 2.4469 (0.748 sec/step)\n","I0908 16:19:01.674363 140650862335872 learning.py:512] global step 3982: loss = 2.4469 (0.748 sec/step)\n","INFO:tensorflow:global step 3983: loss = 2.2798 (0.735 sec/step)\n","I0908 16:19:02.410702 140650862335872 learning.py:512] global step 3983: loss = 2.2798 (0.735 sec/step)\n","INFO:tensorflow:global step 3984: loss = 2.0772 (0.766 sec/step)\n","I0908 16:19:03.177981 140650862335872 learning.py:512] global step 3984: loss = 2.0772 (0.766 sec/step)\n","INFO:tensorflow:global step 3985: loss = 2.3436 (0.766 sec/step)\n","I0908 16:19:03.945601 140650862335872 learning.py:512] global step 3985: loss = 2.3436 (0.766 sec/step)\n","INFO:tensorflow:global step 3986: loss = 1.9965 (0.762 sec/step)\n","I0908 16:19:04.708674 140650862335872 learning.py:512] global step 3986: loss = 1.9965 (0.762 sec/step)\n","INFO:tensorflow:global step 3987: loss = 2.0105 (0.752 sec/step)\n","I0908 16:19:05.462381 140650862335872 learning.py:512] global step 3987: loss = 2.0105 (0.752 sec/step)\n","INFO:tensorflow:global step 3988: loss = 1.8267 (0.762 sec/step)\n","I0908 16:19:06.225898 140650862335872 learning.py:512] global step 3988: loss = 1.8267 (0.762 sec/step)\n","INFO:tensorflow:global step 3989: loss = 2.2990 (0.767 sec/step)\n","I0908 16:19:06.994228 140650862335872 learning.py:512] global step 3989: loss = 2.2990 (0.767 sec/step)\n","INFO:tensorflow:global step 3990: loss = 2.1116 (0.765 sec/step)\n","I0908 16:19:07.760719 140650862335872 learning.py:512] global step 3990: loss = 2.1116 (0.765 sec/step)\n","INFO:tensorflow:global step 3991: loss = 1.8748 (0.770 sec/step)\n","I0908 16:19:08.532484 140650862335872 learning.py:512] global step 3991: loss = 1.8748 (0.770 sec/step)\n","INFO:tensorflow:global step 3992: loss = 2.1434 (0.737 sec/step)\n","I0908 16:19:09.271208 140650862335872 learning.py:512] global step 3992: loss = 2.1434 (0.737 sec/step)\n","INFO:tensorflow:global step 3993: loss = 1.8807 (0.769 sec/step)\n","I0908 16:19:10.041691 140650862335872 learning.py:512] global step 3993: loss = 1.8807 (0.769 sec/step)\n","INFO:tensorflow:global step 3994: loss = 2.2960 (0.759 sec/step)\n","I0908 16:19:10.802332 140650862335872 learning.py:512] global step 3994: loss = 2.2960 (0.759 sec/step)\n","INFO:tensorflow:global step 3995: loss = 2.2940 (0.762 sec/step)\n","I0908 16:19:11.566634 140650862335872 learning.py:512] global step 3995: loss = 2.2940 (0.762 sec/step)\n","INFO:tensorflow:global step 3996: loss = 1.8921 (0.745 sec/step)\n","I0908 16:19:12.312882 140650862335872 learning.py:512] global step 3996: loss = 1.8921 (0.745 sec/step)\n","INFO:tensorflow:global step 3997: loss = 1.9359 (0.756 sec/step)\n","I0908 16:19:13.070780 140650862335872 learning.py:512] global step 3997: loss = 1.9359 (0.756 sec/step)\n","INFO:tensorflow:global step 3998: loss = 1.7407 (0.759 sec/step)\n","I0908 16:19:13.831995 140650862335872 learning.py:512] global step 3998: loss = 1.7407 (0.759 sec/step)\n","INFO:tensorflow:global step 3999: loss = 2.1545 (0.774 sec/step)\n","I0908 16:19:14.607707 140650862335872 learning.py:512] global step 3999: loss = 2.1545 (0.774 sec/step)\n","INFO:tensorflow:global step 4000: loss = 2.0375 (0.772 sec/step)\n","I0908 16:19:15.380961 140650862335872 learning.py:512] global step 4000: loss = 2.0375 (0.772 sec/step)\n","INFO:tensorflow:global step 4001: loss = 2.0161 (0.756 sec/step)\n","I0908 16:19:16.138530 140650862335872 learning.py:512] global step 4001: loss = 2.0161 (0.756 sec/step)\n","INFO:tensorflow:global step 4002: loss = 1.8913 (0.750 sec/step)\n","I0908 16:19:16.890289 140650862335872 learning.py:512] global step 4002: loss = 1.8913 (0.750 sec/step)\n","INFO:tensorflow:global step 4003: loss = 2.3722 (0.754 sec/step)\n","I0908 16:19:17.645734 140650862335872 learning.py:512] global step 4003: loss = 2.3722 (0.754 sec/step)\n","INFO:tensorflow:global step 4004: loss = 2.1636 (0.769 sec/step)\n","I0908 16:19:18.416292 140650862335872 learning.py:512] global step 4004: loss = 2.1636 (0.769 sec/step)\n","INFO:tensorflow:global step 4005: loss = 2.1642 (0.741 sec/step)\n","I0908 16:19:19.160486 140650862335872 learning.py:512] global step 4005: loss = 2.1642 (0.741 sec/step)\n","INFO:tensorflow:global step 4006: loss = 1.9889 (0.755 sec/step)\n","I0908 16:19:19.918810 140650862335872 learning.py:512] global step 4006: loss = 1.9889 (0.755 sec/step)\n","INFO:tensorflow:global step 4007: loss = 2.6996 (0.751 sec/step)\n","I0908 16:19:20.671699 140650862335872 learning.py:512] global step 4007: loss = 2.6996 (0.751 sec/step)\n","INFO:tensorflow:global step 4008: loss = 1.9623 (0.757 sec/step)\n","I0908 16:19:21.430792 140650862335872 learning.py:512] global step 4008: loss = 1.9623 (0.757 sec/step)\n","INFO:tensorflow:global step 4009: loss = 1.9587 (0.755 sec/step)\n","I0908 16:19:22.187691 140650862335872 learning.py:512] global step 4009: loss = 1.9587 (0.755 sec/step)\n","INFO:tensorflow:global step 4010: loss = 2.0319 (0.763 sec/step)\n","I0908 16:19:22.952364 140650862335872 learning.py:512] global step 4010: loss = 2.0319 (0.763 sec/step)\n","INFO:tensorflow:global step 4011: loss = 2.0179 (0.772 sec/step)\n","I0908 16:19:23.726049 140650862335872 learning.py:512] global step 4011: loss = 2.0179 (0.772 sec/step)\n","INFO:tensorflow:global step 4012: loss = 2.1400 (0.758 sec/step)\n","I0908 16:19:24.486161 140650862335872 learning.py:512] global step 4012: loss = 2.1400 (0.758 sec/step)\n","INFO:tensorflow:global step 4013: loss = 2.4469 (0.749 sec/step)\n","I0908 16:19:25.237155 140650862335872 learning.py:512] global step 4013: loss = 2.4469 (0.749 sec/step)\n","INFO:tensorflow:global step 4014: loss = 2.0800 (0.767 sec/step)\n","I0908 16:19:26.006125 140650862335872 learning.py:512] global step 4014: loss = 2.0800 (0.767 sec/step)\n","INFO:tensorflow:global step 4015: loss = 2.3009 (0.747 sec/step)\n","I0908 16:19:26.754345 140650862335872 learning.py:512] global step 4015: loss = 2.3009 (0.747 sec/step)\n","INFO:tensorflow:global step 4016: loss = 1.8734 (0.753 sec/step)\n","I0908 16:19:27.508768 140650862335872 learning.py:512] global step 4016: loss = 1.8734 (0.753 sec/step)\n","INFO:tensorflow:global step 4017: loss = 2.2150 (0.759 sec/step)\n","I0908 16:19:28.269791 140650862335872 learning.py:512] global step 4017: loss = 2.2150 (0.759 sec/step)\n","INFO:tensorflow:global step 4018: loss = 2.3446 (0.765 sec/step)\n","I0908 16:19:29.036743 140650862335872 learning.py:512] global step 4018: loss = 2.3446 (0.765 sec/step)\n","INFO:tensorflow:global step 4019: loss = 1.9001 (0.767 sec/step)\n","I0908 16:19:29.806104 140650862335872 learning.py:512] global step 4019: loss = 1.9001 (0.767 sec/step)\n","INFO:tensorflow:global step 4020: loss = 2.2718 (0.746 sec/step)\n","I0908 16:19:30.553488 140650862335872 learning.py:512] global step 4020: loss = 2.2718 (0.746 sec/step)\n","INFO:tensorflow:global step 4021: loss = 2.1637 (0.764 sec/step)\n","I0908 16:19:31.319546 140650862335872 learning.py:512] global step 4021: loss = 2.1637 (0.764 sec/step)\n","INFO:tensorflow:global step 4022: loss = 2.6984 (0.763 sec/step)\n","I0908 16:19:32.084160 140650862335872 learning.py:512] global step 4022: loss = 2.6984 (0.763 sec/step)\n","INFO:tensorflow:global step 4023: loss = 1.9441 (0.750 sec/step)\n","I0908 16:19:32.836467 140650862335872 learning.py:512] global step 4023: loss = 1.9441 (0.750 sec/step)\n","INFO:tensorflow:global step 4024: loss = 2.1557 (0.762 sec/step)\n","I0908 16:19:33.600360 140650862335872 learning.py:512] global step 4024: loss = 2.1557 (0.762 sec/step)\n","INFO:tensorflow:global step 4025: loss = 1.7538 (0.745 sec/step)\n","I0908 16:19:34.347061 140650862335872 learning.py:512] global step 4025: loss = 1.7538 (0.745 sec/step)\n","INFO:tensorflow:global step 4026: loss = 2.4202 (0.766 sec/step)\n","I0908 16:19:35.114357 140650862335872 learning.py:512] global step 4026: loss = 2.4202 (0.766 sec/step)\n","INFO:tensorflow:global step 4027: loss = 1.9298 (0.749 sec/step)\n","I0908 16:19:35.864864 140650862335872 learning.py:512] global step 4027: loss = 1.9298 (0.749 sec/step)\n","INFO:tensorflow:global step 4028: loss = 1.7568 (0.764 sec/step)\n","I0908 16:19:36.630481 140650862335872 learning.py:512] global step 4028: loss = 1.7568 (0.764 sec/step)\n","INFO:tensorflow:global step 4029: loss = 2.6588 (0.759 sec/step)\n","I0908 16:19:37.391680 140650862335872 learning.py:512] global step 4029: loss = 2.6588 (0.759 sec/step)\n","INFO:tensorflow:global step 4030: loss = 1.8185 (0.777 sec/step)\n","I0908 16:19:38.170146 140650862335872 learning.py:512] global step 4030: loss = 1.8185 (0.777 sec/step)\n","INFO:tensorflow:global step 4031: loss = 2.3527 (0.759 sec/step)\n","I0908 16:19:38.931025 140650862335872 learning.py:512] global step 4031: loss = 2.3527 (0.759 sec/step)\n","INFO:tensorflow:global step 4032: loss = 2.0581 (0.751 sec/step)\n","I0908 16:19:39.683482 140650862335872 learning.py:512] global step 4032: loss = 2.0581 (0.751 sec/step)\n","INFO:tensorflow:global step 4033: loss = 2.1800 (0.758 sec/step)\n","I0908 16:19:40.443169 140650862335872 learning.py:512] global step 4033: loss = 2.1800 (0.758 sec/step)\n","INFO:tensorflow:global step 4034: loss = 2.1655 (0.761 sec/step)\n","I0908 16:19:41.205745 140650862335872 learning.py:512] global step 4034: loss = 2.1655 (0.761 sec/step)\n","INFO:tensorflow:global step 4035: loss = 2.0171 (0.756 sec/step)\n","I0908 16:19:41.963000 140650862335872 learning.py:512] global step 4035: loss = 2.0171 (0.756 sec/step)\n","INFO:tensorflow:global step 4036: loss = 2.1272 (0.764 sec/step)\n","I0908 16:19:42.728761 140650862335872 learning.py:512] global step 4036: loss = 2.1272 (0.764 sec/step)\n","INFO:tensorflow:global step 4037: loss = 1.8065 (0.757 sec/step)\n","I0908 16:19:43.487871 140650862335872 learning.py:512] global step 4037: loss = 1.8065 (0.757 sec/step)\n","INFO:tensorflow:global step 4038: loss = 2.0916 (0.781 sec/step)\n","I0908 16:19:44.270224 140650862335872 learning.py:512] global step 4038: loss = 2.0916 (0.781 sec/step)\n","INFO:tensorflow:global step 4039: loss = 1.8344 (0.759 sec/step)\n","I0908 16:19:45.031207 140650862335872 learning.py:512] global step 4039: loss = 1.8344 (0.759 sec/step)\n","INFO:tensorflow:global step 4040: loss = 1.8740 (0.764 sec/step)\n","I0908 16:19:45.796702 140650862335872 learning.py:512] global step 4040: loss = 1.8740 (0.764 sec/step)\n","INFO:tensorflow:global step 4041: loss = 2.4616 (0.843 sec/step)\n","I0908 16:19:46.652432 140650862335872 learning.py:512] global step 4041: loss = 2.4616 (0.843 sec/step)\n","INFO:tensorflow:Recording summary at step 4041.\n","I0908 16:19:47.629190 140646941251328 supervisor.py:1050] Recording summary at step 4041.\n","INFO:tensorflow:global step 4042: loss = 1.9539 (1.209 sec/step)\n","I0908 16:19:47.865872 140650862335872 learning.py:512] global step 4042: loss = 1.9539 (1.209 sec/step)\n","INFO:tensorflow:global step 4043: loss = 2.1632 (0.747 sec/step)\n","I0908 16:19:48.614926 140650862335872 learning.py:512] global step 4043: loss = 2.1632 (0.747 sec/step)\n","INFO:tensorflow:global step 4044: loss = 2.2848 (0.764 sec/step)\n","I0908 16:19:49.380776 140650862335872 learning.py:512] global step 4044: loss = 2.2848 (0.764 sec/step)\n","INFO:tensorflow:global step 4045: loss = 1.8739 (0.750 sec/step)\n","I0908 16:19:50.132034 140650862335872 learning.py:512] global step 4045: loss = 1.8739 (0.750 sec/step)\n","INFO:tensorflow:global step 4046: loss = 2.1307 (0.776 sec/step)\n","I0908 16:19:50.910100 140650862335872 learning.py:512] global step 4046: loss = 2.1307 (0.776 sec/step)\n","INFO:tensorflow:global step 4047: loss = 2.0016 (0.761 sec/step)\n","I0908 16:19:51.672955 140650862335872 learning.py:512] global step 4047: loss = 2.0016 (0.761 sec/step)\n","INFO:tensorflow:global step 4048: loss = 1.6407 (0.772 sec/step)\n","I0908 16:19:52.446908 140650862335872 learning.py:512] global step 4048: loss = 1.6407 (0.772 sec/step)\n","INFO:tensorflow:global step 4049: loss = 2.3229 (0.765 sec/step)\n","I0908 16:19:53.213190 140650862335872 learning.py:512] global step 4049: loss = 2.3229 (0.765 sec/step)\n","INFO:tensorflow:global step 4050: loss = 2.1648 (0.760 sec/step)\n","I0908 16:19:53.975354 140650862335872 learning.py:512] global step 4050: loss = 2.1648 (0.760 sec/step)\n","INFO:tensorflow:global step 4051: loss = 2.2126 (0.764 sec/step)\n","I0908 16:19:54.741327 140650862335872 learning.py:512] global step 4051: loss = 2.2126 (0.764 sec/step)\n","INFO:tensorflow:global step 4052: loss = 2.0224 (0.763 sec/step)\n","I0908 16:19:55.506498 140650862335872 learning.py:512] global step 4052: loss = 2.0224 (0.763 sec/step)\n","INFO:tensorflow:global step 4053: loss = 2.2053 (0.747 sec/step)\n","I0908 16:19:56.255340 140650862335872 learning.py:512] global step 4053: loss = 2.2053 (0.747 sec/step)\n","INFO:tensorflow:global step 4054: loss = 2.1377 (0.750 sec/step)\n","I0908 16:19:57.006826 140650862335872 learning.py:512] global step 4054: loss = 2.1377 (0.750 sec/step)\n","INFO:tensorflow:global step 4055: loss = 2.2195 (0.759 sec/step)\n","I0908 16:19:57.767270 140650862335872 learning.py:512] global step 4055: loss = 2.2195 (0.759 sec/step)\n","INFO:tensorflow:global step 4056: loss = 2.4759 (0.749 sec/step)\n","I0908 16:19:58.517510 140650862335872 learning.py:512] global step 4056: loss = 2.4759 (0.749 sec/step)\n","INFO:tensorflow:global step 4057: loss = 1.9839 (0.738 sec/step)\n","I0908 16:19:59.257339 140650862335872 learning.py:512] global step 4057: loss = 1.9839 (0.738 sec/step)\n","INFO:tensorflow:global step 4058: loss = 2.2611 (0.763 sec/step)\n","I0908 16:20:00.021711 140650862335872 learning.py:512] global step 4058: loss = 2.2611 (0.763 sec/step)\n","INFO:tensorflow:global step 4059: loss = 2.0682 (0.772 sec/step)\n","I0908 16:20:00.795476 140650862335872 learning.py:512] global step 4059: loss = 2.0682 (0.772 sec/step)\n","INFO:tensorflow:global step 4060: loss = 2.3100 (0.743 sec/step)\n","I0908 16:20:01.539726 140650862335872 learning.py:512] global step 4060: loss = 2.3100 (0.743 sec/step)\n","INFO:tensorflow:global step 4061: loss = 2.2717 (0.733 sec/step)\n","I0908 16:20:02.274603 140650862335872 learning.py:512] global step 4061: loss = 2.2717 (0.733 sec/step)\n","INFO:tensorflow:global step 4062: loss = 2.4331 (0.749 sec/step)\n","I0908 16:20:03.025425 140650862335872 learning.py:512] global step 4062: loss = 2.4331 (0.749 sec/step)\n","INFO:tensorflow:global step 4063: loss = 1.7599 (0.747 sec/step)\n","I0908 16:20:03.773919 140650862335872 learning.py:512] global step 4063: loss = 1.7599 (0.747 sec/step)\n","INFO:tensorflow:global step 4064: loss = 2.1651 (0.758 sec/step)\n","I0908 16:20:04.533972 140650862335872 learning.py:512] global step 4064: loss = 2.1651 (0.758 sec/step)\n","INFO:tensorflow:global step 4065: loss = 2.2620 (0.766 sec/step)\n","I0908 16:20:05.301553 140650862335872 learning.py:512] global step 4065: loss = 2.2620 (0.766 sec/step)\n","INFO:tensorflow:global step 4066: loss = 2.2823 (0.766 sec/step)\n","I0908 16:20:06.069312 140650862335872 learning.py:512] global step 4066: loss = 2.2823 (0.766 sec/step)\n","INFO:tensorflow:global step 4067: loss = 2.7733 (0.756 sec/step)\n","I0908 16:20:06.827518 140650862335872 learning.py:512] global step 4067: loss = 2.7733 (0.756 sec/step)\n","INFO:tensorflow:global step 4068: loss = 2.4767 (0.753 sec/step)\n","I0908 16:20:07.582072 140650862335872 learning.py:512] global step 4068: loss = 2.4767 (0.753 sec/step)\n","INFO:tensorflow:global step 4069: loss = 2.0723 (0.755 sec/step)\n","I0908 16:20:08.338796 140650862335872 learning.py:512] global step 4069: loss = 2.0723 (0.755 sec/step)\n","INFO:tensorflow:global step 4070: loss = 1.8642 (0.734 sec/step)\n","I0908 16:20:09.074434 140650862335872 learning.py:512] global step 4070: loss = 1.8642 (0.734 sec/step)\n","INFO:tensorflow:global step 4071: loss = 2.0550 (0.755 sec/step)\n","I0908 16:20:09.830976 140650862335872 learning.py:512] global step 4071: loss = 2.0550 (0.755 sec/step)\n","INFO:tensorflow:global step 4072: loss = 1.8337 (0.760 sec/step)\n","I0908 16:20:10.593048 140650862335872 learning.py:512] global step 4072: loss = 1.8337 (0.760 sec/step)\n","INFO:tensorflow:global step 4073: loss = 2.3396 (0.751 sec/step)\n","I0908 16:20:11.345701 140650862335872 learning.py:512] global step 4073: loss = 2.3396 (0.751 sec/step)\n","INFO:tensorflow:global step 4074: loss = 1.8813 (0.751 sec/step)\n","I0908 16:20:12.098193 140650862335872 learning.py:512] global step 4074: loss = 1.8813 (0.751 sec/step)\n","INFO:tensorflow:global step 4075: loss = 2.1078 (0.777 sec/step)\n","I0908 16:20:12.876526 140650862335872 learning.py:512] global step 4075: loss = 2.1078 (0.777 sec/step)\n","INFO:tensorflow:global step 4076: loss = 1.8195 (0.750 sec/step)\n","I0908 16:20:13.628492 140650862335872 learning.py:512] global step 4076: loss = 1.8195 (0.750 sec/step)\n","INFO:tensorflow:global step 4077: loss = 2.0082 (0.767 sec/step)\n","I0908 16:20:14.397024 140650862335872 learning.py:512] global step 4077: loss = 2.0082 (0.767 sec/step)\n","INFO:tensorflow:global step 4078: loss = 2.2159 (0.753 sec/step)\n","I0908 16:20:15.152439 140650862335872 learning.py:512] global step 4078: loss = 2.2159 (0.753 sec/step)\n","INFO:tensorflow:global step 4079: loss = 1.8128 (0.755 sec/step)\n","I0908 16:20:15.909347 140650862335872 learning.py:512] global step 4079: loss = 1.8128 (0.755 sec/step)\n","INFO:tensorflow:global step 4080: loss = 1.8937 (0.779 sec/step)\n","I0908 16:20:16.689949 140650862335872 learning.py:512] global step 4080: loss = 1.8937 (0.779 sec/step)\n","INFO:tensorflow:global step 4081: loss = 2.2796 (0.739 sec/step)\n","I0908 16:20:17.431215 140650862335872 learning.py:512] global step 4081: loss = 2.2796 (0.739 sec/step)\n","INFO:tensorflow:global step 4082: loss = 2.1108 (0.770 sec/step)\n","I0908 16:20:18.204316 140650862335872 learning.py:512] global step 4082: loss = 2.1108 (0.770 sec/step)\n","INFO:tensorflow:global step 4083: loss = 2.2805 (0.740 sec/step)\n","I0908 16:20:18.946506 140650862335872 learning.py:512] global step 4083: loss = 2.2805 (0.740 sec/step)\n","INFO:tensorflow:global step 4084: loss = 2.0900 (0.769 sec/step)\n","I0908 16:20:19.717666 140650862335872 learning.py:512] global step 4084: loss = 2.0900 (0.769 sec/step)\n","INFO:tensorflow:global step 4085: loss = 2.0004 (0.773 sec/step)\n","I0908 16:20:20.492427 140650862335872 learning.py:512] global step 4085: loss = 2.0004 (0.773 sec/step)\n","INFO:tensorflow:global step 4086: loss = 1.9440 (0.753 sec/step)\n","I0908 16:20:21.247006 140650862335872 learning.py:512] global step 4086: loss = 1.9440 (0.753 sec/step)\n","INFO:tensorflow:global step 4087: loss = 1.8620 (0.767 sec/step)\n","I0908 16:20:22.016119 140650862335872 learning.py:512] global step 4087: loss = 1.8620 (0.767 sec/step)\n","INFO:tensorflow:global step 4088: loss = 2.2403 (0.780 sec/step)\n","I0908 16:20:22.798577 140650862335872 learning.py:512] global step 4088: loss = 2.2403 (0.780 sec/step)\n","INFO:tensorflow:global step 4089: loss = 2.3059 (0.775 sec/step)\n","I0908 16:20:23.576052 140650862335872 learning.py:512] global step 4089: loss = 2.3059 (0.775 sec/step)\n","INFO:tensorflow:global step 4090: loss = 1.7533 (0.755 sec/step)\n","I0908 16:20:24.333088 140650862335872 learning.py:512] global step 4090: loss = 1.7533 (0.755 sec/step)\n","INFO:tensorflow:global step 4091: loss = 2.2451 (0.751 sec/step)\n","I0908 16:20:25.086869 140650862335872 learning.py:512] global step 4091: loss = 2.2451 (0.751 sec/step)\n","INFO:tensorflow:global step 4092: loss = 2.4346 (0.767 sec/step)\n","I0908 16:20:25.855405 140650862335872 learning.py:512] global step 4092: loss = 2.4346 (0.767 sec/step)\n","INFO:tensorflow:global step 4093: loss = 2.0403 (0.769 sec/step)\n","I0908 16:20:26.626434 140650862335872 learning.py:512] global step 4093: loss = 2.0403 (0.769 sec/step)\n","INFO:tensorflow:global step 4094: loss = 2.4370 (0.754 sec/step)\n","I0908 16:20:27.382246 140650862335872 learning.py:512] global step 4094: loss = 2.4370 (0.754 sec/step)\n","INFO:tensorflow:global step 4095: loss = 2.2284 (0.756 sec/step)\n","I0908 16:20:28.139809 140650862335872 learning.py:512] global step 4095: loss = 2.2284 (0.756 sec/step)\n","INFO:tensorflow:global step 4096: loss = 2.0458 (0.762 sec/step)\n","I0908 16:20:28.904160 140650862335872 learning.py:512] global step 4096: loss = 2.0458 (0.762 sec/step)\n","INFO:tensorflow:global step 4097: loss = 1.7796 (0.753 sec/step)\n","I0908 16:20:29.658337 140650862335872 learning.py:512] global step 4097: loss = 1.7796 (0.753 sec/step)\n","INFO:tensorflow:global step 4098: loss = 2.2406 (0.754 sec/step)\n","I0908 16:20:30.414176 140650862335872 learning.py:512] global step 4098: loss = 2.2406 (0.754 sec/step)\n","INFO:tensorflow:global step 4099: loss = 2.3604 (0.740 sec/step)\n","I0908 16:20:31.155952 140650862335872 learning.py:512] global step 4099: loss = 2.3604 (0.740 sec/step)\n","INFO:tensorflow:global step 4100: loss = 1.7608 (0.766 sec/step)\n","I0908 16:20:31.923649 140650862335872 learning.py:512] global step 4100: loss = 1.7608 (0.766 sec/step)\n","INFO:tensorflow:global step 4101: loss = 2.1578 (0.759 sec/step)\n","I0908 16:20:32.684055 140650862335872 learning.py:512] global step 4101: loss = 2.1578 (0.759 sec/step)\n","INFO:tensorflow:global step 4102: loss = 1.8163 (0.764 sec/step)\n","I0908 16:20:33.449697 140650862335872 learning.py:512] global step 4102: loss = 1.8163 (0.764 sec/step)\n","INFO:tensorflow:global step 4103: loss = 2.1381 (0.766 sec/step)\n","I0908 16:20:34.217684 140650862335872 learning.py:512] global step 4103: loss = 2.1381 (0.766 sec/step)\n","INFO:tensorflow:global step 4104: loss = 1.6434 (0.757 sec/step)\n","I0908 16:20:34.976111 140650862335872 learning.py:512] global step 4104: loss = 1.6434 (0.757 sec/step)\n","INFO:tensorflow:global step 4105: loss = 1.9465 (0.757 sec/step)\n","I0908 16:20:35.734327 140650862335872 learning.py:512] global step 4105: loss = 1.9465 (0.757 sec/step)\n","INFO:tensorflow:global step 4106: loss = 2.3485 (0.748 sec/step)\n","I0908 16:20:36.483818 140650862335872 learning.py:512] global step 4106: loss = 2.3485 (0.748 sec/step)\n","INFO:tensorflow:global step 4107: loss = 1.9692 (0.753 sec/step)\n","I0908 16:20:37.238633 140650862335872 learning.py:512] global step 4107: loss = 1.9692 (0.753 sec/step)\n","INFO:tensorflow:global step 4108: loss = 1.9766 (0.754 sec/step)\n","I0908 16:20:37.993751 140650862335872 learning.py:512] global step 4108: loss = 1.9766 (0.754 sec/step)\n","INFO:tensorflow:global step 4109: loss = 1.7387 (0.769 sec/step)\n","I0908 16:20:38.764304 140650862335872 learning.py:512] global step 4109: loss = 1.7387 (0.769 sec/step)\n","INFO:tensorflow:global step 4110: loss = 2.1139 (0.769 sec/step)\n","I0908 16:20:39.534570 140650862335872 learning.py:512] global step 4110: loss = 2.1139 (0.769 sec/step)\n","INFO:tensorflow:global step 4111: loss = 2.5935 (0.800 sec/step)\n","I0908 16:20:40.336515 140650862335872 learning.py:512] global step 4111: loss = 2.5935 (0.800 sec/step)\n","INFO:tensorflow:global step 4112: loss = 2.4922 (0.769 sec/step)\n","I0908 16:20:41.107802 140650862335872 learning.py:512] global step 4112: loss = 2.4922 (0.769 sec/step)\n","INFO:tensorflow:global step 4113: loss = 1.6983 (0.754 sec/step)\n","I0908 16:20:41.864064 140650862335872 learning.py:512] global step 4113: loss = 1.6983 (0.754 sec/step)\n","INFO:tensorflow:global step 4114: loss = 1.7169 (0.780 sec/step)\n","I0908 16:20:42.645831 140650862335872 learning.py:512] global step 4114: loss = 1.7169 (0.780 sec/step)\n","INFO:tensorflow:global step 4115: loss = 1.8914 (0.766 sec/step)\n","I0908 16:20:43.414065 140650862335872 learning.py:512] global step 4115: loss = 1.8914 (0.766 sec/step)\n","INFO:tensorflow:global step 4116: loss = 2.0575 (0.776 sec/step)\n","I0908 16:20:44.192083 140650862335872 learning.py:512] global step 4116: loss = 2.0575 (0.776 sec/step)\n","INFO:tensorflow:global step 4117: loss = 2.0311 (0.752 sec/step)\n","I0908 16:20:44.946014 140650862335872 learning.py:512] global step 4117: loss = 2.0311 (0.752 sec/step)\n","INFO:tensorflow:global step 4118: loss = 2.2549 (0.781 sec/step)\n","I0908 16:20:45.729070 140650862335872 learning.py:512] global step 4118: loss = 2.2549 (0.781 sec/step)\n","INFO:tensorflow:global step 4119: loss = 2.2815 (0.769 sec/step)\n","I0908 16:20:46.500460 140650862335872 learning.py:512] global step 4119: loss = 2.2815 (0.769 sec/step)\n","INFO:tensorflow:global step 4120: loss = 1.8414 (0.761 sec/step)\n","I0908 16:20:47.263139 140650862335872 learning.py:512] global step 4120: loss = 1.8414 (0.761 sec/step)\n","INFO:tensorflow:global step 4121: loss = 2.0032 (0.759 sec/step)\n","I0908 16:20:48.024248 140650862335872 learning.py:512] global step 4121: loss = 2.0032 (0.759 sec/step)\n","INFO:tensorflow:global step 4122: loss = 1.9613 (0.745 sec/step)\n","I0908 16:20:48.770819 140650862335872 learning.py:512] global step 4122: loss = 1.9613 (0.745 sec/step)\n","INFO:tensorflow:global step 4123: loss = 1.7067 (0.756 sec/step)\n","I0908 16:20:49.529032 140650862335872 learning.py:512] global step 4123: loss = 1.7067 (0.756 sec/step)\n","INFO:tensorflow:global step 4124: loss = 1.7028 (0.738 sec/step)\n","I0908 16:20:50.269448 140650862335872 learning.py:512] global step 4124: loss = 1.7028 (0.738 sec/step)\n","INFO:tensorflow:global step 4125: loss = 1.7992 (0.755 sec/step)\n","I0908 16:20:51.026275 140650862335872 learning.py:512] global step 4125: loss = 1.7992 (0.755 sec/step)\n","INFO:tensorflow:global step 4126: loss = 1.9444 (0.756 sec/step)\n","I0908 16:20:51.783525 140650862335872 learning.py:512] global step 4126: loss = 1.9444 (0.756 sec/step)\n","INFO:tensorflow:global step 4127: loss = 1.9091 (0.773 sec/step)\n","I0908 16:20:52.558512 140650862335872 learning.py:512] global step 4127: loss = 1.9091 (0.773 sec/step)\n","INFO:tensorflow:global step 4128: loss = 2.1740 (0.760 sec/step)\n","I0908 16:20:53.320048 140650862335872 learning.py:512] global step 4128: loss = 2.1740 (0.760 sec/step)\n","INFO:tensorflow:global step 4129: loss = 1.9374 (0.777 sec/step)\n","I0908 16:20:54.098756 140650862335872 learning.py:512] global step 4129: loss = 1.9374 (0.777 sec/step)\n","INFO:tensorflow:global step 4130: loss = 1.8005 (0.755 sec/step)\n","I0908 16:20:54.855244 140650862335872 learning.py:512] global step 4130: loss = 1.8005 (0.755 sec/step)\n","INFO:tensorflow:global step 4131: loss = 2.0168 (0.749 sec/step)\n","I0908 16:20:55.605588 140650862335872 learning.py:512] global step 4131: loss = 2.0168 (0.749 sec/step)\n","INFO:tensorflow:global step 4132: loss = 1.9882 (0.761 sec/step)\n","I0908 16:20:56.367913 140650862335872 learning.py:512] global step 4132: loss = 1.9882 (0.761 sec/step)\n","INFO:tensorflow:global step 4133: loss = 2.0879 (0.769 sec/step)\n","I0908 16:20:57.138973 140650862335872 learning.py:512] global step 4133: loss = 2.0879 (0.769 sec/step)\n","INFO:tensorflow:global step 4134: loss = 2.7606 (0.753 sec/step)\n","I0908 16:20:57.893897 140650862335872 learning.py:512] global step 4134: loss = 2.7606 (0.753 sec/step)\n","INFO:tensorflow:global step 4135: loss = 2.2919 (0.763 sec/step)\n","I0908 16:20:58.658573 140650862335872 learning.py:512] global step 4135: loss = 2.2919 (0.763 sec/step)\n","INFO:tensorflow:global step 4136: loss = 1.8321 (0.753 sec/step)\n","I0908 16:20:59.413450 140650862335872 learning.py:512] global step 4136: loss = 1.8321 (0.753 sec/step)\n","INFO:tensorflow:global step 4137: loss = 2.2746 (0.756 sec/step)\n","I0908 16:21:00.170860 140650862335872 learning.py:512] global step 4137: loss = 2.2746 (0.756 sec/step)\n","INFO:tensorflow:global step 4138: loss = 2.2317 (0.763 sec/step)\n","I0908 16:21:00.935190 140650862335872 learning.py:512] global step 4138: loss = 2.2317 (0.763 sec/step)\n","INFO:tensorflow:global step 4139: loss = 1.5479 (0.773 sec/step)\n","I0908 16:21:01.710098 140650862335872 learning.py:512] global step 4139: loss = 1.5479 (0.773 sec/step)\n","INFO:tensorflow:global step 4140: loss = 2.0228 (0.775 sec/step)\n","I0908 16:21:02.486544 140650862335872 learning.py:512] global step 4140: loss = 2.0228 (0.775 sec/step)\n","INFO:tensorflow:global step 4141: loss = 2.5762 (0.767 sec/step)\n","I0908 16:21:03.255014 140650862335872 learning.py:512] global step 4141: loss = 2.5762 (0.767 sec/step)\n","INFO:tensorflow:global step 4142: loss = 2.0387 (0.761 sec/step)\n","I0908 16:21:04.017430 140650862335872 learning.py:512] global step 4142: loss = 2.0387 (0.761 sec/step)\n","INFO:tensorflow:global step 4143: loss = 2.5405 (0.773 sec/step)\n","I0908 16:21:04.792501 140650862335872 learning.py:512] global step 4143: loss = 2.5405 (0.773 sec/step)\n","INFO:tensorflow:global step 4144: loss = 2.5755 (0.782 sec/step)\n","I0908 16:21:05.576544 140650862335872 learning.py:512] global step 4144: loss = 2.5755 (0.782 sec/step)\n","INFO:tensorflow:global step 4145: loss = 2.0481 (0.748 sec/step)\n","I0908 16:21:06.326608 140650862335872 learning.py:512] global step 4145: loss = 2.0481 (0.748 sec/step)\n","INFO:tensorflow:global step 4146: loss = 1.9163 (0.777 sec/step)\n","I0908 16:21:07.104962 140650862335872 learning.py:512] global step 4146: loss = 1.9163 (0.777 sec/step)\n","INFO:tensorflow:global step 4147: loss = 2.1259 (0.757 sec/step)\n","I0908 16:21:07.864218 140650862335872 learning.py:512] global step 4147: loss = 2.1259 (0.757 sec/step)\n","INFO:tensorflow:global step 4148: loss = 2.0763 (0.761 sec/step)\n","I0908 16:21:08.627341 140650862335872 learning.py:512] global step 4148: loss = 2.0763 (0.761 sec/step)\n","INFO:tensorflow:global step 4149: loss = 2.1962 (0.775 sec/step)\n","I0908 16:21:09.403861 140650862335872 learning.py:512] global step 4149: loss = 2.1962 (0.775 sec/step)\n","INFO:tensorflow:global step 4150: loss = 1.8299 (0.775 sec/step)\n","I0908 16:21:10.180660 140650862335872 learning.py:512] global step 4150: loss = 1.8299 (0.775 sec/step)\n","INFO:tensorflow:global step 4151: loss = 1.8595 (0.764 sec/step)\n","I0908 16:21:10.946849 140650862335872 learning.py:512] global step 4151: loss = 1.8595 (0.764 sec/step)\n","INFO:tensorflow:global step 4152: loss = 2.1479 (0.778 sec/step)\n","I0908 16:21:11.726355 140650862335872 learning.py:512] global step 4152: loss = 2.1479 (0.778 sec/step)\n","INFO:tensorflow:global step 4153: loss = 1.9145 (0.757 sec/step)\n","I0908 16:21:12.484920 140650862335872 learning.py:512] global step 4153: loss = 1.9145 (0.757 sec/step)\n","INFO:tensorflow:global step 4154: loss = 1.9353 (0.740 sec/step)\n","I0908 16:21:13.226939 140650862335872 learning.py:512] global step 4154: loss = 1.9353 (0.740 sec/step)\n","INFO:tensorflow:global step 4155: loss = 2.2014 (0.775 sec/step)\n","I0908 16:21:14.003184 140650862335872 learning.py:512] global step 4155: loss = 2.2014 (0.775 sec/step)\n","INFO:tensorflow:global step 4156: loss = 2.4361 (0.770 sec/step)\n","I0908 16:21:14.775310 140650862335872 learning.py:512] global step 4156: loss = 2.4361 (0.770 sec/step)\n","INFO:tensorflow:global step 4157: loss = 1.8971 (0.774 sec/step)\n","I0908 16:21:15.550947 140650862335872 learning.py:512] global step 4157: loss = 1.8971 (0.774 sec/step)\n","INFO:tensorflow:global step 4158: loss = 2.2111 (0.750 sec/step)\n","I0908 16:21:16.302735 140650862335872 learning.py:512] global step 4158: loss = 2.2111 (0.750 sec/step)\n","INFO:tensorflow:global step 4159: loss = 1.8304 (0.767 sec/step)\n","I0908 16:21:17.071439 140650862335872 learning.py:512] global step 4159: loss = 1.8304 (0.767 sec/step)\n","INFO:tensorflow:global step 4160: loss = 1.9189 (0.771 sec/step)\n","I0908 16:21:17.844510 140650862335872 learning.py:512] global step 4160: loss = 1.9189 (0.771 sec/step)\n","INFO:tensorflow:global step 4161: loss = 2.2607 (0.757 sec/step)\n","I0908 16:21:18.603434 140650862335872 learning.py:512] global step 4161: loss = 2.2607 (0.757 sec/step)\n","INFO:tensorflow:global step 4162: loss = 1.8166 (0.774 sec/step)\n","I0908 16:21:19.379338 140650862335872 learning.py:512] global step 4162: loss = 1.8166 (0.774 sec/step)\n","INFO:tensorflow:global step 4163: loss = 2.3810 (0.756 sec/step)\n","I0908 16:21:20.136619 140650862335872 learning.py:512] global step 4163: loss = 2.3810 (0.756 sec/step)\n","INFO:tensorflow:global step 4164: loss = 1.7880 (0.755 sec/step)\n","I0908 16:21:20.893077 140650862335872 learning.py:512] global step 4164: loss = 1.7880 (0.755 sec/step)\n","INFO:tensorflow:global step 4165: loss = 1.9406 (0.773 sec/step)\n","I0908 16:21:21.667861 140650862335872 learning.py:512] global step 4165: loss = 1.9406 (0.773 sec/step)\n","INFO:tensorflow:global step 4166: loss = 2.1307 (0.742 sec/step)\n","I0908 16:21:22.411353 140650862335872 learning.py:512] global step 4166: loss = 2.1307 (0.742 sec/step)\n","INFO:tensorflow:global step 4167: loss = 2.1544 (0.768 sec/step)\n","I0908 16:21:23.180877 140650862335872 learning.py:512] global step 4167: loss = 2.1544 (0.768 sec/step)\n","INFO:tensorflow:global step 4168: loss = 1.7273 (0.764 sec/step)\n","I0908 16:21:23.946395 140650862335872 learning.py:512] global step 4168: loss = 1.7273 (0.764 sec/step)\n","INFO:tensorflow:global step 4169: loss = 2.1744 (0.762 sec/step)\n","I0908 16:21:24.710223 140650862335872 learning.py:512] global step 4169: loss = 2.1744 (0.762 sec/step)\n","INFO:tensorflow:global step 4170: loss = 2.0484 (0.737 sec/step)\n","I0908 16:21:25.448477 140650862335872 learning.py:512] global step 4170: loss = 2.0484 (0.737 sec/step)\n","INFO:tensorflow:global step 4171: loss = 2.1424 (0.742 sec/step)\n","I0908 16:21:26.192196 140650862335872 learning.py:512] global step 4171: loss = 2.1424 (0.742 sec/step)\n","INFO:tensorflow:global step 4172: loss = 1.9742 (0.771 sec/step)\n","I0908 16:21:26.965241 140650862335872 learning.py:512] global step 4172: loss = 1.9742 (0.771 sec/step)\n","INFO:tensorflow:global step 4173: loss = 2.0521 (0.762 sec/step)\n","I0908 16:21:27.729280 140650862335872 learning.py:512] global step 4173: loss = 2.0521 (0.762 sec/step)\n","INFO:tensorflow:global step 4174: loss = 1.9239 (0.769 sec/step)\n","I0908 16:21:28.499777 140650862335872 learning.py:512] global step 4174: loss = 1.9239 (0.769 sec/step)\n","INFO:tensorflow:global step 4175: loss = 2.0250 (0.741 sec/step)\n","I0908 16:21:29.242325 140650862335872 learning.py:512] global step 4175: loss = 2.0250 (0.741 sec/step)\n","INFO:tensorflow:global step 4176: loss = 2.1003 (0.767 sec/step)\n","I0908 16:21:30.010646 140650862335872 learning.py:512] global step 4176: loss = 2.1003 (0.767 sec/step)\n","INFO:tensorflow:global step 4177: loss = 2.3888 (0.756 sec/step)\n","I0908 16:21:30.768490 140650862335872 learning.py:512] global step 4177: loss = 2.3888 (0.756 sec/step)\n","INFO:tensorflow:global step 4178: loss = 2.5048 (0.759 sec/step)\n","I0908 16:21:31.528898 140650862335872 learning.py:512] global step 4178: loss = 2.5048 (0.759 sec/step)\n","INFO:tensorflow:global step 4179: loss = 2.0151 (0.776 sec/step)\n","I0908 16:21:32.306785 140650862335872 learning.py:512] global step 4179: loss = 2.0151 (0.776 sec/step)\n","INFO:tensorflow:global step 4180: loss = 1.9320 (0.759 sec/step)\n","I0908 16:21:33.067137 140650862335872 learning.py:512] global step 4180: loss = 1.9320 (0.759 sec/step)\n","INFO:tensorflow:global step 4181: loss = 2.2259 (0.757 sec/step)\n","I0908 16:21:33.826239 140650862335872 learning.py:512] global step 4181: loss = 2.2259 (0.757 sec/step)\n","INFO:tensorflow:global step 4182: loss = 2.0723 (0.764 sec/step)\n","I0908 16:21:34.591546 140650862335872 learning.py:512] global step 4182: loss = 2.0723 (0.764 sec/step)\n","INFO:tensorflow:global step 4183: loss = 2.2934 (0.739 sec/step)\n","I0908 16:21:35.331959 140650862335872 learning.py:512] global step 4183: loss = 2.2934 (0.739 sec/step)\n","INFO:tensorflow:global step 4184: loss = 2.5602 (0.768 sec/step)\n","I0908 16:21:36.101469 140650862335872 learning.py:512] global step 4184: loss = 2.5602 (0.768 sec/step)\n","INFO:tensorflow:global step 4185: loss = 2.1421 (0.762 sec/step)\n","I0908 16:21:36.865572 140650862335872 learning.py:512] global step 4185: loss = 2.1421 (0.762 sec/step)\n","INFO:tensorflow:global step 4186: loss = 1.7689 (0.764 sec/step)\n","I0908 16:21:37.631112 140650862335872 learning.py:512] global step 4186: loss = 1.7689 (0.764 sec/step)\n","INFO:tensorflow:global step 4187: loss = 2.1944 (0.759 sec/step)\n","I0908 16:21:38.391760 140650862335872 learning.py:512] global step 4187: loss = 2.1944 (0.759 sec/step)\n","INFO:tensorflow:global step 4188: loss = 1.6867 (0.742 sec/step)\n","I0908 16:21:39.135417 140650862335872 learning.py:512] global step 4188: loss = 1.6867 (0.742 sec/step)\n","INFO:tensorflow:global step 4189: loss = 1.7776 (0.739 sec/step)\n","I0908 16:21:39.876283 140650862335872 learning.py:512] global step 4189: loss = 1.7776 (0.739 sec/step)\n","INFO:tensorflow:global step 4190: loss = 2.0609 (0.736 sec/step)\n","I0908 16:21:40.614267 140650862335872 learning.py:512] global step 4190: loss = 2.0609 (0.736 sec/step)\n","INFO:tensorflow:global step 4191: loss = 1.8200 (0.763 sec/step)\n","I0908 16:21:41.379214 140650862335872 learning.py:512] global step 4191: loss = 1.8200 (0.763 sec/step)\n","INFO:tensorflow:global step 4192: loss = 2.2572 (0.753 sec/step)\n","I0908 16:21:42.133393 140650862335872 learning.py:512] global step 4192: loss = 2.2572 (0.753 sec/step)\n","INFO:tensorflow:global step 4193: loss = 1.9257 (0.762 sec/step)\n","I0908 16:21:42.897514 140650862335872 learning.py:512] global step 4193: loss = 1.9257 (0.762 sec/step)\n","INFO:tensorflow:global step 4194: loss = 1.8978 (0.758 sec/step)\n","I0908 16:21:43.657329 140650862335872 learning.py:512] global step 4194: loss = 1.8978 (0.758 sec/step)\n","INFO:tensorflow:global step 4195: loss = 1.8564 (0.769 sec/step)\n","I0908 16:21:44.428288 140650862335872 learning.py:512] global step 4195: loss = 1.8564 (0.769 sec/step)\n","INFO:tensorflow:global step 4196: loss = 1.9985 (0.761 sec/step)\n","I0908 16:21:45.190741 140650862335872 learning.py:512] global step 4196: loss = 1.9985 (0.761 sec/step)\n","INFO:tensorflow:global step 4197: loss = 2.1877 (0.749 sec/step)\n","I0908 16:21:45.941758 140650862335872 learning.py:512] global step 4197: loss = 2.1877 (0.749 sec/step)\n","INFO:tensorflow:global step 4198: loss = 2.5790 (1.275 sec/step)\n","I0908 16:21:47.218062 140650862335872 learning.py:512] global step 4198: loss = 2.5790 (1.275 sec/step)\n","INFO:tensorflow:Recording summary at step 4198.\n","I0908 16:21:47.381273 140646941251328 supervisor.py:1050] Recording summary at step 4198.\n","INFO:tensorflow:global step 4199: loss = 1.8370 (0.749 sec/step)\n","I0908 16:21:47.969231 140650862335872 learning.py:512] global step 4199: loss = 1.8370 (0.749 sec/step)\n","INFO:tensorflow:global step 4200: loss = 2.0440 (0.745 sec/step)\n","I0908 16:21:48.716195 140650862335872 learning.py:512] global step 4200: loss = 2.0440 (0.745 sec/step)\n","INFO:tensorflow:global step 4201: loss = 1.9107 (0.744 sec/step)\n","I0908 16:21:49.461613 140650862335872 learning.py:512] global step 4201: loss = 1.9107 (0.744 sec/step)\n","INFO:tensorflow:global step 4202: loss = 2.1360 (0.761 sec/step)\n","I0908 16:21:50.224053 140650862335872 learning.py:512] global step 4202: loss = 2.1360 (0.761 sec/step)\n","INFO:tensorflow:global step 4203: loss = 2.0548 (0.745 sec/step)\n","I0908 16:21:50.970462 140650862335872 learning.py:512] global step 4203: loss = 2.0548 (0.745 sec/step)\n","INFO:tensorflow:global step 4204: loss = 2.1089 (0.766 sec/step)\n","I0908 16:21:51.738268 140650862335872 learning.py:512] global step 4204: loss = 2.1089 (0.766 sec/step)\n","INFO:tensorflow:global step 4205: loss = 2.2138 (0.747 sec/step)\n","I0908 16:21:52.487470 140650862335872 learning.py:512] global step 4205: loss = 2.2138 (0.747 sec/step)\n","INFO:tensorflow:global step 4206: loss = 2.0952 (0.738 sec/step)\n","I0908 16:21:53.226720 140650862335872 learning.py:512] global step 4206: loss = 2.0952 (0.738 sec/step)\n","INFO:tensorflow:global step 4207: loss = 1.9859 (0.742 sec/step)\n","I0908 16:21:53.969888 140650862335872 learning.py:512] global step 4207: loss = 1.9859 (0.742 sec/step)\n","INFO:tensorflow:global step 4208: loss = 1.5839 (0.751 sec/step)\n","I0908 16:21:54.722950 140650862335872 learning.py:512] global step 4208: loss = 1.5839 (0.751 sec/step)\n","INFO:tensorflow:global step 4209: loss = 2.3076 (0.758 sec/step)\n","I0908 16:21:55.483181 140650862335872 learning.py:512] global step 4209: loss = 2.3076 (0.758 sec/step)\n","INFO:tensorflow:global step 4210: loss = 2.0881 (0.757 sec/step)\n","I0908 16:21:56.242290 140650862335872 learning.py:512] global step 4210: loss = 2.0881 (0.757 sec/step)\n","INFO:tensorflow:global step 4211: loss = 2.0908 (0.764 sec/step)\n","I0908 16:21:57.007820 140650862335872 learning.py:512] global step 4211: loss = 2.0908 (0.764 sec/step)\n","INFO:tensorflow:global step 4212: loss = 2.2656 (0.746 sec/step)\n","I0908 16:21:57.755198 140650862335872 learning.py:512] global step 4212: loss = 2.2656 (0.746 sec/step)\n","INFO:tensorflow:global step 4213: loss = 2.1737 (0.746 sec/step)\n","I0908 16:21:58.503289 140650862335872 learning.py:512] global step 4213: loss = 2.1737 (0.746 sec/step)\n","INFO:tensorflow:global step 4214: loss = 1.7986 (0.752 sec/step)\n","I0908 16:21:59.257416 140650862335872 learning.py:512] global step 4214: loss = 1.7986 (0.752 sec/step)\n","INFO:tensorflow:global step 4215: loss = 2.3256 (0.771 sec/step)\n","I0908 16:22:00.030650 140650862335872 learning.py:512] global step 4215: loss = 2.3256 (0.771 sec/step)\n","INFO:tensorflow:global step 4216: loss = 2.5713 (0.752 sec/step)\n","I0908 16:22:00.784518 140650862335872 learning.py:512] global step 4216: loss = 2.5713 (0.752 sec/step)\n","INFO:tensorflow:global step 4217: loss = 2.0941 (0.782 sec/step)\n","I0908 16:22:01.567962 140650862335872 learning.py:512] global step 4217: loss = 2.0941 (0.782 sec/step)\n","INFO:tensorflow:global step 4218: loss = 2.2450 (0.744 sec/step)\n","I0908 16:22:02.313082 140650862335872 learning.py:512] global step 4218: loss = 2.2450 (0.744 sec/step)\n","INFO:tensorflow:global step 4219: loss = 2.3532 (0.755 sec/step)\n","I0908 16:22:03.069550 140650862335872 learning.py:512] global step 4219: loss = 2.3532 (0.755 sec/step)\n","INFO:tensorflow:global step 4220: loss = 2.0452 (0.756 sec/step)\n","I0908 16:22:03.827116 140650862335872 learning.py:512] global step 4220: loss = 2.0452 (0.756 sec/step)\n","INFO:tensorflow:global step 4221: loss = 2.0553 (0.768 sec/step)\n","I0908 16:22:04.597423 140650862335872 learning.py:512] global step 4221: loss = 2.0553 (0.768 sec/step)\n","INFO:tensorflow:global step 4222: loss = 1.8102 (0.776 sec/step)\n","I0908 16:22:05.375002 140650862335872 learning.py:512] global step 4222: loss = 1.8102 (0.776 sec/step)\n","INFO:tensorflow:global step 4223: loss = 2.3557 (0.766 sec/step)\n","I0908 16:22:06.143033 140650862335872 learning.py:512] global step 4223: loss = 2.3557 (0.766 sec/step)\n","INFO:tensorflow:global step 4224: loss = 3.0050 (0.754 sec/step)\n","I0908 16:22:06.900757 140650862335872 learning.py:512] global step 4224: loss = 3.0050 (0.754 sec/step)\n","INFO:tensorflow:global step 4225: loss = 2.3676 (0.762 sec/step)\n","I0908 16:22:07.665025 140650862335872 learning.py:512] global step 4225: loss = 2.3676 (0.762 sec/step)\n","INFO:tensorflow:global step 4226: loss = 2.5887 (0.749 sec/step)\n","I0908 16:22:08.415620 140650862335872 learning.py:512] global step 4226: loss = 2.5887 (0.749 sec/step)\n","INFO:tensorflow:global step 4227: loss = 2.1626 (0.755 sec/step)\n","I0908 16:22:09.172497 140650862335872 learning.py:512] global step 4227: loss = 2.1626 (0.755 sec/step)\n","INFO:tensorflow:global step 4228: loss = 1.9193 (0.745 sec/step)\n","I0908 16:22:09.919114 140650862335872 learning.py:512] global step 4228: loss = 1.9193 (0.745 sec/step)\n","INFO:tensorflow:global step 4229: loss = 2.2964 (0.758 sec/step)\n","I0908 16:22:10.678869 140650862335872 learning.py:512] global step 4229: loss = 2.2964 (0.758 sec/step)\n","INFO:tensorflow:global step 4230: loss = 2.3357 (0.753 sec/step)\n","I0908 16:22:11.433070 140650862335872 learning.py:512] global step 4230: loss = 2.3357 (0.753 sec/step)\n","INFO:tensorflow:global step 4231: loss = 1.8533 (0.759 sec/step)\n","I0908 16:22:12.193487 140650862335872 learning.py:512] global step 4231: loss = 1.8533 (0.759 sec/step)\n","INFO:tensorflow:global step 4232: loss = 2.0702 (0.757 sec/step)\n","I0908 16:22:12.952340 140650862335872 learning.py:512] global step 4232: loss = 2.0702 (0.757 sec/step)\n","INFO:tensorflow:global step 4233: loss = 1.7219 (0.741 sec/step)\n","I0908 16:22:13.695053 140650862335872 learning.py:512] global step 4233: loss = 1.7219 (0.741 sec/step)\n","INFO:tensorflow:global step 4234: loss = 2.2243 (0.761 sec/step)\n","I0908 16:22:14.457948 140650862335872 learning.py:512] global step 4234: loss = 2.2243 (0.761 sec/step)\n","INFO:tensorflow:global step 4235: loss = 1.8323 (0.762 sec/step)\n","I0908 16:22:15.222076 140650862335872 learning.py:512] global step 4235: loss = 1.8323 (0.762 sec/step)\n","INFO:tensorflow:global step 4236: loss = 2.0540 (0.761 sec/step)\n","I0908 16:22:15.985094 140650862335872 learning.py:512] global step 4236: loss = 2.0540 (0.761 sec/step)\n","INFO:tensorflow:global step 4237: loss = 1.7235 (0.784 sec/step)\n","I0908 16:22:16.770550 140650862335872 learning.py:512] global step 4237: loss = 1.7235 (0.784 sec/step)\n","INFO:tensorflow:global step 4238: loss = 2.0949 (0.756 sec/step)\n","I0908 16:22:17.527998 140650862335872 learning.py:512] global step 4238: loss = 2.0949 (0.756 sec/step)\n","INFO:tensorflow:global step 4239: loss = 1.9444 (0.762 sec/step)\n","I0908 16:22:18.291404 140650862335872 learning.py:512] global step 4239: loss = 1.9444 (0.762 sec/step)\n","INFO:tensorflow:global step 4240: loss = 2.0034 (0.747 sec/step)\n","I0908 16:22:19.039628 140650862335872 learning.py:512] global step 4240: loss = 2.0034 (0.747 sec/step)\n","INFO:tensorflow:global step 4241: loss = 2.0656 (0.753 sec/step)\n","I0908 16:22:19.794595 140650862335872 learning.py:512] global step 4241: loss = 2.0656 (0.753 sec/step)\n","INFO:tensorflow:global step 4242: loss = 1.9113 (0.746 sec/step)\n","I0908 16:22:20.541798 140650862335872 learning.py:512] global step 4242: loss = 1.9113 (0.746 sec/step)\n","INFO:tensorflow:global step 4243: loss = 2.2180 (0.743 sec/step)\n","I0908 16:22:21.286666 140650862335872 learning.py:512] global step 4243: loss = 2.2180 (0.743 sec/step)\n","INFO:tensorflow:global step 4244: loss = 2.0676 (0.768 sec/step)\n","I0908 16:22:22.056770 140650862335872 learning.py:512] global step 4244: loss = 2.0676 (0.768 sec/step)\n","INFO:tensorflow:global step 4245: loss = 2.2637 (0.754 sec/step)\n","I0908 16:22:22.812791 140650862335872 learning.py:512] global step 4245: loss = 2.2637 (0.754 sec/step)\n","INFO:tensorflow:global step 4246: loss = 2.7049 (0.745 sec/step)\n","I0908 16:22:23.559461 140650862335872 learning.py:512] global step 4246: loss = 2.7049 (0.745 sec/step)\n","INFO:tensorflow:global step 4247: loss = 2.1257 (0.763 sec/step)\n","I0908 16:22:24.324082 140650862335872 learning.py:512] global step 4247: loss = 2.1257 (0.763 sec/step)\n","INFO:tensorflow:global step 4248: loss = 2.0874 (0.763 sec/step)\n","I0908 16:22:25.088388 140650862335872 learning.py:512] global step 4248: loss = 2.0874 (0.763 sec/step)\n","INFO:tensorflow:global step 4249: loss = 2.5516 (0.777 sec/step)\n","I0908 16:22:25.867571 140650862335872 learning.py:512] global step 4249: loss = 2.5516 (0.777 sec/step)\n","INFO:tensorflow:global step 4250: loss = 2.0641 (0.756 sec/step)\n","I0908 16:22:26.625499 140650862335872 learning.py:512] global step 4250: loss = 2.0641 (0.756 sec/step)\n","INFO:tensorflow:global step 4251: loss = 1.9247 (0.758 sec/step)\n","I0908 16:22:27.385293 140650862335872 learning.py:512] global step 4251: loss = 1.9247 (0.758 sec/step)\n","INFO:tensorflow:global step 4252: loss = 1.4935 (0.770 sec/step)\n","I0908 16:22:28.157315 140650862335872 learning.py:512] global step 4252: loss = 1.4935 (0.770 sec/step)\n","INFO:tensorflow:global step 4253: loss = 2.2043 (0.750 sec/step)\n","I0908 16:22:28.909064 140650862335872 learning.py:512] global step 4253: loss = 2.2043 (0.750 sec/step)\n","INFO:tensorflow:global step 4254: loss = 1.8976 (0.742 sec/step)\n","I0908 16:22:29.652867 140650862335872 learning.py:512] global step 4254: loss = 1.8976 (0.742 sec/step)\n","INFO:tensorflow:global step 4255: loss = 2.1718 (0.750 sec/step)\n","I0908 16:22:30.404641 140650862335872 learning.py:512] global step 4255: loss = 2.1718 (0.750 sec/step)\n","INFO:tensorflow:global step 4256: loss = 2.1705 (0.746 sec/step)\n","I0908 16:22:31.151766 140650862335872 learning.py:512] global step 4256: loss = 2.1705 (0.746 sec/step)\n","INFO:tensorflow:global step 4257: loss = 2.0227 (0.760 sec/step)\n","I0908 16:22:31.913188 140650862335872 learning.py:512] global step 4257: loss = 2.0227 (0.760 sec/step)\n","INFO:tensorflow:global step 4258: loss = 1.9774 (0.757 sec/step)\n","I0908 16:22:32.671702 140650862335872 learning.py:512] global step 4258: loss = 1.9774 (0.757 sec/step)\n","INFO:tensorflow:global step 4259: loss = 1.7483 (0.764 sec/step)\n","I0908 16:22:33.437641 140650862335872 learning.py:512] global step 4259: loss = 1.7483 (0.764 sec/step)\n","INFO:tensorflow:global step 4260: loss = 2.1508 (0.759 sec/step)\n","I0908 16:22:34.198321 140650862335872 learning.py:512] global step 4260: loss = 2.1508 (0.759 sec/step)\n","INFO:tensorflow:global step 4261: loss = 2.1442 (0.745 sec/step)\n","I0908 16:22:34.945159 140650862335872 learning.py:512] global step 4261: loss = 2.1442 (0.745 sec/step)\n","INFO:tensorflow:global step 4262: loss = 2.1540 (0.742 sec/step)\n","I0908 16:22:35.689210 140650862335872 learning.py:512] global step 4262: loss = 2.1540 (0.742 sec/step)\n","INFO:tensorflow:global step 4263: loss = 2.3019 (0.756 sec/step)\n","I0908 16:22:36.447089 140650862335872 learning.py:512] global step 4263: loss = 2.3019 (0.756 sec/step)\n","INFO:tensorflow:global step 4264: loss = 2.5220 (0.757 sec/step)\n","I0908 16:22:37.205936 140650862335872 learning.py:512] global step 4264: loss = 2.5220 (0.757 sec/step)\n","INFO:tensorflow:global step 4265: loss = 1.9252 (0.738 sec/step)\n","I0908 16:22:37.946058 140650862335872 learning.py:512] global step 4265: loss = 1.9252 (0.738 sec/step)\n","INFO:tensorflow:global step 4266: loss = 2.4338 (0.756 sec/step)\n","I0908 16:22:38.704136 140650862335872 learning.py:512] global step 4266: loss = 2.4338 (0.756 sec/step)\n","INFO:tensorflow:global step 4267: loss = 1.9995 (0.787 sec/step)\n","I0908 16:22:39.492578 140650862335872 learning.py:512] global step 4267: loss = 1.9995 (0.787 sec/step)\n","INFO:tensorflow:global step 4268: loss = 2.0682 (0.761 sec/step)\n","I0908 16:22:40.254827 140650862335872 learning.py:512] global step 4268: loss = 2.0682 (0.761 sec/step)\n","INFO:tensorflow:global step 4269: loss = 1.9992 (0.754 sec/step)\n","I0908 16:22:41.010330 140650862335872 learning.py:512] global step 4269: loss = 1.9992 (0.754 sec/step)\n","INFO:tensorflow:global step 4270: loss = 2.1684 (0.773 sec/step)\n","I0908 16:22:41.785140 140650862335872 learning.py:512] global step 4270: loss = 2.1684 (0.773 sec/step)\n","INFO:tensorflow:global step 4271: loss = 2.2882 (0.783 sec/step)\n","I0908 16:22:42.569283 140650862335872 learning.py:512] global step 4271: loss = 2.2882 (0.783 sec/step)\n","INFO:tensorflow:global step 4272: loss = 2.7145 (0.758 sec/step)\n","I0908 16:22:43.328682 140650862335872 learning.py:512] global step 4272: loss = 2.7145 (0.758 sec/step)\n","INFO:tensorflow:global step 4273: loss = 1.8921 (0.737 sec/step)\n","I0908 16:22:44.067351 140650862335872 learning.py:512] global step 4273: loss = 1.8921 (0.737 sec/step)\n","INFO:tensorflow:global step 4274: loss = 2.1979 (0.758 sec/step)\n","I0908 16:22:44.826496 140650862335872 learning.py:512] global step 4274: loss = 2.1979 (0.758 sec/step)\n","INFO:tensorflow:global step 4275: loss = 2.0899 (0.781 sec/step)\n","I0908 16:22:45.609362 140650862335872 learning.py:512] global step 4275: loss = 2.0899 (0.781 sec/step)\n","INFO:tensorflow:global step 4276: loss = 2.1673 (0.761 sec/step)\n","I0908 16:22:46.372486 140650862335872 learning.py:512] global step 4276: loss = 2.1673 (0.761 sec/step)\n","INFO:tensorflow:global step 4277: loss = 2.1491 (0.759 sec/step)\n","I0908 16:22:47.133810 140650862335872 learning.py:512] global step 4277: loss = 2.1491 (0.759 sec/step)\n","INFO:tensorflow:global step 4278: loss = 1.9524 (0.779 sec/step)\n","I0908 16:22:47.914151 140650862335872 learning.py:512] global step 4278: loss = 1.9524 (0.779 sec/step)\n","INFO:tensorflow:global step 4279: loss = 2.2141 (0.768 sec/step)\n","I0908 16:22:48.684444 140650862335872 learning.py:512] global step 4279: loss = 2.2141 (0.768 sec/step)\n","INFO:tensorflow:global step 4280: loss = 1.7087 (0.738 sec/step)\n","I0908 16:22:49.424019 140650862335872 learning.py:512] global step 4280: loss = 1.7087 (0.738 sec/step)\n","INFO:tensorflow:global step 4281: loss = 2.1325 (0.744 sec/step)\n","I0908 16:22:50.170064 140650862335872 learning.py:512] global step 4281: loss = 2.1325 (0.744 sec/step)\n","INFO:tensorflow:global step 4282: loss = 2.0694 (0.776 sec/step)\n","I0908 16:22:50.947463 140650862335872 learning.py:512] global step 4282: loss = 2.0694 (0.776 sec/step)\n","INFO:tensorflow:global step 4283: loss = 2.1410 (0.757 sec/step)\n","I0908 16:22:51.706099 140650862335872 learning.py:512] global step 4283: loss = 2.1410 (0.757 sec/step)\n","INFO:tensorflow:global step 4284: loss = 1.8415 (0.736 sec/step)\n","I0908 16:22:52.443711 140650862335872 learning.py:512] global step 4284: loss = 1.8415 (0.736 sec/step)\n","INFO:tensorflow:global step 4285: loss = 1.7691 (0.756 sec/step)\n","I0908 16:22:53.200876 140650862335872 learning.py:512] global step 4285: loss = 1.7691 (0.756 sec/step)\n","INFO:tensorflow:global step 4286: loss = 1.9057 (0.764 sec/step)\n","I0908 16:22:53.966492 140650862335872 learning.py:512] global step 4286: loss = 1.9057 (0.764 sec/step)\n","INFO:tensorflow:global step 4287: loss = 2.1256 (0.752 sec/step)\n","I0908 16:22:54.719895 140650862335872 learning.py:512] global step 4287: loss = 2.1256 (0.752 sec/step)\n","INFO:tensorflow:global step 4288: loss = 1.6647 (0.742 sec/step)\n","I0908 16:22:55.464082 140650862335872 learning.py:512] global step 4288: loss = 1.6647 (0.742 sec/step)\n","INFO:tensorflow:global step 4289: loss = 2.0304 (0.771 sec/step)\n","I0908 16:22:56.237189 140650862335872 learning.py:512] global step 4289: loss = 2.0304 (0.771 sec/step)\n","INFO:tensorflow:global step 4290: loss = 2.4338 (0.765 sec/step)\n","I0908 16:22:57.003265 140650862335872 learning.py:512] global step 4290: loss = 2.4338 (0.765 sec/step)\n","INFO:tensorflow:global step 4291: loss = 1.9760 (0.768 sec/step)\n","I0908 16:22:57.772828 140650862335872 learning.py:512] global step 4291: loss = 1.9760 (0.768 sec/step)\n","INFO:tensorflow:global step 4292: loss = 2.1445 (0.750 sec/step)\n","I0908 16:22:58.524708 140650862335872 learning.py:512] global step 4292: loss = 2.1445 (0.750 sec/step)\n","INFO:tensorflow:global step 4293: loss = 1.9949 (0.758 sec/step)\n","I0908 16:22:59.284244 140650862335872 learning.py:512] global step 4293: loss = 1.9949 (0.758 sec/step)\n","INFO:tensorflow:global step 4294: loss = 1.8425 (0.766 sec/step)\n","I0908 16:23:00.051592 140650862335872 learning.py:512] global step 4294: loss = 1.8425 (0.766 sec/step)\n","INFO:tensorflow:global step 4295: loss = 1.8078 (0.747 sec/step)\n","I0908 16:23:00.800714 140650862335872 learning.py:512] global step 4295: loss = 1.8078 (0.747 sec/step)\n","INFO:tensorflow:global step 4296: loss = 2.3950 (0.762 sec/step)\n","I0908 16:23:01.564284 140650862335872 learning.py:512] global step 4296: loss = 2.3950 (0.762 sec/step)\n","INFO:tensorflow:global step 4297: loss = 2.0539 (0.735 sec/step)\n","I0908 16:23:02.301270 140650862335872 learning.py:512] global step 4297: loss = 2.0539 (0.735 sec/step)\n","INFO:tensorflow:global step 4298: loss = 2.4231 (0.769 sec/step)\n","I0908 16:23:03.072263 140650862335872 learning.py:512] global step 4298: loss = 2.4231 (0.769 sec/step)\n","INFO:tensorflow:global step 4299: loss = 1.7273 (0.737 sec/step)\n","I0908 16:23:03.810996 140650862335872 learning.py:512] global step 4299: loss = 1.7273 (0.737 sec/step)\n","INFO:tensorflow:global step 4300: loss = 2.2308 (0.758 sec/step)\n","I0908 16:23:04.570276 140650862335872 learning.py:512] global step 4300: loss = 2.2308 (0.758 sec/step)\n","INFO:tensorflow:global step 4301: loss = 1.8362 (0.746 sec/step)\n","I0908 16:23:05.318228 140650862335872 learning.py:512] global step 4301: loss = 1.8362 (0.746 sec/step)\n","INFO:tensorflow:global step 4302: loss = 2.3328 (0.756 sec/step)\n","I0908 16:23:06.076202 140650862335872 learning.py:512] global step 4302: loss = 2.3328 (0.756 sec/step)\n","INFO:tensorflow:global step 4303: loss = 2.4912 (0.747 sec/step)\n","I0908 16:23:06.825659 140650862335872 learning.py:512] global step 4303: loss = 2.4912 (0.747 sec/step)\n","INFO:tensorflow:global step 4304: loss = 1.9749 (0.744 sec/step)\n","I0908 16:23:07.571359 140650862335872 learning.py:512] global step 4304: loss = 1.9749 (0.744 sec/step)\n","INFO:tensorflow:global step 4305: loss = 2.0957 (0.768 sec/step)\n","I0908 16:23:08.340685 140650862335872 learning.py:512] global step 4305: loss = 2.0957 (0.768 sec/step)\n","INFO:tensorflow:global step 4306: loss = 1.9602 (0.751 sec/step)\n","I0908 16:23:09.092837 140650862335872 learning.py:512] global step 4306: loss = 1.9602 (0.751 sec/step)\n","INFO:tensorflow:global step 4307: loss = 2.1693 (0.742 sec/step)\n","I0908 16:23:09.837134 140650862335872 learning.py:512] global step 4307: loss = 2.1693 (0.742 sec/step)\n","INFO:tensorflow:global step 4308: loss = 1.7170 (0.739 sec/step)\n","I0908 16:23:10.578234 140650862335872 learning.py:512] global step 4308: loss = 1.7170 (0.739 sec/step)\n","INFO:tensorflow:global step 4309: loss = 2.5370 (0.741 sec/step)\n","I0908 16:23:11.320513 140650862335872 learning.py:512] global step 4309: loss = 2.5370 (0.741 sec/step)\n","INFO:tensorflow:global step 4310: loss = 1.8505 (0.739 sec/step)\n","I0908 16:23:12.061127 140650862335872 learning.py:512] global step 4310: loss = 1.8505 (0.739 sec/step)\n","INFO:tensorflow:global step 4311: loss = 2.5675 (0.770 sec/step)\n","I0908 16:23:12.833297 140650862335872 learning.py:512] global step 4311: loss = 2.5675 (0.770 sec/step)\n","INFO:tensorflow:global step 4312: loss = 2.1897 (0.752 sec/step)\n","I0908 16:23:13.587274 140650862335872 learning.py:512] global step 4312: loss = 2.1897 (0.752 sec/step)\n","INFO:tensorflow:global step 4313: loss = 2.2534 (0.745 sec/step)\n","I0908 16:23:14.334367 140650862335872 learning.py:512] global step 4313: loss = 2.2534 (0.745 sec/step)\n","INFO:tensorflow:global step 4314: loss = 1.8645 (0.747 sec/step)\n","I0908 16:23:15.082732 140650862335872 learning.py:512] global step 4314: loss = 1.8645 (0.747 sec/step)\n","INFO:tensorflow:global step 4315: loss = 2.2242 (0.748 sec/step)\n","I0908 16:23:15.831851 140650862335872 learning.py:512] global step 4315: loss = 2.2242 (0.748 sec/step)\n","INFO:tensorflow:global step 4316: loss = 1.9030 (0.751 sec/step)\n","I0908 16:23:16.584596 140650862335872 learning.py:512] global step 4316: loss = 1.9030 (0.751 sec/step)\n","INFO:tensorflow:global step 4317: loss = 1.8550 (0.757 sec/step)\n","I0908 16:23:17.342992 140650862335872 learning.py:512] global step 4317: loss = 1.8550 (0.757 sec/step)\n","INFO:tensorflow:global step 4318: loss = 2.0759 (0.747 sec/step)\n","I0908 16:23:18.091769 140650862335872 learning.py:512] global step 4318: loss = 2.0759 (0.747 sec/step)\n","INFO:tensorflow:global step 4319: loss = 2.1403 (0.766 sec/step)\n","I0908 16:23:18.859337 140650862335872 learning.py:512] global step 4319: loss = 2.1403 (0.766 sec/step)\n","INFO:tensorflow:global step 4320: loss = 2.0459 (0.748 sec/step)\n","I0908 16:23:19.608858 140650862335872 learning.py:512] global step 4320: loss = 2.0459 (0.748 sec/step)\n","INFO:tensorflow:global step 4321: loss = 2.3502 (0.742 sec/step)\n","I0908 16:23:20.352746 140650862335872 learning.py:512] global step 4321: loss = 2.3502 (0.742 sec/step)\n","INFO:tensorflow:global step 4322: loss = 2.1017 (0.769 sec/step)\n","I0908 16:23:21.123280 140650862335872 learning.py:512] global step 4322: loss = 2.1017 (0.769 sec/step)\n","INFO:tensorflow:global step 4323: loss = 1.7656 (0.735 sec/step)\n","I0908 16:23:21.859825 140650862335872 learning.py:512] global step 4323: loss = 1.7656 (0.735 sec/step)\n","INFO:tensorflow:global step 4324: loss = 1.8959 (0.734 sec/step)\n","I0908 16:23:22.595553 140650862335872 learning.py:512] global step 4324: loss = 1.8959 (0.734 sec/step)\n","INFO:tensorflow:global step 4325: loss = 1.7311 (0.734 sec/step)\n","I0908 16:23:23.331022 140650862335872 learning.py:512] global step 4325: loss = 1.7311 (0.734 sec/step)\n","INFO:tensorflow:global step 4326: loss = 1.9200 (0.747 sec/step)\n","I0908 16:23:24.080110 140650862335872 learning.py:512] global step 4326: loss = 1.9200 (0.747 sec/step)\n","INFO:tensorflow:global step 4327: loss = 2.2762 (0.745 sec/step)\n","I0908 16:23:24.826265 140650862335872 learning.py:512] global step 4327: loss = 2.2762 (0.745 sec/step)\n","INFO:tensorflow:global step 4328: loss = 2.1450 (0.739 sec/step)\n","I0908 16:23:25.566833 140650862335872 learning.py:512] global step 4328: loss = 2.1450 (0.739 sec/step)\n","INFO:tensorflow:global step 4329: loss = 3.0842 (0.778 sec/step)\n","I0908 16:23:26.346435 140650862335872 learning.py:512] global step 4329: loss = 3.0842 (0.778 sec/step)\n","INFO:tensorflow:global step 4330: loss = 1.8599 (0.746 sec/step)\n","I0908 16:23:27.094284 140650862335872 learning.py:512] global step 4330: loss = 1.8599 (0.746 sec/step)\n","INFO:tensorflow:global step 4331: loss = 2.2360 (0.754 sec/step)\n","I0908 16:23:27.849869 140650862335872 learning.py:512] global step 4331: loss = 2.2360 (0.754 sec/step)\n","INFO:tensorflow:global step 4332: loss = 2.1703 (0.774 sec/step)\n","I0908 16:23:28.625704 140650862335872 learning.py:512] global step 4332: loss = 2.1703 (0.774 sec/step)\n","INFO:tensorflow:global step 4333: loss = 1.8302 (0.773 sec/step)\n","I0908 16:23:29.400122 140650862335872 learning.py:512] global step 4333: loss = 1.8302 (0.773 sec/step)\n","INFO:tensorflow:global step 4334: loss = 2.2936 (0.738 sec/step)\n","I0908 16:23:30.140026 140650862335872 learning.py:512] global step 4334: loss = 2.2936 (0.738 sec/step)\n","INFO:tensorflow:global step 4335: loss = 2.1116 (0.746 sec/step)\n","I0908 16:23:30.887926 140650862335872 learning.py:512] global step 4335: loss = 2.1116 (0.746 sec/step)\n","INFO:tensorflow:global step 4336: loss = 1.8329 (0.775 sec/step)\n","I0908 16:23:31.664982 140650862335872 learning.py:512] global step 4336: loss = 1.8329 (0.775 sec/step)\n","INFO:tensorflow:global step 4337: loss = 2.0500 (0.761 sec/step)\n","I0908 16:23:32.427992 140650862335872 learning.py:512] global step 4337: loss = 2.0500 (0.761 sec/step)\n","INFO:tensorflow:global step 4338: loss = 2.1402 (0.763 sec/step)\n","I0908 16:23:33.192297 140650862335872 learning.py:512] global step 4338: loss = 2.1402 (0.763 sec/step)\n","INFO:tensorflow:global step 4339: loss = 2.4003 (0.738 sec/step)\n","I0908 16:23:33.932055 140650862335872 learning.py:512] global step 4339: loss = 2.4003 (0.738 sec/step)\n","INFO:tensorflow:global step 4340: loss = 1.9466 (0.760 sec/step)\n","I0908 16:23:34.694158 140650862335872 learning.py:512] global step 4340: loss = 1.9466 (0.760 sec/step)\n","INFO:tensorflow:global step 4341: loss = 2.1149 (0.764 sec/step)\n","I0908 16:23:35.459619 140650862335872 learning.py:512] global step 4341: loss = 2.1149 (0.764 sec/step)\n","INFO:tensorflow:global step 4342: loss = 2.3570 (0.745 sec/step)\n","I0908 16:23:36.205996 140650862335872 learning.py:512] global step 4342: loss = 2.3570 (0.745 sec/step)\n","INFO:tensorflow:global step 4343: loss = 1.7433 (0.737 sec/step)\n","I0908 16:23:36.944792 140650862335872 learning.py:512] global step 4343: loss = 1.7433 (0.737 sec/step)\n","INFO:tensorflow:global step 4344: loss = 1.8601 (0.750 sec/step)\n","I0908 16:23:37.696748 140650862335872 learning.py:512] global step 4344: loss = 1.8601 (0.750 sec/step)\n","INFO:tensorflow:global step 4345: loss = 2.0860 (0.749 sec/step)\n","I0908 16:23:38.447691 140650862335872 learning.py:512] global step 4345: loss = 2.0860 (0.749 sec/step)\n","INFO:tensorflow:global step 4346: loss = 1.9611 (0.761 sec/step)\n","I0908 16:23:39.210742 140650862335872 learning.py:512] global step 4346: loss = 1.9611 (0.761 sec/step)\n","INFO:tensorflow:global step 4347: loss = 1.6575 (0.754 sec/step)\n","I0908 16:23:39.966096 140650862335872 learning.py:512] global step 4347: loss = 1.6575 (0.754 sec/step)\n","INFO:tensorflow:global step 4348: loss = 2.3490 (0.768 sec/step)\n","I0908 16:23:40.736096 140650862335872 learning.py:512] global step 4348: loss = 2.3490 (0.768 sec/step)\n","INFO:tensorflow:global step 4349: loss = 2.0221 (0.750 sec/step)\n","I0908 16:23:41.487934 140650862335872 learning.py:512] global step 4349: loss = 2.0221 (0.750 sec/step)\n","INFO:tensorflow:global step 4350: loss = 1.7411 (0.747 sec/step)\n","I0908 16:23:42.237340 140650862335872 learning.py:512] global step 4350: loss = 1.7411 (0.747 sec/step)\n","INFO:tensorflow:global step 4351: loss = 1.7295 (0.767 sec/step)\n","I0908 16:23:43.005990 140650862335872 learning.py:512] global step 4351: loss = 1.7295 (0.767 sec/step)\n","INFO:tensorflow:global step 4352: loss = 2.0881 (0.753 sec/step)\n","I0908 16:23:43.761229 140650862335872 learning.py:512] global step 4352: loss = 2.0881 (0.753 sec/step)\n","INFO:tensorflow:global step 4353: loss = 1.7476 (0.756 sec/step)\n","I0908 16:23:44.518589 140650862335872 learning.py:512] global step 4353: loss = 1.7476 (0.756 sec/step)\n","INFO:tensorflow:global step 4354: loss = 1.5994 (0.766 sec/step)\n","I0908 16:23:45.285984 140650862335872 learning.py:512] global step 4354: loss = 1.5994 (0.766 sec/step)\n","INFO:tensorflow:global step 4355: loss = 2.1735 (0.766 sec/step)\n","I0908 16:23:46.053665 140650862335872 learning.py:512] global step 4355: loss = 2.1735 (0.766 sec/step)\n","INFO:tensorflow:global step 4356: loss = 1.7982 (0.848 sec/step)\n","I0908 16:23:46.903972 140650862335872 learning.py:512] global step 4356: loss = 1.7982 (0.848 sec/step)\n","INFO:tensorflow:Recording summary at step 4356.\n","I0908 16:23:47.589408 140646941251328 supervisor.py:1050] Recording summary at step 4356.\n","INFO:tensorflow:global step 4357: loss = 2.0464 (1.206 sec/step)\n","I0908 16:23:48.113083 140650862335872 learning.py:512] global step 4357: loss = 2.0464 (1.206 sec/step)\n","INFO:tensorflow:global step 4358: loss = 2.1401 (0.755 sec/step)\n","I0908 16:23:48.869894 140650862335872 learning.py:512] global step 4358: loss = 2.1401 (0.755 sec/step)\n","INFO:tensorflow:global step 4359: loss = 1.6459 (0.746 sec/step)\n","I0908 16:23:49.617626 140650862335872 learning.py:512] global step 4359: loss = 1.6459 (0.746 sec/step)\n","INFO:tensorflow:global step 4360: loss = 1.6237 (0.755 sec/step)\n","I0908 16:23:50.374122 140650862335872 learning.py:512] global step 4360: loss = 1.6237 (0.755 sec/step)\n","INFO:tensorflow:global step 4361: loss = 2.0225 (0.752 sec/step)\n","I0908 16:23:51.128115 140650862335872 learning.py:512] global step 4361: loss = 2.0225 (0.752 sec/step)\n","INFO:tensorflow:global step 4362: loss = 2.0352 (0.780 sec/step)\n","I0908 16:23:51.910451 140650862335872 learning.py:512] global step 4362: loss = 2.0352 (0.780 sec/step)\n","INFO:tensorflow:global step 4363: loss = 2.1446 (0.767 sec/step)\n","I0908 16:23:52.679636 140650862335872 learning.py:512] global step 4363: loss = 2.1446 (0.767 sec/step)\n","INFO:tensorflow:global step 4364: loss = 2.4801 (0.762 sec/step)\n","I0908 16:23:53.443636 140650862335872 learning.py:512] global step 4364: loss = 2.4801 (0.762 sec/step)\n","INFO:tensorflow:global step 4365: loss = 1.6560 (0.780 sec/step)\n","I0908 16:23:54.225308 140650862335872 learning.py:512] global step 4365: loss = 1.6560 (0.780 sec/step)\n","INFO:tensorflow:global step 4366: loss = 2.0181 (0.757 sec/step)\n","I0908 16:23:54.984337 140650862335872 learning.py:512] global step 4366: loss = 2.0181 (0.757 sec/step)\n","INFO:tensorflow:global step 4367: loss = 2.1377 (0.734 sec/step)\n","I0908 16:23:55.719791 140650862335872 learning.py:512] global step 4367: loss = 2.1377 (0.734 sec/step)\n","INFO:tensorflow:global step 4368: loss = 2.0113 (0.752 sec/step)\n","I0908 16:23:56.473729 140650862335872 learning.py:512] global step 4368: loss = 2.0113 (0.752 sec/step)\n","INFO:tensorflow:global step 4369: loss = 1.7965 (0.753 sec/step)\n","I0908 16:23:57.227973 140650862335872 learning.py:512] global step 4369: loss = 1.7965 (0.753 sec/step)\n","INFO:tensorflow:global step 4370: loss = 1.5539 (0.745 sec/step)\n","I0908 16:23:57.974250 140650862335872 learning.py:512] global step 4370: loss = 1.5539 (0.745 sec/step)\n","INFO:tensorflow:global step 4371: loss = 2.3169 (0.757 sec/step)\n","I0908 16:23:58.733413 140650862335872 learning.py:512] global step 4371: loss = 2.3169 (0.757 sec/step)\n","INFO:tensorflow:global step 4372: loss = 1.9456 (0.746 sec/step)\n","I0908 16:23:59.481129 140650862335872 learning.py:512] global step 4372: loss = 1.9456 (0.746 sec/step)\n","INFO:tensorflow:global step 4373: loss = 2.5165 (0.761 sec/step)\n","I0908 16:24:00.243534 140650862335872 learning.py:512] global step 4373: loss = 2.5165 (0.761 sec/step)\n","INFO:tensorflow:global step 4374: loss = 1.8351 (0.733 sec/step)\n","I0908 16:24:00.978414 140650862335872 learning.py:512] global step 4374: loss = 1.8351 (0.733 sec/step)\n","INFO:tensorflow:global step 4375: loss = 2.1997 (0.747 sec/step)\n","I0908 16:24:01.726986 140650862335872 learning.py:512] global step 4375: loss = 2.1997 (0.747 sec/step)\n","INFO:tensorflow:global step 4376: loss = 1.4893 (0.742 sec/step)\n","I0908 16:24:02.470606 140650862335872 learning.py:512] global step 4376: loss = 1.4893 (0.742 sec/step)\n","INFO:tensorflow:global step 4377: loss = 1.8370 (0.727 sec/step)\n","I0908 16:24:03.199809 140650862335872 learning.py:512] global step 4377: loss = 1.8370 (0.727 sec/step)\n","INFO:tensorflow:global step 4378: loss = 1.8844 (0.756 sec/step)\n","I0908 16:24:03.957581 140650862335872 learning.py:512] global step 4378: loss = 1.8844 (0.756 sec/step)\n","INFO:tensorflow:global step 4379: loss = 2.0301 (0.738 sec/step)\n","I0908 16:24:04.697504 140650862335872 learning.py:512] global step 4379: loss = 2.0301 (0.738 sec/step)\n","INFO:tensorflow:global step 4380: loss = 1.6155 (0.741 sec/step)\n","I0908 16:24:05.440108 140650862335872 learning.py:512] global step 4380: loss = 1.6155 (0.741 sec/step)\n","INFO:tensorflow:global step 4381: loss = 1.9287 (0.743 sec/step)\n","I0908 16:24:06.184992 140650862335872 learning.py:512] global step 4381: loss = 1.9287 (0.743 sec/step)\n","INFO:tensorflow:global step 4382: loss = 1.8640 (0.743 sec/step)\n","I0908 16:24:06.929901 140650862335872 learning.py:512] global step 4382: loss = 1.8640 (0.743 sec/step)\n","INFO:tensorflow:global step 4383: loss = 1.6895 (0.756 sec/step)\n","I0908 16:24:07.687434 140650862335872 learning.py:512] global step 4383: loss = 1.6895 (0.756 sec/step)\n","INFO:tensorflow:global step 4384: loss = 1.9652 (0.766 sec/step)\n","I0908 16:24:08.455212 140650862335872 learning.py:512] global step 4384: loss = 1.9652 (0.766 sec/step)\n","INFO:tensorflow:global step 4385: loss = 2.2472 (0.754 sec/step)\n","I0908 16:24:09.211112 140650862335872 learning.py:512] global step 4385: loss = 2.2472 (0.754 sec/step)\n","INFO:tensorflow:global step 4386: loss = 2.2365 (0.756 sec/step)\n","I0908 16:24:09.968666 140650862335872 learning.py:512] global step 4386: loss = 2.2365 (0.756 sec/step)\n","INFO:tensorflow:global step 4387: loss = 2.1963 (0.759 sec/step)\n","I0908 16:24:10.729022 140650862335872 learning.py:512] global step 4387: loss = 2.1963 (0.759 sec/step)\n","INFO:tensorflow:global step 4388: loss = 2.1493 (0.758 sec/step)\n","I0908 16:24:11.488896 140650862335872 learning.py:512] global step 4388: loss = 2.1493 (0.758 sec/step)\n","INFO:tensorflow:global step 4389: loss = 1.9449 (0.762 sec/step)\n","I0908 16:24:12.252538 140650862335872 learning.py:512] global step 4389: loss = 1.9449 (0.762 sec/step)\n","INFO:tensorflow:global step 4390: loss = 1.9234 (0.754 sec/step)\n","I0908 16:24:13.008408 140650862335872 learning.py:512] global step 4390: loss = 1.9234 (0.754 sec/step)\n","INFO:tensorflow:global step 4391: loss = 1.9976 (0.743 sec/step)\n","I0908 16:24:13.753068 140650862335872 learning.py:512] global step 4391: loss = 1.9976 (0.743 sec/step)\n","INFO:tensorflow:global step 4392: loss = 2.0724 (0.732 sec/step)\n","I0908 16:24:14.487095 140650862335872 learning.py:512] global step 4392: loss = 2.0724 (0.732 sec/step)\n","INFO:tensorflow:global step 4393: loss = 1.9303 (0.760 sec/step)\n","I0908 16:24:15.248405 140650862335872 learning.py:512] global step 4393: loss = 1.9303 (0.760 sec/step)\n","INFO:tensorflow:global step 4394: loss = 2.5055 (0.762 sec/step)\n","I0908 16:24:16.011622 140650862335872 learning.py:512] global step 4394: loss = 2.5055 (0.762 sec/step)\n","INFO:tensorflow:global step 4395: loss = 1.7815 (0.766 sec/step)\n","I0908 16:24:16.779818 140650862335872 learning.py:512] global step 4395: loss = 1.7815 (0.766 sec/step)\n","INFO:tensorflow:global step 4396: loss = 2.1565 (0.761 sec/step)\n","I0908 16:24:17.542478 140650862335872 learning.py:512] global step 4396: loss = 2.1565 (0.761 sec/step)\n","INFO:tensorflow:global step 4397: loss = 1.7624 (0.766 sec/step)\n","I0908 16:24:18.310498 140650862335872 learning.py:512] global step 4397: loss = 1.7624 (0.766 sec/step)\n","INFO:tensorflow:global step 4398: loss = 2.0357 (0.733 sec/step)\n","I0908 16:24:19.044932 140650862335872 learning.py:512] global step 4398: loss = 2.0357 (0.733 sec/step)\n","INFO:tensorflow:global step 4399: loss = 2.1880 (0.753 sec/step)\n","I0908 16:24:19.799659 140650862335872 learning.py:512] global step 4399: loss = 2.1880 (0.753 sec/step)\n","INFO:tensorflow:global step 4400: loss = 2.0177 (0.742 sec/step)\n","I0908 16:24:20.543030 140650862335872 learning.py:512] global step 4400: loss = 2.0177 (0.742 sec/step)\n","INFO:tensorflow:global step 4401: loss = 1.5984 (0.765 sec/step)\n","I0908 16:24:21.309654 140650862335872 learning.py:512] global step 4401: loss = 1.5984 (0.765 sec/step)\n","INFO:tensorflow:global step 4402: loss = 2.3100 (0.781 sec/step)\n","I0908 16:24:22.092501 140650862335872 learning.py:512] global step 4402: loss = 2.3100 (0.781 sec/step)\n","INFO:tensorflow:global step 4403: loss = 1.8424 (0.761 sec/step)\n","I0908 16:24:22.854909 140650862335872 learning.py:512] global step 4403: loss = 1.8424 (0.761 sec/step)\n","INFO:tensorflow:global step 4404: loss = 1.7132 (0.771 sec/step)\n","I0908 16:24:23.627777 140650862335872 learning.py:512] global step 4404: loss = 1.7132 (0.771 sec/step)\n","INFO:tensorflow:global step 4405: loss = 2.2556 (0.757 sec/step)\n","I0908 16:24:24.386213 140650862335872 learning.py:512] global step 4405: loss = 2.2556 (0.757 sec/step)\n","INFO:tensorflow:global step 4406: loss = 2.0339 (0.758 sec/step)\n","I0908 16:24:25.146131 140650862335872 learning.py:512] global step 4406: loss = 2.0339 (0.758 sec/step)\n","INFO:tensorflow:global step 4407: loss = 2.2217 (0.755 sec/step)\n","I0908 16:24:25.903503 140650862335872 learning.py:512] global step 4407: loss = 2.2217 (0.755 sec/step)\n","INFO:tensorflow:global step 4408: loss = 1.9262 (0.755 sec/step)\n","I0908 16:24:26.660514 140650862335872 learning.py:512] global step 4408: loss = 1.9262 (0.755 sec/step)\n","INFO:tensorflow:global step 4409: loss = 2.0525 (0.768 sec/step)\n","I0908 16:24:27.430454 140650862335872 learning.py:512] global step 4409: loss = 2.0525 (0.768 sec/step)\n","INFO:tensorflow:global step 4410: loss = 2.2761 (0.755 sec/step)\n","I0908 16:24:28.187446 140650862335872 learning.py:512] global step 4410: loss = 2.2761 (0.755 sec/step)\n","INFO:tensorflow:global step 4411: loss = 2.0641 (0.768 sec/step)\n","I0908 16:24:28.956808 140650862335872 learning.py:512] global step 4411: loss = 2.0641 (0.768 sec/step)\n","INFO:tensorflow:global step 4412: loss = 1.9114 (0.759 sec/step)\n","I0908 16:24:29.717125 140650862335872 learning.py:512] global step 4412: loss = 1.9114 (0.759 sec/step)\n","INFO:tensorflow:global step 4413: loss = 1.6436 (0.760 sec/step)\n","I0908 16:24:30.478345 140650862335872 learning.py:512] global step 4413: loss = 1.6436 (0.760 sec/step)\n","INFO:tensorflow:global step 4414: loss = 2.3627 (0.738 sec/step)\n","I0908 16:24:31.217606 140650862335872 learning.py:512] global step 4414: loss = 2.3627 (0.738 sec/step)\n","INFO:tensorflow:global step 4415: loss = 1.9182 (0.747 sec/step)\n","I0908 16:24:31.966482 140650862335872 learning.py:512] global step 4415: loss = 1.9182 (0.747 sec/step)\n","INFO:tensorflow:global step 4416: loss = 1.6896 (0.741 sec/step)\n","I0908 16:24:32.709087 140650862335872 learning.py:512] global step 4416: loss = 1.6896 (0.741 sec/step)\n","INFO:tensorflow:global step 4417: loss = 2.3449 (0.751 sec/step)\n","I0908 16:24:33.461796 140650862335872 learning.py:512] global step 4417: loss = 2.3449 (0.751 sec/step)\n","INFO:tensorflow:global step 4418: loss = 2.1169 (0.742 sec/step)\n","I0908 16:24:34.205879 140650862335872 learning.py:512] global step 4418: loss = 2.1169 (0.742 sec/step)\n","INFO:tensorflow:global step 4419: loss = 2.1416 (0.730 sec/step)\n","I0908 16:24:34.937147 140650862335872 learning.py:512] global step 4419: loss = 2.1416 (0.730 sec/step)\n","INFO:tensorflow:global step 4420: loss = 1.7723 (0.747 sec/step)\n","I0908 16:24:35.685553 140650862335872 learning.py:512] global step 4420: loss = 1.7723 (0.747 sec/step)\n","INFO:tensorflow:global step 4421: loss = 1.9883 (0.763 sec/step)\n","I0908 16:24:36.450427 140650862335872 learning.py:512] global step 4421: loss = 1.9883 (0.763 sec/step)\n","INFO:tensorflow:global step 4422: loss = 1.9683 (0.763 sec/step)\n","I0908 16:24:37.215253 140650862335872 learning.py:512] global step 4422: loss = 1.9683 (0.763 sec/step)\n","INFO:tensorflow:global step 4423: loss = 1.8792 (0.761 sec/step)\n","I0908 16:24:37.977959 140650862335872 learning.py:512] global step 4423: loss = 1.8792 (0.761 sec/step)\n","INFO:tensorflow:global step 4424: loss = 2.7309 (0.758 sec/step)\n","I0908 16:24:38.737137 140650862335872 learning.py:512] global step 4424: loss = 2.7309 (0.758 sec/step)\n","INFO:tensorflow:global step 4425: loss = 1.9740 (0.733 sec/step)\n","I0908 16:24:39.471962 140650862335872 learning.py:512] global step 4425: loss = 1.9740 (0.733 sec/step)\n","INFO:tensorflow:global step 4426: loss = 1.7735 (0.743 sec/step)\n","I0908 16:24:40.216309 140650862335872 learning.py:512] global step 4426: loss = 1.7735 (0.743 sec/step)\n","INFO:tensorflow:global step 4427: loss = 2.0721 (0.755 sec/step)\n","I0908 16:24:40.973139 140650862335872 learning.py:512] global step 4427: loss = 2.0721 (0.755 sec/step)\n","INFO:tensorflow:global step 4428: loss = 2.1361 (0.751 sec/step)\n","I0908 16:24:41.725776 140650862335872 learning.py:512] global step 4428: loss = 2.1361 (0.751 sec/step)\n","INFO:tensorflow:global step 4429: loss = 2.4389 (0.759 sec/step)\n","I0908 16:24:42.485988 140650862335872 learning.py:512] global step 4429: loss = 2.4389 (0.759 sec/step)\n","INFO:tensorflow:global step 4430: loss = 2.1593 (0.760 sec/step)\n","I0908 16:24:43.247192 140650862335872 learning.py:512] global step 4430: loss = 2.1593 (0.760 sec/step)\n","INFO:tensorflow:global step 4431: loss = 1.9461 (0.758 sec/step)\n","I0908 16:24:44.007473 140650862335872 learning.py:512] global step 4431: loss = 1.9461 (0.758 sec/step)\n","INFO:tensorflow:global step 4432: loss = 1.9698 (0.753 sec/step)\n","I0908 16:24:44.762312 140650862335872 learning.py:512] global step 4432: loss = 1.9698 (0.753 sec/step)\n","INFO:tensorflow:global step 4433: loss = 1.6370 (0.730 sec/step)\n","I0908 16:24:45.494155 140650862335872 learning.py:512] global step 4433: loss = 1.6370 (0.730 sec/step)\n","INFO:tensorflow:global step 4434: loss = 2.1113 (0.742 sec/step)\n","I0908 16:24:46.237810 140650862335872 learning.py:512] global step 4434: loss = 2.1113 (0.742 sec/step)\n","INFO:tensorflow:global step 4435: loss = 2.2024 (0.743 sec/step)\n","I0908 16:24:46.981848 140650862335872 learning.py:512] global step 4435: loss = 2.2024 (0.743 sec/step)\n","INFO:tensorflow:global step 4436: loss = 1.7645 (0.756 sec/step)\n","I0908 16:24:47.740402 140650862335872 learning.py:512] global step 4436: loss = 1.7645 (0.756 sec/step)\n","INFO:tensorflow:global step 4437: loss = 2.2245 (0.751 sec/step)\n","I0908 16:24:48.493269 140650862335872 learning.py:512] global step 4437: loss = 2.2245 (0.751 sec/step)\n","INFO:tensorflow:global step 4438: loss = 2.0640 (0.766 sec/step)\n","I0908 16:24:49.261209 140650862335872 learning.py:512] global step 4438: loss = 2.0640 (0.766 sec/step)\n","INFO:tensorflow:global step 4439: loss = 1.7672 (0.766 sec/step)\n","I0908 16:24:50.028934 140650862335872 learning.py:512] global step 4439: loss = 1.7672 (0.766 sec/step)\n","INFO:tensorflow:global step 4440: loss = 2.0358 (0.758 sec/step)\n","I0908 16:24:50.788894 140650862335872 learning.py:512] global step 4440: loss = 2.0358 (0.758 sec/step)\n","INFO:tensorflow:global step 4441: loss = 2.4211 (0.770 sec/step)\n","I0908 16:24:51.560925 140650862335872 learning.py:512] global step 4441: loss = 2.4211 (0.770 sec/step)\n","INFO:tensorflow:global step 4442: loss = 1.9814 (0.760 sec/step)\n","I0908 16:24:52.322560 140650862335872 learning.py:512] global step 4442: loss = 1.9814 (0.760 sec/step)\n","INFO:tensorflow:global step 4443: loss = 2.1356 (0.773 sec/step)\n","I0908 16:24:53.097019 140650862335872 learning.py:512] global step 4443: loss = 2.1356 (0.773 sec/step)\n","INFO:tensorflow:global step 4444: loss = 2.5770 (0.755 sec/step)\n","I0908 16:24:53.853719 140650862335872 learning.py:512] global step 4444: loss = 2.5770 (0.755 sec/step)\n","INFO:tensorflow:global step 4445: loss = 2.0826 (0.769 sec/step)\n","I0908 16:24:54.624764 140650862335872 learning.py:512] global step 4445: loss = 2.0826 (0.769 sec/step)\n","INFO:tensorflow:global step 4446: loss = 1.5094 (0.750 sec/step)\n","I0908 16:24:55.376346 140650862335872 learning.py:512] global step 4446: loss = 1.5094 (0.750 sec/step)\n","INFO:tensorflow:global step 4447: loss = 2.2533 (0.738 sec/step)\n","I0908 16:24:56.116003 140650862335872 learning.py:512] global step 4447: loss = 2.2533 (0.738 sec/step)\n","INFO:tensorflow:global step 4448: loss = 1.8498 (0.756 sec/step)\n","I0908 16:24:56.873513 140650862335872 learning.py:512] global step 4448: loss = 1.8498 (0.756 sec/step)\n","INFO:tensorflow:global step 4449: loss = 1.9961 (0.747 sec/step)\n","I0908 16:24:57.622084 140650862335872 learning.py:512] global step 4449: loss = 1.9961 (0.747 sec/step)\n","INFO:tensorflow:global step 4450: loss = 2.0574 (0.782 sec/step)\n","I0908 16:24:58.405456 140650862335872 learning.py:512] global step 4450: loss = 2.0574 (0.782 sec/step)\n","INFO:tensorflow:global step 4451: loss = 1.8946 (0.744 sec/step)\n","I0908 16:24:59.150525 140650862335872 learning.py:512] global step 4451: loss = 1.8946 (0.744 sec/step)\n","INFO:tensorflow:global step 4452: loss = 1.8715 (0.768 sec/step)\n","I0908 16:24:59.920138 140650862335872 learning.py:512] global step 4452: loss = 1.8715 (0.768 sec/step)\n","INFO:tensorflow:global step 4453: loss = 2.3586 (0.748 sec/step)\n","I0908 16:25:00.669739 140650862335872 learning.py:512] global step 4453: loss = 2.3586 (0.748 sec/step)\n","INFO:tensorflow:global step 4454: loss = 2.5168 (0.761 sec/step)\n","I0908 16:25:01.432781 140650862335872 learning.py:512] global step 4454: loss = 2.5168 (0.761 sec/step)\n","INFO:tensorflow:global step 4455: loss = 2.1406 (0.763 sec/step)\n","I0908 16:25:02.197604 140650862335872 learning.py:512] global step 4455: loss = 2.1406 (0.763 sec/step)\n","INFO:tensorflow:global step 4456: loss = 1.8674 (0.760 sec/step)\n","I0908 16:25:02.959146 140650862335872 learning.py:512] global step 4456: loss = 1.8674 (0.760 sec/step)\n","INFO:tensorflow:global step 4457: loss = 1.9868 (0.767 sec/step)\n","I0908 16:25:03.727648 140650862335872 learning.py:512] global step 4457: loss = 1.9868 (0.767 sec/step)\n","INFO:tensorflow:global step 4458: loss = 1.8245 (0.744 sec/step)\n","I0908 16:25:04.472860 140650862335872 learning.py:512] global step 4458: loss = 1.8245 (0.744 sec/step)\n","INFO:tensorflow:global step 4459: loss = 1.8423 (0.744 sec/step)\n","I0908 16:25:05.218170 140650862335872 learning.py:512] global step 4459: loss = 1.8423 (0.744 sec/step)\n","INFO:tensorflow:global step 4460: loss = 1.8800 (0.740 sec/step)\n","I0908 16:25:05.959773 140650862335872 learning.py:512] global step 4460: loss = 1.8800 (0.740 sec/step)\n","INFO:tensorflow:global step 4461: loss = 1.9600 (0.759 sec/step)\n","I0908 16:25:06.720487 140650862335872 learning.py:512] global step 4461: loss = 1.9600 (0.759 sec/step)\n","INFO:tensorflow:global step 4462: loss = 1.6312 (0.728 sec/step)\n","I0908 16:25:07.449828 140650862335872 learning.py:512] global step 4462: loss = 1.6312 (0.728 sec/step)\n","INFO:tensorflow:global step 4463: loss = 2.3470 (0.759 sec/step)\n","I0908 16:25:08.210164 140650862335872 learning.py:512] global step 4463: loss = 2.3470 (0.759 sec/step)\n","INFO:tensorflow:global step 4464: loss = 2.1261 (0.737 sec/step)\n","I0908 16:25:08.948523 140650862335872 learning.py:512] global step 4464: loss = 2.1261 (0.737 sec/step)\n","INFO:tensorflow:global step 4465: loss = 2.0890 (0.762 sec/step)\n","I0908 16:25:09.712681 140650862335872 learning.py:512] global step 4465: loss = 2.0890 (0.762 sec/step)\n","INFO:tensorflow:global step 4466: loss = 1.9586 (0.758 sec/step)\n","I0908 16:25:10.472114 140650862335872 learning.py:512] global step 4466: loss = 1.9586 (0.758 sec/step)\n","INFO:tensorflow:global step 4467: loss = 1.7595 (0.748 sec/step)\n","I0908 16:25:11.221700 140650862335872 learning.py:512] global step 4467: loss = 1.7595 (0.748 sec/step)\n","INFO:tensorflow:global step 4468: loss = 2.0319 (0.754 sec/step)\n","I0908 16:25:11.977033 140650862335872 learning.py:512] global step 4468: loss = 2.0319 (0.754 sec/step)\n","INFO:tensorflow:global step 4469: loss = 2.0243 (0.771 sec/step)\n","I0908 16:25:12.750218 140650862335872 learning.py:512] global step 4469: loss = 2.0243 (0.771 sec/step)\n","INFO:tensorflow:global step 4470: loss = 2.4812 (0.738 sec/step)\n","I0908 16:25:13.489448 140650862335872 learning.py:512] global step 4470: loss = 2.4812 (0.738 sec/step)\n","INFO:tensorflow:global step 4471: loss = 2.2699 (0.750 sec/step)\n","I0908 16:25:14.241413 140650862335872 learning.py:512] global step 4471: loss = 2.2699 (0.750 sec/step)\n","INFO:tensorflow:global step 4472: loss = 2.2517 (0.762 sec/step)\n","I0908 16:25:15.005196 140650862335872 learning.py:512] global step 4472: loss = 2.2517 (0.762 sec/step)\n","INFO:tensorflow:global step 4473: loss = 1.7372 (0.760 sec/step)\n","I0908 16:25:15.767318 140650862335872 learning.py:512] global step 4473: loss = 1.7372 (0.760 sec/step)\n","INFO:tensorflow:global step 4474: loss = 1.8925 (0.755 sec/step)\n","I0908 16:25:16.523835 140650862335872 learning.py:512] global step 4474: loss = 1.8925 (0.755 sec/step)\n","INFO:tensorflow:global step 4475: loss = 2.6943 (0.749 sec/step)\n","I0908 16:25:17.274580 140650862335872 learning.py:512] global step 4475: loss = 2.6943 (0.749 sec/step)\n","INFO:tensorflow:global step 4476: loss = 2.0872 (0.760 sec/step)\n","I0908 16:25:18.036290 140650862335872 learning.py:512] global step 4476: loss = 2.0872 (0.760 sec/step)\n","INFO:tensorflow:global step 4477: loss = 1.5416 (0.736 sec/step)\n","I0908 16:25:18.774121 140650862335872 learning.py:512] global step 4477: loss = 1.5416 (0.736 sec/step)\n","INFO:tensorflow:global step 4478: loss = 1.6727 (0.758 sec/step)\n","I0908 16:25:19.533721 140650862335872 learning.py:512] global step 4478: loss = 1.6727 (0.758 sec/step)\n","INFO:tensorflow:global step 4479: loss = 1.6527 (0.758 sec/step)\n","I0908 16:25:20.293740 140650862335872 learning.py:512] global step 4479: loss = 1.6527 (0.758 sec/step)\n","INFO:tensorflow:global step 4480: loss = 1.9309 (0.744 sec/step)\n","I0908 16:25:21.039382 140650862335872 learning.py:512] global step 4480: loss = 1.9309 (0.744 sec/step)\n","INFO:tensorflow:global step 4481: loss = 2.0071 (0.758 sec/step)\n","I0908 16:25:21.799281 140650862335872 learning.py:512] global step 4481: loss = 2.0071 (0.758 sec/step)\n","INFO:tensorflow:global step 4482: loss = 1.8822 (0.746 sec/step)\n","I0908 16:25:22.547245 140650862335872 learning.py:512] global step 4482: loss = 1.8822 (0.746 sec/step)\n","INFO:tensorflow:global step 4483: loss = 2.2887 (0.762 sec/step)\n","I0908 16:25:23.311235 140650862335872 learning.py:512] global step 4483: loss = 2.2887 (0.762 sec/step)\n","INFO:tensorflow:global step 4484: loss = 2.1461 (0.752 sec/step)\n","I0908 16:25:24.064687 140650862335872 learning.py:512] global step 4484: loss = 2.1461 (0.752 sec/step)\n","INFO:tensorflow:global step 4485: loss = 1.6618 (0.761 sec/step)\n","I0908 16:25:24.827214 140650862335872 learning.py:512] global step 4485: loss = 1.6618 (0.761 sec/step)\n","INFO:tensorflow:global step 4486: loss = 1.6918 (0.772 sec/step)\n","I0908 16:25:25.601102 140650862335872 learning.py:512] global step 4486: loss = 1.6918 (0.772 sec/step)\n","INFO:tensorflow:global step 4487: loss = 1.8924 (0.781 sec/step)\n","I0908 16:25:26.383659 140650862335872 learning.py:512] global step 4487: loss = 1.8924 (0.781 sec/step)\n","INFO:tensorflow:global step 4488: loss = 2.3150 (0.741 sec/step)\n","I0908 16:25:27.126797 140650862335872 learning.py:512] global step 4488: loss = 2.3150 (0.741 sec/step)\n","INFO:tensorflow:global step 4489: loss = 2.1768 (0.768 sec/step)\n","I0908 16:25:27.896432 140650862335872 learning.py:512] global step 4489: loss = 2.1768 (0.768 sec/step)\n","INFO:tensorflow:global step 4490: loss = 2.0350 (0.770 sec/step)\n","I0908 16:25:28.668286 140650862335872 learning.py:512] global step 4490: loss = 2.0350 (0.770 sec/step)\n","INFO:tensorflow:global step 4491: loss = 1.9595 (0.762 sec/step)\n","I0908 16:25:29.432284 140650862335872 learning.py:512] global step 4491: loss = 1.9595 (0.762 sec/step)\n","INFO:tensorflow:global step 4492: loss = 2.0247 (0.736 sec/step)\n","I0908 16:25:30.170696 140650862335872 learning.py:512] global step 4492: loss = 2.0247 (0.736 sec/step)\n","INFO:tensorflow:global step 4493: loss = 1.7803 (0.775 sec/step)\n","I0908 16:25:30.948008 140650862335872 learning.py:512] global step 4493: loss = 1.7803 (0.775 sec/step)\n","INFO:tensorflow:global step 4494: loss = 2.1249 (0.771 sec/step)\n","I0908 16:25:31.721081 140650862335872 learning.py:512] global step 4494: loss = 2.1249 (0.771 sec/step)\n","INFO:tensorflow:global step 4495: loss = 1.7724 (0.766 sec/step)\n","I0908 16:25:32.489279 140650862335872 learning.py:512] global step 4495: loss = 1.7724 (0.766 sec/step)\n","INFO:tensorflow:global step 4496: loss = 1.9411 (0.734 sec/step)\n","I0908 16:25:33.225286 140650862335872 learning.py:512] global step 4496: loss = 1.9411 (0.734 sec/step)\n","INFO:tensorflow:global step 4497: loss = 1.9476 (0.741 sec/step)\n","I0908 16:25:33.968743 140650862335872 learning.py:512] global step 4497: loss = 1.9476 (0.741 sec/step)\n","INFO:tensorflow:global step 4498: loss = 2.4216 (0.764 sec/step)\n","I0908 16:25:34.734813 140650862335872 learning.py:512] global step 4498: loss = 2.4216 (0.764 sec/step)\n","INFO:tensorflow:global step 4499: loss = 1.9017 (0.747 sec/step)\n","I0908 16:25:35.484599 140650862335872 learning.py:512] global step 4499: loss = 1.9017 (0.747 sec/step)\n","INFO:tensorflow:global step 4500: loss = 2.2009 (0.776 sec/step)\n","I0908 16:25:36.262718 140650862335872 learning.py:512] global step 4500: loss = 2.2009 (0.776 sec/step)\n","INFO:tensorflow:global step 4501: loss = 2.1140 (0.765 sec/step)\n","I0908 16:25:37.030210 140650862335872 learning.py:512] global step 4501: loss = 2.1140 (0.765 sec/step)\n","INFO:tensorflow:global step 4502: loss = 2.2738 (0.754 sec/step)\n","I0908 16:25:37.786316 140650862335872 learning.py:512] global step 4502: loss = 2.2738 (0.754 sec/step)\n","INFO:tensorflow:global step 4503: loss = 2.1995 (0.740 sec/step)\n","I0908 16:25:38.528315 140650862335872 learning.py:512] global step 4503: loss = 2.1995 (0.740 sec/step)\n","INFO:tensorflow:global step 4504: loss = 2.0858 (0.751 sec/step)\n","I0908 16:25:39.281036 140650862335872 learning.py:512] global step 4504: loss = 2.0858 (0.751 sec/step)\n","INFO:tensorflow:global step 4505: loss = 1.7924 (0.767 sec/step)\n","I0908 16:25:40.049353 140650862335872 learning.py:512] global step 4505: loss = 1.7924 (0.767 sec/step)\n","INFO:tensorflow:global step 4506: loss = 1.7574 (0.760 sec/step)\n","I0908 16:25:40.810867 140650862335872 learning.py:512] global step 4506: loss = 1.7574 (0.760 sec/step)\n","INFO:tensorflow:global step 4507: loss = 1.9781 (0.759 sec/step)\n","I0908 16:25:41.571678 140650862335872 learning.py:512] global step 4507: loss = 1.9781 (0.759 sec/step)\n","INFO:tensorflow:global step 4508: loss = 2.1216 (0.754 sec/step)\n","I0908 16:25:42.326952 140650862335872 learning.py:512] global step 4508: loss = 2.1216 (0.754 sec/step)\n","INFO:tensorflow:global step 4509: loss = 2.6043 (0.768 sec/step)\n","I0908 16:25:43.096768 140650862335872 learning.py:512] global step 4509: loss = 2.6043 (0.768 sec/step)\n","INFO:tensorflow:global step 4510: loss = 2.0186 (0.728 sec/step)\n","I0908 16:25:43.826809 140650862335872 learning.py:512] global step 4510: loss = 2.0186 (0.728 sec/step)\n","INFO:tensorflow:global step 4511: loss = 2.2411 (0.742 sec/step)\n","I0908 16:25:44.570492 140650862335872 learning.py:512] global step 4511: loss = 2.2411 (0.742 sec/step)\n","INFO:tensorflow:global step 4512: loss = 2.1586 (0.747 sec/step)\n","I0908 16:25:45.319098 140650862335872 learning.py:512] global step 4512: loss = 2.1586 (0.747 sec/step)\n","INFO:tensorflow:global step 4513: loss = 1.8353 (0.772 sec/step)\n","I0908 16:25:46.093293 140650862335872 learning.py:512] global step 4513: loss = 1.8353 (0.772 sec/step)\n","INFO:tensorflow:global step 4514: loss = 1.6701 (0.848 sec/step)\n","I0908 16:25:46.943069 140650862335872 learning.py:512] global step 4514: loss = 1.6701 (0.848 sec/step)\n","INFO:tensorflow:Recording summary at step 4514.\n","I0908 16:25:47.925979 140646941251328 supervisor.py:1050] Recording summary at step 4514.\n","INFO:tensorflow:global step 4515: loss = 1.7119 (1.193 sec/step)\n","I0908 16:25:48.142270 140650862335872 learning.py:512] global step 4515: loss = 1.7119 (1.193 sec/step)\n","INFO:tensorflow:global step 4516: loss = 1.6944 (0.759 sec/step)\n","I0908 16:25:48.903270 140650862335872 learning.py:512] global step 4516: loss = 1.6944 (0.759 sec/step)\n","INFO:tensorflow:global step 4517: loss = 2.3271 (0.766 sec/step)\n","I0908 16:25:49.671135 140650862335872 learning.py:512] global step 4517: loss = 2.3271 (0.766 sec/step)\n","INFO:tensorflow:global step 4518: loss = 1.9836 (0.771 sec/step)\n","I0908 16:25:50.443574 140650862335872 learning.py:512] global step 4518: loss = 1.9836 (0.771 sec/step)\n","INFO:tensorflow:global step 4519: loss = 1.8741 (0.757 sec/step)\n","I0908 16:25:51.202357 140650862335872 learning.py:512] global step 4519: loss = 1.8741 (0.757 sec/step)\n","INFO:tensorflow:global step 4520: loss = 2.3731 (0.750 sec/step)\n","I0908 16:25:51.954224 140650862335872 learning.py:512] global step 4520: loss = 2.3731 (0.750 sec/step)\n","INFO:tensorflow:global step 4521: loss = 2.0966 (0.755 sec/step)\n","I0908 16:25:52.710469 140650862335872 learning.py:512] global step 4521: loss = 2.0966 (0.755 sec/step)\n","INFO:tensorflow:global step 4522: loss = 2.2151 (0.771 sec/step)\n","I0908 16:25:53.482721 140650862335872 learning.py:512] global step 4522: loss = 2.2151 (0.771 sec/step)\n","INFO:tensorflow:global step 4523: loss = 2.3300 (0.741 sec/step)\n","I0908 16:25:54.225766 140650862335872 learning.py:512] global step 4523: loss = 2.3300 (0.741 sec/step)\n","INFO:tensorflow:global step 4524: loss = 1.9921 (0.748 sec/step)\n","I0908 16:25:54.974834 140650862335872 learning.py:512] global step 4524: loss = 1.9921 (0.748 sec/step)\n","INFO:tensorflow:global step 4525: loss = 2.2632 (0.765 sec/step)\n","I0908 16:25:55.741243 140650862335872 learning.py:512] global step 4525: loss = 2.2632 (0.765 sec/step)\n","INFO:tensorflow:global step 4526: loss = 1.9006 (0.770 sec/step)\n","I0908 16:25:56.513358 140650862335872 learning.py:512] global step 4526: loss = 1.9006 (0.770 sec/step)\n","INFO:tensorflow:global step 4527: loss = 1.8915 (0.755 sec/step)\n","I0908 16:25:57.270151 140650862335872 learning.py:512] global step 4527: loss = 1.8915 (0.755 sec/step)\n","INFO:tensorflow:global step 4528: loss = 1.9594 (0.747 sec/step)\n","I0908 16:25:58.018580 140650862335872 learning.py:512] global step 4528: loss = 1.9594 (0.747 sec/step)\n","INFO:tensorflow:global step 4529: loss = 1.8211 (0.786 sec/step)\n","I0908 16:25:58.806245 140650862335872 learning.py:512] global step 4529: loss = 1.8211 (0.786 sec/step)\n","INFO:tensorflow:global step 4530: loss = 1.8623 (0.779 sec/step)\n","I0908 16:25:59.587597 140650862335872 learning.py:512] global step 4530: loss = 1.8623 (0.779 sec/step)\n","INFO:tensorflow:global step 4531: loss = 1.7117 (0.779 sec/step)\n","I0908 16:26:00.368078 140650862335872 learning.py:512] global step 4531: loss = 1.7117 (0.779 sec/step)\n","INFO:tensorflow:global step 4532: loss = 1.8507 (0.749 sec/step)\n","I0908 16:26:01.118392 140650862335872 learning.py:512] global step 4532: loss = 1.8507 (0.749 sec/step)\n","INFO:tensorflow:global step 4533: loss = 1.7969 (0.748 sec/step)\n","I0908 16:26:01.867875 140650862335872 learning.py:512] global step 4533: loss = 1.7969 (0.748 sec/step)\n","INFO:tensorflow:global step 4534: loss = 2.1077 (0.762 sec/step)\n","I0908 16:26:02.631316 140650862335872 learning.py:512] global step 4534: loss = 2.1077 (0.762 sec/step)\n","INFO:tensorflow:global step 4535: loss = 2.2498 (0.755 sec/step)\n","I0908 16:26:03.388486 140650862335872 learning.py:512] global step 4535: loss = 2.2498 (0.755 sec/step)\n","INFO:tensorflow:global step 4536: loss = 2.2730 (0.744 sec/step)\n","I0908 16:26:04.133817 140650862335872 learning.py:512] global step 4536: loss = 2.2730 (0.744 sec/step)\n","INFO:tensorflow:global step 4537: loss = 2.1672 (0.754 sec/step)\n","I0908 16:26:04.889250 140650862335872 learning.py:512] global step 4537: loss = 2.1672 (0.754 sec/step)\n","INFO:tensorflow:global step 4538: loss = 2.0202 (0.735 sec/step)\n","I0908 16:26:05.625602 140650862335872 learning.py:512] global step 4538: loss = 2.0202 (0.735 sec/step)\n","INFO:tensorflow:global step 4539: loss = 2.6722 (0.756 sec/step)\n","I0908 16:26:06.383154 140650862335872 learning.py:512] global step 4539: loss = 2.6722 (0.756 sec/step)\n","INFO:tensorflow:global step 4540: loss = 2.0986 (0.740 sec/step)\n","I0908 16:26:07.125340 140650862335872 learning.py:512] global step 4540: loss = 2.0986 (0.740 sec/step)\n","INFO:tensorflow:global step 4541: loss = 1.9058 (0.750 sec/step)\n","I0908 16:26:07.877435 140650862335872 learning.py:512] global step 4541: loss = 1.9058 (0.750 sec/step)\n","INFO:tensorflow:global step 4542: loss = 1.9880 (0.763 sec/step)\n","I0908 16:26:08.642141 140650862335872 learning.py:512] global step 4542: loss = 1.9880 (0.763 sec/step)\n","INFO:tensorflow:global step 4543: loss = 2.2089 (0.747 sec/step)\n","I0908 16:26:09.391065 140650862335872 learning.py:512] global step 4543: loss = 2.2089 (0.747 sec/step)\n","INFO:tensorflow:global step 4544: loss = 2.5745 (0.767 sec/step)\n","I0908 16:26:10.160362 140650862335872 learning.py:512] global step 4544: loss = 2.5745 (0.767 sec/step)\n","INFO:tensorflow:global step 4545: loss = 1.8371 (0.748 sec/step)\n","I0908 16:26:10.910049 140650862335872 learning.py:512] global step 4545: loss = 1.8371 (0.748 sec/step)\n","INFO:tensorflow:global step 4546: loss = 2.1963 (0.760 sec/step)\n","I0908 16:26:11.671283 140650862335872 learning.py:512] global step 4546: loss = 2.1963 (0.760 sec/step)\n","INFO:tensorflow:global step 4547: loss = 2.1585 (0.751 sec/step)\n","I0908 16:26:12.424062 140650862335872 learning.py:512] global step 4547: loss = 2.1585 (0.751 sec/step)\n","INFO:tensorflow:global step 4548: loss = 2.0968 (0.760 sec/step)\n","I0908 16:26:13.186130 140650862335872 learning.py:512] global step 4548: loss = 2.0968 (0.760 sec/step)\n","INFO:tensorflow:global step 4549: loss = 2.3264 (0.759 sec/step)\n","I0908 16:26:13.946850 140650862335872 learning.py:512] global step 4549: loss = 2.3264 (0.759 sec/step)\n","INFO:tensorflow:global step 4550: loss = 2.4652 (0.746 sec/step)\n","I0908 16:26:14.694091 140650862335872 learning.py:512] global step 4550: loss = 2.4652 (0.746 sec/step)\n","INFO:tensorflow:global step 4551: loss = 2.2292 (0.764 sec/step)\n","I0908 16:26:15.460388 140650862335872 learning.py:512] global step 4551: loss = 2.2292 (0.764 sec/step)\n","INFO:tensorflow:global step 4552: loss = 2.0518 (0.760 sec/step)\n","I0908 16:26:16.221475 140650862335872 learning.py:512] global step 4552: loss = 2.0518 (0.760 sec/step)\n","INFO:tensorflow:global step 4553: loss = 1.8849 (0.767 sec/step)\n","I0908 16:26:16.990350 140650862335872 learning.py:512] global step 4553: loss = 1.8849 (0.767 sec/step)\n","INFO:tensorflow:global step 4554: loss = 2.5976 (0.765 sec/step)\n","I0908 16:26:17.757038 140650862335872 learning.py:512] global step 4554: loss = 2.5976 (0.765 sec/step)\n","INFO:tensorflow:global step 4555: loss = 1.6677 (0.771 sec/step)\n","I0908 16:26:18.529418 140650862335872 learning.py:512] global step 4555: loss = 1.6677 (0.771 sec/step)\n","INFO:tensorflow:global step 4556: loss = 1.9841 (0.756 sec/step)\n","I0908 16:26:19.287162 140650862335872 learning.py:512] global step 4556: loss = 1.9841 (0.756 sec/step)\n","INFO:tensorflow:global step 4557: loss = 1.7000 (0.749 sec/step)\n","I0908 16:26:20.038439 140650862335872 learning.py:512] global step 4557: loss = 1.7000 (0.749 sec/step)\n","INFO:tensorflow:global step 4558: loss = 2.5092 (0.748 sec/step)\n","I0908 16:26:20.787845 140650862335872 learning.py:512] global step 4558: loss = 2.5092 (0.748 sec/step)\n","INFO:tensorflow:global step 4559: loss = 2.1046 (0.776 sec/step)\n","I0908 16:26:21.565733 140650862335872 learning.py:512] global step 4559: loss = 2.1046 (0.776 sec/step)\n","INFO:tensorflow:global step 4560: loss = 1.6489 (0.778 sec/step)\n","I0908 16:26:22.345716 140650862335872 learning.py:512] global step 4560: loss = 1.6489 (0.778 sec/step)\n","INFO:tensorflow:global step 4561: loss = 1.8995 (0.749 sec/step)\n","I0908 16:26:23.096701 140650862335872 learning.py:512] global step 4561: loss = 1.8995 (0.749 sec/step)\n","INFO:tensorflow:global step 4562: loss = 1.9201 (0.755 sec/step)\n","I0908 16:26:23.853804 140650862335872 learning.py:512] global step 4562: loss = 1.9201 (0.755 sec/step)\n","INFO:tensorflow:global step 4563: loss = 2.2059 (0.754 sec/step)\n","I0908 16:26:24.609524 140650862335872 learning.py:512] global step 4563: loss = 2.2059 (0.754 sec/step)\n","INFO:tensorflow:global step 4564: loss = 1.8986 (0.736 sec/step)\n","I0908 16:26:25.347123 140650862335872 learning.py:512] global step 4564: loss = 1.8986 (0.736 sec/step)\n","INFO:tensorflow:global step 4565: loss = 2.0441 (0.737 sec/step)\n","I0908 16:26:26.086207 140650862335872 learning.py:512] global step 4565: loss = 2.0441 (0.737 sec/step)\n","INFO:tensorflow:global step 4566: loss = 1.9141 (0.763 sec/step)\n","I0908 16:26:26.851252 140650862335872 learning.py:512] global step 4566: loss = 1.9141 (0.763 sec/step)\n","INFO:tensorflow:global step 4567: loss = 2.1035 (0.776 sec/step)\n","I0908 16:26:27.628792 140650862335872 learning.py:512] global step 4567: loss = 2.1035 (0.776 sec/step)\n","INFO:tensorflow:global step 4568: loss = 1.8456 (0.762 sec/step)\n","I0908 16:26:28.392504 140650862335872 learning.py:512] global step 4568: loss = 1.8456 (0.762 sec/step)\n","INFO:tensorflow:global step 4569: loss = 2.3921 (0.746 sec/step)\n","I0908 16:26:29.140239 140650862335872 learning.py:512] global step 4569: loss = 2.3921 (0.746 sec/step)\n","INFO:tensorflow:global step 4570: loss = 1.8909 (0.760 sec/step)\n","I0908 16:26:29.902542 140650862335872 learning.py:512] global step 4570: loss = 1.8909 (0.760 sec/step)\n","INFO:tensorflow:global step 4571: loss = 2.0923 (0.752 sec/step)\n","I0908 16:26:30.656250 140650862335872 learning.py:512] global step 4571: loss = 2.0923 (0.752 sec/step)\n","INFO:tensorflow:global step 4572: loss = 1.8413 (0.776 sec/step)\n","I0908 16:26:31.433884 140650862335872 learning.py:512] global step 4572: loss = 1.8413 (0.776 sec/step)\n","INFO:tensorflow:global step 4573: loss = 2.0948 (0.801 sec/step)\n","I0908 16:26:32.236983 140650862335872 learning.py:512] global step 4573: loss = 2.0948 (0.801 sec/step)\n","INFO:tensorflow:global step 4574: loss = 2.0400 (0.775 sec/step)\n","I0908 16:26:33.013991 140650862335872 learning.py:512] global step 4574: loss = 2.0400 (0.775 sec/step)\n","INFO:tensorflow:global step 4575: loss = 2.3859 (0.761 sec/step)\n","I0908 16:26:33.776927 140650862335872 learning.py:512] global step 4575: loss = 2.3859 (0.761 sec/step)\n","INFO:tensorflow:global step 4576: loss = 1.9987 (0.745 sec/step)\n","I0908 16:26:34.523219 140650862335872 learning.py:512] global step 4576: loss = 1.9987 (0.745 sec/step)\n","INFO:tensorflow:global step 4577: loss = 1.9356 (0.754 sec/step)\n","I0908 16:26:35.278657 140650862335872 learning.py:512] global step 4577: loss = 1.9356 (0.754 sec/step)\n","INFO:tensorflow:global step 4578: loss = 2.0751 (0.750 sec/step)\n","I0908 16:26:36.030591 140650862335872 learning.py:512] global step 4578: loss = 2.0751 (0.750 sec/step)\n","INFO:tensorflow:global step 4579: loss = 2.3454 (0.767 sec/step)\n","I0908 16:26:36.799419 140650862335872 learning.py:512] global step 4579: loss = 2.3454 (0.767 sec/step)\n","INFO:tensorflow:global step 4580: loss = 1.9631 (0.755 sec/step)\n","I0908 16:26:37.556519 140650862335872 learning.py:512] global step 4580: loss = 1.9631 (0.755 sec/step)\n","INFO:tensorflow:global step 4581: loss = 1.8045 (0.759 sec/step)\n","I0908 16:26:38.316906 140650862335872 learning.py:512] global step 4581: loss = 1.8045 (0.759 sec/step)\n","INFO:tensorflow:global step 4582: loss = 2.1541 (0.773 sec/step)\n","I0908 16:26:39.091968 140650862335872 learning.py:512] global step 4582: loss = 2.1541 (0.773 sec/step)\n","INFO:tensorflow:global step 4583: loss = 1.6430 (0.749 sec/step)\n","I0908 16:26:39.842225 140650862335872 learning.py:512] global step 4583: loss = 1.6430 (0.749 sec/step)\n","INFO:tensorflow:global step 4584: loss = 1.8244 (0.736 sec/step)\n","I0908 16:26:40.579669 140650862335872 learning.py:512] global step 4584: loss = 1.8244 (0.736 sec/step)\n","INFO:tensorflow:global step 4585: loss = 1.8297 (0.753 sec/step)\n","I0908 16:26:41.334830 140650862335872 learning.py:512] global step 4585: loss = 1.8297 (0.753 sec/step)\n","INFO:tensorflow:global step 4586: loss = 2.0634 (0.748 sec/step)\n","I0908 16:26:42.084451 140650862335872 learning.py:512] global step 4586: loss = 2.0634 (0.748 sec/step)\n","INFO:tensorflow:global step 4587: loss = 2.2290 (0.747 sec/step)\n","I0908 16:26:42.833274 140650862335872 learning.py:512] global step 4587: loss = 2.2290 (0.747 sec/step)\n","INFO:tensorflow:global step 4588: loss = 1.8074 (0.732 sec/step)\n","I0908 16:26:43.567283 140650862335872 learning.py:512] global step 4588: loss = 1.8074 (0.732 sec/step)\n","INFO:tensorflow:global step 4589: loss = 2.1046 (0.743 sec/step)\n","I0908 16:26:44.312124 140650862335872 learning.py:512] global step 4589: loss = 2.1046 (0.743 sec/step)\n","INFO:tensorflow:global step 4590: loss = 1.9353 (0.753 sec/step)\n","I0908 16:26:45.066877 140650862335872 learning.py:512] global step 4590: loss = 1.9353 (0.753 sec/step)\n","INFO:tensorflow:global step 4591: loss = 2.0385 (0.744 sec/step)\n","I0908 16:26:45.812284 140650862335872 learning.py:512] global step 4591: loss = 2.0385 (0.744 sec/step)\n","INFO:tensorflow:global step 4592: loss = 2.0787 (0.756 sec/step)\n","I0908 16:26:46.569617 140650862335872 learning.py:512] global step 4592: loss = 2.0787 (0.756 sec/step)\n","INFO:tensorflow:global step 4593: loss = 1.8216 (0.766 sec/step)\n","I0908 16:26:47.336767 140650862335872 learning.py:512] global step 4593: loss = 1.8216 (0.766 sec/step)\n","INFO:tensorflow:global step 4594: loss = 2.0409 (0.760 sec/step)\n","I0908 16:26:48.099391 140650862335872 learning.py:512] global step 4594: loss = 2.0409 (0.760 sec/step)\n","INFO:tensorflow:global step 4595: loss = 1.8962 (0.755 sec/step)\n","I0908 16:26:48.856132 140650862335872 learning.py:512] global step 4595: loss = 1.8962 (0.755 sec/step)\n","INFO:tensorflow:global step 4596: loss = 1.8276 (0.737 sec/step)\n","I0908 16:26:49.594600 140650862335872 learning.py:512] global step 4596: loss = 1.8276 (0.737 sec/step)\n","INFO:tensorflow:global step 4597: loss = 2.1383 (0.742 sec/step)\n","I0908 16:26:50.338409 140650862335872 learning.py:512] global step 4597: loss = 2.1383 (0.742 sec/step)\n","INFO:tensorflow:global step 4598: loss = 1.8803 (0.747 sec/step)\n","I0908 16:26:51.087491 140650862335872 learning.py:512] global step 4598: loss = 1.8803 (0.747 sec/step)\n","INFO:tensorflow:global step 4599: loss = 2.0685 (0.756 sec/step)\n","I0908 16:26:51.845045 140650862335872 learning.py:512] global step 4599: loss = 2.0685 (0.756 sec/step)\n","INFO:tensorflow:global step 4600: loss = 2.0734 (0.750 sec/step)\n","I0908 16:26:52.596503 140650862335872 learning.py:512] global step 4600: loss = 2.0734 (0.750 sec/step)\n","INFO:tensorflow:global step 4601: loss = 2.5858 (0.745 sec/step)\n","I0908 16:26:53.342789 140650862335872 learning.py:512] global step 4601: loss = 2.5858 (0.745 sec/step)\n","INFO:tensorflow:global step 4602: loss = 2.1746 (0.734 sec/step)\n","I0908 16:26:54.078214 140650862335872 learning.py:512] global step 4602: loss = 2.1746 (0.734 sec/step)\n","INFO:tensorflow:global step 4603: loss = 1.7615 (0.771 sec/step)\n","I0908 16:26:54.851133 140650862335872 learning.py:512] global step 4603: loss = 1.7615 (0.771 sec/step)\n","INFO:tensorflow:global step 4604: loss = 1.6090 (0.749 sec/step)\n","I0908 16:26:55.601964 140650862335872 learning.py:512] global step 4604: loss = 1.6090 (0.749 sec/step)\n","INFO:tensorflow:global step 4605: loss = 2.0852 (0.735 sec/step)\n","I0908 16:26:56.338483 140650862335872 learning.py:512] global step 4605: loss = 2.0852 (0.735 sec/step)\n","INFO:tensorflow:global step 4606: loss = 2.2228 (0.759 sec/step)\n","I0908 16:26:57.099099 140650862335872 learning.py:512] global step 4606: loss = 2.2228 (0.759 sec/step)\n","INFO:tensorflow:global step 4607: loss = 2.4678 (0.750 sec/step)\n","I0908 16:26:57.850423 140650862335872 learning.py:512] global step 4607: loss = 2.4678 (0.750 sec/step)\n","INFO:tensorflow:global step 4608: loss = 2.1817 (0.750 sec/step)\n","I0908 16:26:58.601860 140650862335872 learning.py:512] global step 4608: loss = 2.1817 (0.750 sec/step)\n","INFO:tensorflow:global step 4609: loss = 1.8338 (0.760 sec/step)\n","I0908 16:26:59.363423 140650862335872 learning.py:512] global step 4609: loss = 1.8338 (0.760 sec/step)\n","INFO:tensorflow:global step 4610: loss = 1.9063 (0.765 sec/step)\n","I0908 16:27:00.130203 140650862335872 learning.py:512] global step 4610: loss = 1.9063 (0.765 sec/step)\n","INFO:tensorflow:global step 4611: loss = 2.5453 (0.752 sec/step)\n","I0908 16:27:00.883503 140650862335872 learning.py:512] global step 4611: loss = 2.5453 (0.752 sec/step)\n","INFO:tensorflow:global step 4612: loss = 2.0819 (0.781 sec/step)\n","I0908 16:27:01.665710 140650862335872 learning.py:512] global step 4612: loss = 2.0819 (0.781 sec/step)\n","INFO:tensorflow:global step 4613: loss = 2.2561 (0.772 sec/step)\n","I0908 16:27:02.440006 140650862335872 learning.py:512] global step 4613: loss = 2.2561 (0.772 sec/step)\n","INFO:tensorflow:global step 4614: loss = 2.0773 (0.769 sec/step)\n","I0908 16:27:03.210918 140650862335872 learning.py:512] global step 4614: loss = 2.0773 (0.769 sec/step)\n","INFO:tensorflow:global step 4615: loss = 1.8036 (0.751 sec/step)\n","I0908 16:27:03.963393 140650862335872 learning.py:512] global step 4615: loss = 1.8036 (0.751 sec/step)\n","INFO:tensorflow:global step 4616: loss = 1.9280 (0.752 sec/step)\n","I0908 16:27:04.717502 140650862335872 learning.py:512] global step 4616: loss = 1.9280 (0.752 sec/step)\n","INFO:tensorflow:global step 4617: loss = 2.3657 (0.748 sec/step)\n","I0908 16:27:05.466884 140650862335872 learning.py:512] global step 4617: loss = 2.3657 (0.748 sec/step)\n","INFO:tensorflow:global step 4618: loss = 2.1041 (0.756 sec/step)\n","I0908 16:27:06.224224 140650862335872 learning.py:512] global step 4618: loss = 2.1041 (0.756 sec/step)\n","INFO:tensorflow:global step 4619: loss = 1.8912 (0.739 sec/step)\n","I0908 16:27:06.965837 140650862335872 learning.py:512] global step 4619: loss = 1.8912 (0.739 sec/step)\n","INFO:tensorflow:global step 4620: loss = 1.9129 (0.741 sec/step)\n","I0908 16:27:07.711230 140650862335872 learning.py:512] global step 4620: loss = 1.9129 (0.741 sec/step)\n","INFO:tensorflow:global step 4621: loss = 2.0894 (0.769 sec/step)\n","I0908 16:27:08.481701 140650862335872 learning.py:512] global step 4621: loss = 2.0894 (0.769 sec/step)\n","INFO:tensorflow:global step 4622: loss = 1.7367 (0.768 sec/step)\n","I0908 16:27:09.251098 140650862335872 learning.py:512] global step 4622: loss = 1.7367 (0.768 sec/step)\n","INFO:tensorflow:global step 4623: loss = 2.0523 (0.754 sec/step)\n","I0908 16:27:10.007142 140650862335872 learning.py:512] global step 4623: loss = 2.0523 (0.754 sec/step)\n","INFO:tensorflow:global step 4624: loss = 1.9015 (0.751 sec/step)\n","I0908 16:27:10.759561 140650862335872 learning.py:512] global step 4624: loss = 1.9015 (0.751 sec/step)\n","INFO:tensorflow:global step 4625: loss = 2.5214 (0.752 sec/step)\n","I0908 16:27:11.513642 140650862335872 learning.py:512] global step 4625: loss = 2.5214 (0.752 sec/step)\n","INFO:tensorflow:global step 4626: loss = 1.9395 (0.758 sec/step)\n","I0908 16:27:12.273135 140650862335872 learning.py:512] global step 4626: loss = 1.9395 (0.758 sec/step)\n","INFO:tensorflow:global step 4627: loss = 1.8841 (0.754 sec/step)\n","I0908 16:27:13.029195 140650862335872 learning.py:512] global step 4627: loss = 1.8841 (0.754 sec/step)\n","INFO:tensorflow:global step 4628: loss = 1.9068 (0.750 sec/step)\n","I0908 16:27:13.780330 140650862335872 learning.py:512] global step 4628: loss = 1.9068 (0.750 sec/step)\n","INFO:tensorflow:global step 4629: loss = 1.8222 (0.769 sec/step)\n","I0908 16:27:14.550879 140650862335872 learning.py:512] global step 4629: loss = 1.8222 (0.769 sec/step)\n","INFO:tensorflow:global step 4630: loss = 2.0378 (0.754 sec/step)\n","I0908 16:27:15.306314 140650862335872 learning.py:512] global step 4630: loss = 2.0378 (0.754 sec/step)\n","INFO:tensorflow:global step 4631: loss = 2.3004 (0.753 sec/step)\n","I0908 16:27:16.061059 140650862335872 learning.py:512] global step 4631: loss = 2.3004 (0.753 sec/step)\n","INFO:tensorflow:global step 4632: loss = 1.9492 (0.753 sec/step)\n","I0908 16:27:16.816270 140650862335872 learning.py:512] global step 4632: loss = 1.9492 (0.753 sec/step)\n","INFO:tensorflow:global step 4633: loss = 2.1102 (0.751 sec/step)\n","I0908 16:27:17.568794 140650862335872 learning.py:512] global step 4633: loss = 2.1102 (0.751 sec/step)\n","INFO:tensorflow:global step 4634: loss = 2.0962 (0.746 sec/step)\n","I0908 16:27:18.316041 140650862335872 learning.py:512] global step 4634: loss = 2.0962 (0.746 sec/step)\n","INFO:tensorflow:global step 4635: loss = 2.0621 (0.748 sec/step)\n","I0908 16:27:19.065316 140650862335872 learning.py:512] global step 4635: loss = 2.0621 (0.748 sec/step)\n","INFO:tensorflow:global step 4636: loss = 1.9559 (0.772 sec/step)\n","I0908 16:27:19.838981 140650862335872 learning.py:512] global step 4636: loss = 1.9559 (0.772 sec/step)\n","INFO:tensorflow:global step 4637: loss = 1.6987 (0.757 sec/step)\n","I0908 16:27:20.597602 140650862335872 learning.py:512] global step 4637: loss = 1.6987 (0.757 sec/step)\n","INFO:tensorflow:global step 4638: loss = 1.7640 (0.743 sec/step)\n","I0908 16:27:21.342580 140650862335872 learning.py:512] global step 4638: loss = 1.7640 (0.743 sec/step)\n","INFO:tensorflow:global step 4639: loss = 2.4662 (0.746 sec/step)\n","I0908 16:27:22.090291 140650862335872 learning.py:512] global step 4639: loss = 2.4662 (0.746 sec/step)\n","INFO:tensorflow:global step 4640: loss = 2.0170 (0.767 sec/step)\n","I0908 16:27:22.859028 140650862335872 learning.py:512] global step 4640: loss = 2.0170 (0.767 sec/step)\n","INFO:tensorflow:global step 4641: loss = 2.1662 (0.764 sec/step)\n","I0908 16:27:23.625418 140650862335872 learning.py:512] global step 4641: loss = 2.1662 (0.764 sec/step)\n","INFO:tensorflow:global step 4642: loss = 1.9940 (0.752 sec/step)\n","I0908 16:27:24.380484 140650862335872 learning.py:512] global step 4642: loss = 1.9940 (0.752 sec/step)\n","INFO:tensorflow:global step 4643: loss = 1.8692 (0.756 sec/step)\n","I0908 16:27:25.138670 140650862335872 learning.py:512] global step 4643: loss = 1.8692 (0.756 sec/step)\n","INFO:tensorflow:global step 4644: loss = 2.6168 (0.766 sec/step)\n","I0908 16:27:25.906134 140650862335872 learning.py:512] global step 4644: loss = 2.6168 (0.766 sec/step)\n","INFO:tensorflow:global step 4645: loss = 2.2373 (0.757 sec/step)\n","I0908 16:27:26.665329 140650862335872 learning.py:512] global step 4645: loss = 2.2373 (0.757 sec/step)\n","INFO:tensorflow:global step 4646: loss = 2.5644 (0.766 sec/step)\n","I0908 16:27:27.432682 140650862335872 learning.py:512] global step 4646: loss = 2.5644 (0.766 sec/step)\n","INFO:tensorflow:global step 4647: loss = 2.5078 (0.735 sec/step)\n","I0908 16:27:28.168859 140650862335872 learning.py:512] global step 4647: loss = 2.5078 (0.735 sec/step)\n","INFO:tensorflow:global step 4648: loss = 1.8279 (0.760 sec/step)\n","I0908 16:27:28.930468 140650862335872 learning.py:512] global step 4648: loss = 1.8279 (0.760 sec/step)\n","INFO:tensorflow:global step 4649: loss = 2.0158 (0.757 sec/step)\n","I0908 16:27:29.689652 140650862335872 learning.py:512] global step 4649: loss = 2.0158 (0.757 sec/step)\n","INFO:tensorflow:global step 4650: loss = 2.0114 (0.771 sec/step)\n","I0908 16:27:30.462106 140650862335872 learning.py:512] global step 4650: loss = 2.0114 (0.771 sec/step)\n","INFO:tensorflow:global step 4651: loss = 2.0013 (0.763 sec/step)\n","I0908 16:27:31.226952 140650862335872 learning.py:512] global step 4651: loss = 2.0013 (0.763 sec/step)\n","INFO:tensorflow:global step 4652: loss = 2.0504 (0.778 sec/step)\n","I0908 16:27:32.007008 140650862335872 learning.py:512] global step 4652: loss = 2.0504 (0.778 sec/step)\n","INFO:tensorflow:global step 4653: loss = 2.3895 (0.763 sec/step)\n","I0908 16:27:32.771451 140650862335872 learning.py:512] global step 4653: loss = 2.3895 (0.763 sec/step)\n","INFO:tensorflow:global step 4654: loss = 2.1851 (0.761 sec/step)\n","I0908 16:27:33.534056 140650862335872 learning.py:512] global step 4654: loss = 2.1851 (0.761 sec/step)\n","INFO:tensorflow:global step 4655: loss = 1.7725 (0.764 sec/step)\n","I0908 16:27:34.299333 140650862335872 learning.py:512] global step 4655: loss = 1.7725 (0.764 sec/step)\n","INFO:tensorflow:global step 4656: loss = 1.8641 (0.775 sec/step)\n","I0908 16:27:35.075539 140650862335872 learning.py:512] global step 4656: loss = 1.8641 (0.775 sec/step)\n","INFO:tensorflow:global step 4657: loss = 2.1700 (0.761 sec/step)\n","I0908 16:27:35.837680 140650862335872 learning.py:512] global step 4657: loss = 2.1700 (0.761 sec/step)\n","INFO:tensorflow:global step 4658: loss = 2.5764 (0.756 sec/step)\n","I0908 16:27:36.595273 140650862335872 learning.py:512] global step 4658: loss = 2.5764 (0.756 sec/step)\n","INFO:tensorflow:global step 4659: loss = 1.9921 (0.760 sec/step)\n","I0908 16:27:37.356523 140650862335872 learning.py:512] global step 4659: loss = 1.9921 (0.760 sec/step)\n","INFO:tensorflow:global step 4660: loss = 1.9882 (0.760 sec/step)\n","I0908 16:27:38.118138 140650862335872 learning.py:512] global step 4660: loss = 1.9882 (0.760 sec/step)\n","INFO:tensorflow:global step 4661: loss = 2.8034 (0.758 sec/step)\n","I0908 16:27:38.877557 140650862335872 learning.py:512] global step 4661: loss = 2.8034 (0.758 sec/step)\n","INFO:tensorflow:global step 4662: loss = 2.3881 (0.741 sec/step)\n","I0908 16:27:39.620526 140650862335872 learning.py:512] global step 4662: loss = 2.3881 (0.741 sec/step)\n","INFO:tensorflow:global step 4663: loss = 1.7691 (0.749 sec/step)\n","I0908 16:27:40.371099 140650862335872 learning.py:512] global step 4663: loss = 1.7691 (0.749 sec/step)\n","INFO:tensorflow:global step 4664: loss = 1.7836 (0.773 sec/step)\n","I0908 16:27:41.145713 140650862335872 learning.py:512] global step 4664: loss = 1.7836 (0.773 sec/step)\n","INFO:tensorflow:global step 4665: loss = 2.3404 (0.734 sec/step)\n","I0908 16:27:41.881018 140650862335872 learning.py:512] global step 4665: loss = 2.3404 (0.734 sec/step)\n","INFO:tensorflow:global step 4666: loss = 2.1455 (0.765 sec/step)\n","I0908 16:27:42.647411 140650862335872 learning.py:512] global step 4666: loss = 2.1455 (0.765 sec/step)\n","INFO:tensorflow:global step 4667: loss = 2.2830 (0.759 sec/step)\n","I0908 16:27:43.408485 140650862335872 learning.py:512] global step 4667: loss = 2.2830 (0.759 sec/step)\n","INFO:tensorflow:global step 4668: loss = 2.5961 (0.756 sec/step)\n","I0908 16:27:44.166507 140650862335872 learning.py:512] global step 4668: loss = 2.5961 (0.756 sec/step)\n","INFO:tensorflow:global step 4669: loss = 2.6132 (0.765 sec/step)\n","I0908 16:27:44.933180 140650862335872 learning.py:512] global step 4669: loss = 2.6132 (0.765 sec/step)\n","INFO:tensorflow:global step 4670: loss = 2.5303 (0.764 sec/step)\n","I0908 16:27:45.698785 140650862335872 learning.py:512] global step 4670: loss = 2.5303 (0.764 sec/step)\n","INFO:tensorflow:Saving checkpoint to path /root/models/trained_v2/model.ckpt\n","I0908 16:27:46.273346 140646958036736 supervisor.py:1117] Saving checkpoint to path /root/models/trained_v2/model.ckpt\n","INFO:tensorflow:global step 4671: loss = 2.1882 (0.901 sec/step)\n","I0908 16:27:47.164854 140650862335872 learning.py:512] global step 4671: loss = 2.1882 (0.901 sec/step)\n","INFO:tensorflow:Recording summary at step 4671.\n","I0908 16:27:47.781491 140646941251328 supervisor.py:1050] Recording summary at step 4671.\n","INFO:tensorflow:global step 4672: loss = 1.8260 (1.090 sec/step)\n","I0908 16:27:48.267432 140650862335872 learning.py:512] global step 4672: loss = 1.8260 (1.090 sec/step)\n","INFO:tensorflow:global step 4673: loss = 1.9812 (1.014 sec/step)\n","I0908 16:27:49.404763 140650862335872 learning.py:512] global step 4673: loss = 1.9812 (1.014 sec/step)\n","INFO:tensorflow:global step 4674: loss = 2.0491 (0.764 sec/step)\n","I0908 16:27:50.171461 140650862335872 learning.py:512] global step 4674: loss = 2.0491 (0.764 sec/step)\n","INFO:tensorflow:global step 4675: loss = 1.7250 (0.746 sec/step)\n","I0908 16:27:50.918587 140650862335872 learning.py:512] global step 4675: loss = 1.7250 (0.746 sec/step)\n","INFO:tensorflow:global step 4676: loss = 2.1449 (0.757 sec/step)\n","I0908 16:27:51.677580 140650862335872 learning.py:512] global step 4676: loss = 2.1449 (0.757 sec/step)\n","INFO:tensorflow:global step 4677: loss = 2.1771 (0.759 sec/step)\n","I0908 16:27:52.438437 140650862335872 learning.py:512] global step 4677: loss = 2.1771 (0.759 sec/step)\n","INFO:tensorflow:global step 4678: loss = 1.7922 (0.750 sec/step)\n","I0908 16:27:53.190108 140650862335872 learning.py:512] global step 4678: loss = 1.7922 (0.750 sec/step)\n","INFO:tensorflow:global step 4679: loss = 1.9248 (0.749 sec/step)\n","I0908 16:27:53.941396 140650862335872 learning.py:512] global step 4679: loss = 1.9248 (0.749 sec/step)\n","INFO:tensorflow:global step 4680: loss = 2.1170 (0.755 sec/step)\n","I0908 16:27:54.698318 140650862335872 learning.py:512] global step 4680: loss = 2.1170 (0.755 sec/step)\n","INFO:tensorflow:global step 4681: loss = 2.0196 (0.757 sec/step)\n","I0908 16:27:55.456485 140650862335872 learning.py:512] global step 4681: loss = 2.0196 (0.757 sec/step)\n","INFO:tensorflow:global step 4682: loss = 2.5361 (0.759 sec/step)\n","I0908 16:27:56.217284 140650862335872 learning.py:512] global step 4682: loss = 2.5361 (0.759 sec/step)\n","INFO:tensorflow:global step 4683: loss = 1.9035 (0.756 sec/step)\n","I0908 16:27:56.974825 140650862335872 learning.py:512] global step 4683: loss = 1.9035 (0.756 sec/step)\n","INFO:tensorflow:global step 4684: loss = 2.4367 (0.740 sec/step)\n","I0908 16:27:57.716403 140650862335872 learning.py:512] global step 4684: loss = 2.4367 (0.740 sec/step)\n","INFO:tensorflow:global step 4685: loss = 1.6951 (0.763 sec/step)\n","I0908 16:27:58.480661 140650862335872 learning.py:512] global step 4685: loss = 1.6951 (0.763 sec/step)\n","INFO:tensorflow:global step 4686: loss = 2.2591 (0.771 sec/step)\n","I0908 16:27:59.253464 140650862335872 learning.py:512] global step 4686: loss = 2.2591 (0.771 sec/step)\n","INFO:tensorflow:global step 4687: loss = 1.9400 (0.767 sec/step)\n","I0908 16:28:00.022753 140650862335872 learning.py:512] global step 4687: loss = 1.9400 (0.767 sec/step)\n","INFO:tensorflow:global step 4688: loss = 2.1729 (0.737 sec/step)\n","I0908 16:28:00.761056 140650862335872 learning.py:512] global step 4688: loss = 2.1729 (0.737 sec/step)\n","INFO:tensorflow:global step 4689: loss = 1.8910 (0.770 sec/step)\n","I0908 16:28:01.532762 140650862335872 learning.py:512] global step 4689: loss = 1.8910 (0.770 sec/step)\n","INFO:tensorflow:global step 4690: loss = 1.9431 (0.770 sec/step)\n","I0908 16:28:02.304636 140650862335872 learning.py:512] global step 4690: loss = 1.9431 (0.770 sec/step)\n","INFO:tensorflow:global step 4691: loss = 2.3946 (0.736 sec/step)\n","I0908 16:28:03.042169 140650862335872 learning.py:512] global step 4691: loss = 2.3946 (0.736 sec/step)\n","INFO:tensorflow:global step 4692: loss = 1.9193 (0.768 sec/step)\n","I0908 16:28:03.811345 140650862335872 learning.py:512] global step 4692: loss = 1.9193 (0.768 sec/step)\n","INFO:tensorflow:global step 4693: loss = 1.5966 (0.754 sec/step)\n","I0908 16:28:04.566420 140650862335872 learning.py:512] global step 4693: loss = 1.5966 (0.754 sec/step)\n","INFO:tensorflow:global step 4694: loss = 2.2099 (0.757 sec/step)\n","I0908 16:28:05.325339 140650862335872 learning.py:512] global step 4694: loss = 2.2099 (0.757 sec/step)\n","INFO:tensorflow:global step 4695: loss = 1.9522 (0.761 sec/step)\n","I0908 16:28:06.088244 140650862335872 learning.py:512] global step 4695: loss = 1.9522 (0.761 sec/step)\n","INFO:tensorflow:global step 4696: loss = 1.7485 (0.773 sec/step)\n","I0908 16:28:06.863224 140650862335872 learning.py:512] global step 4696: loss = 1.7485 (0.773 sec/step)\n","INFO:tensorflow:global step 4697: loss = 1.7381 (0.750 sec/step)\n","I0908 16:28:07.615457 140650862335872 learning.py:512] global step 4697: loss = 1.7381 (0.750 sec/step)\n","INFO:tensorflow:global step 4698: loss = 2.2679 (0.763 sec/step)\n","I0908 16:28:08.380362 140650862335872 learning.py:512] global step 4698: loss = 2.2679 (0.763 sec/step)\n","INFO:tensorflow:global step 4699: loss = 2.2018 (0.735 sec/step)\n","I0908 16:28:09.117632 140650862335872 learning.py:512] global step 4699: loss = 2.2018 (0.735 sec/step)\n","INFO:tensorflow:global step 4700: loss = 1.9170 (0.727 sec/step)\n","I0908 16:28:09.846786 140650862335872 learning.py:512] global step 4700: loss = 1.9170 (0.727 sec/step)\n","INFO:tensorflow:global step 4701: loss = 2.6410 (0.746 sec/step)\n","I0908 16:28:10.594458 140650862335872 learning.py:512] global step 4701: loss = 2.6410 (0.746 sec/step)\n","INFO:tensorflow:global step 4702: loss = 2.0935 (0.760 sec/step)\n","I0908 16:28:11.356345 140650862335872 learning.py:512] global step 4702: loss = 2.0935 (0.760 sec/step)\n","INFO:tensorflow:global step 4703: loss = 1.9254 (0.747 sec/step)\n","I0908 16:28:12.105460 140650862335872 learning.py:512] global step 4703: loss = 1.9254 (0.747 sec/step)\n","INFO:tensorflow:global step 4704: loss = 1.6481 (0.758 sec/step)\n","I0908 16:28:12.864802 140650862335872 learning.py:512] global step 4704: loss = 1.6481 (0.758 sec/step)\n","INFO:tensorflow:global step 4705: loss = 1.9285 (0.760 sec/step)\n","I0908 16:28:13.626118 140650862335872 learning.py:512] global step 4705: loss = 1.9285 (0.760 sec/step)\n","INFO:tensorflow:global step 4706: loss = 2.6679 (0.728 sec/step)\n","I0908 16:28:14.355354 140650862335872 learning.py:512] global step 4706: loss = 2.6679 (0.728 sec/step)\n","INFO:tensorflow:global step 4707: loss = 1.8038 (0.733 sec/step)\n","I0908 16:28:15.089601 140650862335872 learning.py:512] global step 4707: loss = 1.8038 (0.733 sec/step)\n","INFO:tensorflow:global step 4708: loss = 2.0670 (0.759 sec/step)\n","I0908 16:28:15.850426 140650862335872 learning.py:512] global step 4708: loss = 2.0670 (0.759 sec/step)\n","INFO:tensorflow:global step 4709: loss = 1.7804 (0.745 sec/step)\n","I0908 16:28:16.597159 140650862335872 learning.py:512] global step 4709: loss = 1.7804 (0.745 sec/step)\n","INFO:tensorflow:global step 4710: loss = 1.9675 (0.747 sec/step)\n","I0908 16:28:17.345642 140650862335872 learning.py:512] global step 4710: loss = 1.9675 (0.747 sec/step)\n","INFO:tensorflow:global step 4711: loss = 1.9316 (0.744 sec/step)\n","I0908 16:28:18.091629 140650862335872 learning.py:512] global step 4711: loss = 1.9316 (0.744 sec/step)\n","INFO:tensorflow:global step 4712: loss = 2.3481 (0.752 sec/step)\n","I0908 16:28:18.844863 140650862335872 learning.py:512] global step 4712: loss = 2.3481 (0.752 sec/step)\n","INFO:tensorflow:global step 4713: loss = 2.1948 (0.742 sec/step)\n","I0908 16:28:19.588954 140650862335872 learning.py:512] global step 4713: loss = 2.1948 (0.742 sec/step)\n","INFO:tensorflow:global step 4714: loss = 1.8565 (0.752 sec/step)\n","I0908 16:28:20.342834 140650862335872 learning.py:512] global step 4714: loss = 1.8565 (0.752 sec/step)\n","INFO:tensorflow:global step 4715: loss = 1.9912 (0.771 sec/step)\n","I0908 16:28:21.115346 140650862335872 learning.py:512] global step 4715: loss = 1.9912 (0.771 sec/step)\n","INFO:tensorflow:global step 4716: loss = 1.7835 (0.746 sec/step)\n","I0908 16:28:21.862791 140650862335872 learning.py:512] global step 4716: loss = 1.7835 (0.746 sec/step)\n","INFO:tensorflow:global step 4717: loss = 2.0127 (0.744 sec/step)\n","I0908 16:28:22.608494 140650862335872 learning.py:512] global step 4717: loss = 2.0127 (0.744 sec/step)\n","INFO:tensorflow:global step 4718: loss = 2.2540 (0.746 sec/step)\n","I0908 16:28:23.356554 140650862335872 learning.py:512] global step 4718: loss = 2.2540 (0.746 sec/step)\n","INFO:tensorflow:global step 4719: loss = 2.2920 (0.766 sec/step)\n","I0908 16:28:24.124140 140650862335872 learning.py:512] global step 4719: loss = 2.2920 (0.766 sec/step)\n","INFO:tensorflow:global step 4720: loss = 2.1810 (0.759 sec/step)\n","I0908 16:28:24.884339 140650862335872 learning.py:512] global step 4720: loss = 2.1810 (0.759 sec/step)\n","INFO:tensorflow:global step 4721: loss = 2.1269 (0.756 sec/step)\n","I0908 16:28:25.642214 140650862335872 learning.py:512] global step 4721: loss = 2.1269 (0.756 sec/step)\n","INFO:tensorflow:global step 4722: loss = 2.2069 (0.765 sec/step)\n","I0908 16:28:26.408798 140650862335872 learning.py:512] global step 4722: loss = 2.2069 (0.765 sec/step)\n","INFO:tensorflow:global step 4723: loss = 1.8112 (0.760 sec/step)\n","I0908 16:28:27.171165 140650862335872 learning.py:512] global step 4723: loss = 1.8112 (0.760 sec/step)\n","INFO:tensorflow:global step 4724: loss = 1.8553 (0.762 sec/step)\n","I0908 16:28:27.934307 140650862335872 learning.py:512] global step 4724: loss = 1.8553 (0.762 sec/step)\n","INFO:tensorflow:global step 4725: loss = 2.1777 (0.761 sec/step)\n","I0908 16:28:28.696664 140650862335872 learning.py:512] global step 4725: loss = 2.1777 (0.761 sec/step)\n","INFO:tensorflow:global step 4726: loss = 2.1936 (0.743 sec/step)\n","I0908 16:28:29.441840 140650862335872 learning.py:512] global step 4726: loss = 2.1936 (0.743 sec/step)\n","INFO:tensorflow:global step 4727: loss = 2.0892 (0.759 sec/step)\n","I0908 16:28:30.202255 140650862335872 learning.py:512] global step 4727: loss = 2.0892 (0.759 sec/step)\n","INFO:tensorflow:global step 4728: loss = 1.9264 (0.748 sec/step)\n","I0908 16:28:30.951720 140650862335872 learning.py:512] global step 4728: loss = 1.9264 (0.748 sec/step)\n","INFO:tensorflow:global step 4729: loss = 2.4248 (0.763 sec/step)\n","I0908 16:28:31.716489 140650862335872 learning.py:512] global step 4729: loss = 2.4248 (0.763 sec/step)\n","INFO:tensorflow:global step 4730: loss = 1.6493 (0.771 sec/step)\n","I0908 16:28:32.488909 140650862335872 learning.py:512] global step 4730: loss = 1.6493 (0.771 sec/step)\n","INFO:tensorflow:global step 4731: loss = 2.1171 (0.763 sec/step)\n","I0908 16:28:33.253654 140650862335872 learning.py:512] global step 4731: loss = 2.1171 (0.763 sec/step)\n","INFO:tensorflow:global step 4732: loss = 1.8632 (0.774 sec/step)\n","I0908 16:28:34.029542 140650862335872 learning.py:512] global step 4732: loss = 1.8632 (0.774 sec/step)\n","INFO:tensorflow:global step 4733: loss = 1.9186 (0.744 sec/step)\n","I0908 16:28:34.775531 140650862335872 learning.py:512] global step 4733: loss = 1.9186 (0.744 sec/step)\n","INFO:tensorflow:global step 4734: loss = 2.3575 (0.755 sec/step)\n","I0908 16:28:35.532497 140650862335872 learning.py:512] global step 4734: loss = 2.3575 (0.755 sec/step)\n","INFO:tensorflow:global step 4735: loss = 2.5076 (0.776 sec/step)\n","I0908 16:28:36.309786 140650862335872 learning.py:512] global step 4735: loss = 2.5076 (0.776 sec/step)\n","INFO:tensorflow:global step 4736: loss = 2.1659 (0.761 sec/step)\n","I0908 16:28:37.072501 140650862335872 learning.py:512] global step 4736: loss = 2.1659 (0.761 sec/step)\n","INFO:tensorflow:global step 4737: loss = 1.9587 (0.759 sec/step)\n","I0908 16:28:37.833090 140650862335872 learning.py:512] global step 4737: loss = 1.9587 (0.759 sec/step)\n","INFO:tensorflow:global step 4738: loss = 2.0138 (0.735 sec/step)\n","I0908 16:28:38.569608 140650862335872 learning.py:512] global step 4738: loss = 2.0138 (0.735 sec/step)\n","INFO:tensorflow:global step 4739: loss = 1.9168 (0.767 sec/step)\n","I0908 16:28:39.338695 140650862335872 learning.py:512] global step 4739: loss = 1.9168 (0.767 sec/step)\n","INFO:tensorflow:global step 4740: loss = 1.6671 (0.774 sec/step)\n","I0908 16:28:40.114198 140650862335872 learning.py:512] global step 4740: loss = 1.6671 (0.774 sec/step)\n","INFO:tensorflow:global step 4741: loss = 1.8973 (0.761 sec/step)\n","I0908 16:28:40.877261 140650862335872 learning.py:512] global step 4741: loss = 1.8973 (0.761 sec/step)\n","INFO:tensorflow:global step 4742: loss = 1.8697 (0.751 sec/step)\n","I0908 16:28:41.630437 140650862335872 learning.py:512] global step 4742: loss = 1.8697 (0.751 sec/step)\n","INFO:tensorflow:global step 4743: loss = 2.1885 (0.756 sec/step)\n","I0908 16:28:42.388068 140650862335872 learning.py:512] global step 4743: loss = 2.1885 (0.756 sec/step)\n","INFO:tensorflow:global step 4744: loss = 1.8604 (0.758 sec/step)\n","I0908 16:28:43.147935 140650862335872 learning.py:512] global step 4744: loss = 1.8604 (0.758 sec/step)\n","INFO:tensorflow:global step 4745: loss = 1.8364 (0.776 sec/step)\n","I0908 16:28:43.925412 140650862335872 learning.py:512] global step 4745: loss = 1.8364 (0.776 sec/step)\n","INFO:tensorflow:global step 4746: loss = 1.7346 (0.753 sec/step)\n","I0908 16:28:44.680123 140650862335872 learning.py:512] global step 4746: loss = 1.7346 (0.753 sec/step)\n","INFO:tensorflow:global step 4747: loss = 1.8603 (0.749 sec/step)\n","I0908 16:28:45.431560 140650862335872 learning.py:512] global step 4747: loss = 1.8603 (0.749 sec/step)\n","INFO:tensorflow:global step 4748: loss = 1.6682 (0.750 sec/step)\n","I0908 16:28:46.183214 140650862335872 learning.py:512] global step 4748: loss = 1.6682 (0.750 sec/step)\n","INFO:tensorflow:global step 4749: loss = 2.0320 (0.759 sec/step)\n","I0908 16:28:46.944517 140650862335872 learning.py:512] global step 4749: loss = 2.0320 (0.759 sec/step)\n","INFO:tensorflow:global step 4750: loss = 1.9763 (0.760 sec/step)\n","I0908 16:28:47.706401 140650862335872 learning.py:512] global step 4750: loss = 1.9763 (0.760 sec/step)\n","INFO:tensorflow:global step 4751: loss = 1.9767 (0.767 sec/step)\n","I0908 16:28:48.475591 140650862335872 learning.py:512] global step 4751: loss = 1.9767 (0.767 sec/step)\n","INFO:tensorflow:global step 4752: loss = 1.9005 (0.748 sec/step)\n","I0908 16:28:49.224885 140650862335872 learning.py:512] global step 4752: loss = 1.9005 (0.748 sec/step)\n","INFO:tensorflow:global step 4753: loss = 2.4530 (0.766 sec/step)\n","I0908 16:28:49.992881 140650862335872 learning.py:512] global step 4753: loss = 2.4530 (0.766 sec/step)\n","INFO:tensorflow:global step 4754: loss = 1.9220 (0.764 sec/step)\n","I0908 16:28:50.758226 140650862335872 learning.py:512] global step 4754: loss = 1.9220 (0.764 sec/step)\n","INFO:tensorflow:global step 4755: loss = 2.1729 (0.763 sec/step)\n","I0908 16:28:51.523296 140650862335872 learning.py:512] global step 4755: loss = 2.1729 (0.763 sec/step)\n","INFO:tensorflow:global step 4756: loss = 2.0620 (0.766 sec/step)\n","I0908 16:28:52.290716 140650862335872 learning.py:512] global step 4756: loss = 2.0620 (0.766 sec/step)\n","INFO:tensorflow:global step 4757: loss = 1.7032 (0.765 sec/step)\n","I0908 16:28:53.057623 140650862335872 learning.py:512] global step 4757: loss = 1.7032 (0.765 sec/step)\n","INFO:tensorflow:global step 4758: loss = 1.9005 (0.775 sec/step)\n","I0908 16:28:53.834691 140650862335872 learning.py:512] global step 4758: loss = 1.9005 (0.775 sec/step)\n","INFO:tensorflow:global step 4759: loss = 2.0099 (0.759 sec/step)\n","I0908 16:28:54.595114 140650862335872 learning.py:512] global step 4759: loss = 2.0099 (0.759 sec/step)\n","INFO:tensorflow:global step 4760: loss = 2.2406 (0.752 sec/step)\n","I0908 16:28:55.349506 140650862335872 learning.py:512] global step 4760: loss = 2.2406 (0.752 sec/step)\n","INFO:tensorflow:global step 4761: loss = 2.1072 (0.753 sec/step)\n","I0908 16:28:56.104238 140650862335872 learning.py:512] global step 4761: loss = 2.1072 (0.753 sec/step)\n","INFO:tensorflow:global step 4762: loss = 2.0398 (0.767 sec/step)\n","I0908 16:28:56.872715 140650862335872 learning.py:512] global step 4762: loss = 2.0398 (0.767 sec/step)\n","INFO:tensorflow:global step 4763: loss = 2.1368 (0.745 sec/step)\n","I0908 16:28:57.619704 140650862335872 learning.py:512] global step 4763: loss = 2.1368 (0.745 sec/step)\n","INFO:tensorflow:global step 4764: loss = 1.9655 (0.772 sec/step)\n","I0908 16:28:58.393660 140650862335872 learning.py:512] global step 4764: loss = 1.9655 (0.772 sec/step)\n","INFO:tensorflow:global step 4765: loss = 2.0043 (0.748 sec/step)\n","I0908 16:28:59.143013 140650862335872 learning.py:512] global step 4765: loss = 2.0043 (0.748 sec/step)\n","INFO:tensorflow:global step 4766: loss = 1.8872 (0.746 sec/step)\n","I0908 16:28:59.891105 140650862335872 learning.py:512] global step 4766: loss = 1.8872 (0.746 sec/step)\n","INFO:tensorflow:global step 4767: loss = 2.0568 (0.746 sec/step)\n","I0908 16:29:00.638387 140650862335872 learning.py:512] global step 4767: loss = 2.0568 (0.746 sec/step)\n","INFO:tensorflow:global step 4768: loss = 1.8170 (0.751 sec/step)\n","I0908 16:29:01.391222 140650862335872 learning.py:512] global step 4768: loss = 1.8170 (0.751 sec/step)\n","INFO:tensorflow:global step 4769: loss = 1.6685 (0.776 sec/step)\n","I0908 16:29:02.168934 140650862335872 learning.py:512] global step 4769: loss = 1.6685 (0.776 sec/step)\n","INFO:tensorflow:global step 4770: loss = 2.6900 (0.762 sec/step)\n","I0908 16:29:02.932263 140650862335872 learning.py:512] global step 4770: loss = 2.6900 (0.762 sec/step)\n","INFO:tensorflow:global step 4771: loss = 2.2070 (0.753 sec/step)\n","I0908 16:29:03.686956 140650862335872 learning.py:512] global step 4771: loss = 2.2070 (0.753 sec/step)\n","INFO:tensorflow:global step 4772: loss = 2.1152 (0.736 sec/step)\n","I0908 16:29:04.424530 140650862335872 learning.py:512] global step 4772: loss = 2.1152 (0.736 sec/step)\n","INFO:tensorflow:global step 4773: loss = 1.9342 (0.751 sec/step)\n","I0908 16:29:05.177349 140650862335872 learning.py:512] global step 4773: loss = 1.9342 (0.751 sec/step)\n","INFO:tensorflow:global step 4774: loss = 1.7917 (0.756 sec/step)\n","I0908 16:29:05.935360 140650862335872 learning.py:512] global step 4774: loss = 1.7917 (0.756 sec/step)\n","INFO:tensorflow:global step 4775: loss = 2.8922 (0.762 sec/step)\n","I0908 16:29:06.699432 140650862335872 learning.py:512] global step 4775: loss = 2.8922 (0.762 sec/step)\n","INFO:tensorflow:global step 4776: loss = 1.9392 (0.761 sec/step)\n","I0908 16:29:07.462436 140650862335872 learning.py:512] global step 4776: loss = 1.9392 (0.761 sec/step)\n","INFO:tensorflow:global step 4777: loss = 2.1781 (0.752 sec/step)\n","I0908 16:29:08.215506 140650862335872 learning.py:512] global step 4777: loss = 2.1781 (0.752 sec/step)\n","INFO:tensorflow:global step 4778: loss = 1.9797 (0.756 sec/step)\n","I0908 16:29:08.973038 140650862335872 learning.py:512] global step 4778: loss = 1.9797 (0.756 sec/step)\n","INFO:tensorflow:global step 4779: loss = 1.9594 (0.752 sec/step)\n","I0908 16:29:09.727238 140650862335872 learning.py:512] global step 4779: loss = 1.9594 (0.752 sec/step)\n","INFO:tensorflow:global step 4780: loss = 1.7761 (0.758 sec/step)\n","I0908 16:29:10.487163 140650862335872 learning.py:512] global step 4780: loss = 1.7761 (0.758 sec/step)\n","INFO:tensorflow:global step 4781: loss = 2.0872 (0.751 sec/step)\n","I0908 16:29:11.239574 140650862335872 learning.py:512] global step 4781: loss = 2.0872 (0.751 sec/step)\n","INFO:tensorflow:global step 4782: loss = 1.7002 (0.746 sec/step)\n","I0908 16:29:11.987470 140650862335872 learning.py:512] global step 4782: loss = 1.7002 (0.746 sec/step)\n","INFO:tensorflow:global step 4783: loss = 2.1656 (0.794 sec/step)\n","I0908 16:29:12.783180 140650862335872 learning.py:512] global step 4783: loss = 2.1656 (0.794 sec/step)\n","INFO:tensorflow:global step 4784: loss = 1.7824 (0.758 sec/step)\n","I0908 16:29:13.543441 140650862335872 learning.py:512] global step 4784: loss = 1.7824 (0.758 sec/step)\n","INFO:tensorflow:global step 4785: loss = 2.1342 (0.759 sec/step)\n","I0908 16:29:14.304865 140650862335872 learning.py:512] global step 4785: loss = 2.1342 (0.759 sec/step)\n","INFO:tensorflow:global step 4786: loss = 1.7951 (0.740 sec/step)\n","I0908 16:29:15.047116 140650862335872 learning.py:512] global step 4786: loss = 1.7951 (0.740 sec/step)\n","INFO:tensorflow:global step 4787: loss = 1.7443 (0.776 sec/step)\n","I0908 16:29:15.824610 140650862335872 learning.py:512] global step 4787: loss = 1.7443 (0.776 sec/step)\n","INFO:tensorflow:global step 4788: loss = 1.7278 (0.753 sec/step)\n","I0908 16:29:16.579756 140650862335872 learning.py:512] global step 4788: loss = 1.7278 (0.753 sec/step)\n","INFO:tensorflow:global step 4789: loss = 1.7958 (0.746 sec/step)\n","I0908 16:29:17.328274 140650862335872 learning.py:512] global step 4789: loss = 1.7958 (0.746 sec/step)\n","INFO:tensorflow:global step 4790: loss = 2.0284 (0.759 sec/step)\n","I0908 16:29:18.089365 140650862335872 learning.py:512] global step 4790: loss = 2.0284 (0.759 sec/step)\n","INFO:tensorflow:global step 4791: loss = 1.8674 (0.757 sec/step)\n","I0908 16:29:18.848270 140650862335872 learning.py:512] global step 4791: loss = 1.8674 (0.757 sec/step)\n","INFO:tensorflow:global step 4792: loss = 1.7543 (0.744 sec/step)\n","I0908 16:29:19.593657 140650862335872 learning.py:512] global step 4792: loss = 1.7543 (0.744 sec/step)\n","INFO:tensorflow:global step 4793: loss = 1.8550 (0.760 sec/step)\n","I0908 16:29:20.355112 140650862335872 learning.py:512] global step 4793: loss = 1.8550 (0.760 sec/step)\n","INFO:tensorflow:global step 4794: loss = 1.7895 (0.727 sec/step)\n","I0908 16:29:21.084292 140650862335872 learning.py:512] global step 4794: loss = 1.7895 (0.727 sec/step)\n","INFO:tensorflow:global step 4795: loss = 1.7668 (0.757 sec/step)\n","I0908 16:29:21.843234 140650862335872 learning.py:512] global step 4795: loss = 1.7668 (0.757 sec/step)\n","INFO:tensorflow:global step 4796: loss = 1.8133 (0.759 sec/step)\n","I0908 16:29:22.605511 140650862335872 learning.py:512] global step 4796: loss = 1.8133 (0.759 sec/step)\n","INFO:tensorflow:global step 4797: loss = 2.6624 (0.747 sec/step)\n","I0908 16:29:23.354987 140650862335872 learning.py:512] global step 4797: loss = 2.6624 (0.747 sec/step)\n","INFO:tensorflow:global step 4798: loss = 2.0639 (0.769 sec/step)\n","I0908 16:29:24.125587 140650862335872 learning.py:512] global step 4798: loss = 2.0639 (0.769 sec/step)\n","INFO:tensorflow:global step 4799: loss = 2.2517 (0.770 sec/step)\n","I0908 16:29:24.897450 140650862335872 learning.py:512] global step 4799: loss = 2.2517 (0.770 sec/step)\n","INFO:tensorflow:global step 4800: loss = 1.9924 (0.760 sec/step)\n","I0908 16:29:25.658824 140650862335872 learning.py:512] global step 4800: loss = 1.9924 (0.760 sec/step)\n","INFO:tensorflow:global step 4801: loss = 2.3170 (0.753 sec/step)\n","I0908 16:29:26.413332 140650862335872 learning.py:512] global step 4801: loss = 2.3170 (0.753 sec/step)\n","INFO:tensorflow:global step 4802: loss = 2.1633 (0.768 sec/step)\n","I0908 16:29:27.182829 140650862335872 learning.py:512] global step 4802: loss = 2.1633 (0.768 sec/step)\n","INFO:tensorflow:global step 4803: loss = 2.3467 (0.761 sec/step)\n","I0908 16:29:27.945820 140650862335872 learning.py:512] global step 4803: loss = 2.3467 (0.761 sec/step)\n","INFO:tensorflow:global step 4804: loss = 2.1007 (0.754 sec/step)\n","I0908 16:29:28.701390 140650862335872 learning.py:512] global step 4804: loss = 2.1007 (0.754 sec/step)\n","INFO:tensorflow:global step 4805: loss = 2.6004 (0.755 sec/step)\n","I0908 16:29:29.458510 140650862335872 learning.py:512] global step 4805: loss = 2.6004 (0.755 sec/step)\n","INFO:tensorflow:global step 4806: loss = 1.8646 (0.789 sec/step)\n","I0908 16:29:30.249464 140650862335872 learning.py:512] global step 4806: loss = 1.8646 (0.789 sec/step)\n","INFO:tensorflow:global step 4807: loss = 1.9738 (0.752 sec/step)\n","I0908 16:29:31.002815 140650862335872 learning.py:512] global step 4807: loss = 1.9738 (0.752 sec/step)\n","INFO:tensorflow:global step 4808: loss = 1.8798 (0.748 sec/step)\n","I0908 16:29:31.752179 140650862335872 learning.py:512] global step 4808: loss = 1.8798 (0.748 sec/step)\n","INFO:tensorflow:global step 4809: loss = 1.9032 (0.763 sec/step)\n","I0908 16:29:32.517116 140650862335872 learning.py:512] global step 4809: loss = 1.9032 (0.763 sec/step)\n","INFO:tensorflow:global step 4810: loss = 1.8270 (0.757 sec/step)\n","I0908 16:29:33.276015 140650862335872 learning.py:512] global step 4810: loss = 1.8270 (0.757 sec/step)\n","INFO:tensorflow:global step 4811: loss = 2.5350 (0.764 sec/step)\n","I0908 16:29:34.041191 140650862335872 learning.py:512] global step 4811: loss = 2.5350 (0.764 sec/step)\n","INFO:tensorflow:global step 4812: loss = 2.5521 (0.762 sec/step)\n","I0908 16:29:34.804907 140650862335872 learning.py:512] global step 4812: loss = 2.5521 (0.762 sec/step)\n","INFO:tensorflow:global step 4813: loss = 1.7689 (0.753 sec/step)\n","I0908 16:29:35.559548 140650862335872 learning.py:512] global step 4813: loss = 1.7689 (0.753 sec/step)\n","INFO:tensorflow:global step 4814: loss = 2.0812 (0.763 sec/step)\n","I0908 16:29:36.324154 140650862335872 learning.py:512] global step 4814: loss = 2.0812 (0.763 sec/step)\n","INFO:tensorflow:global step 4815: loss = 2.3094 (0.755 sec/step)\n","I0908 16:29:37.080586 140650862335872 learning.py:512] global step 4815: loss = 2.3094 (0.755 sec/step)\n","INFO:tensorflow:global step 4816: loss = 1.8931 (0.759 sec/step)\n","I0908 16:29:37.841493 140650862335872 learning.py:512] global step 4816: loss = 1.8931 (0.759 sec/step)\n","INFO:tensorflow:global step 4817: loss = 1.7247 (0.772 sec/step)\n","I0908 16:29:38.614989 140650862335872 learning.py:512] global step 4817: loss = 1.7247 (0.772 sec/step)\n","INFO:tensorflow:global step 4818: loss = 2.0664 (0.762 sec/step)\n","I0908 16:29:39.378522 140650862335872 learning.py:512] global step 4818: loss = 2.0664 (0.762 sec/step)\n","INFO:tensorflow:global step 4819: loss = 2.0275 (0.749 sec/step)\n","I0908 16:29:40.129465 140650862335872 learning.py:512] global step 4819: loss = 2.0275 (0.749 sec/step)\n","INFO:tensorflow:global step 4820: loss = 1.6794 (0.760 sec/step)\n","I0908 16:29:40.890754 140650862335872 learning.py:512] global step 4820: loss = 1.6794 (0.760 sec/step)\n","INFO:tensorflow:global step 4821: loss = 1.7254 (0.758 sec/step)\n","I0908 16:29:41.650971 140650862335872 learning.py:512] global step 4821: loss = 1.7254 (0.758 sec/step)\n","INFO:tensorflow:global step 4822: loss = 1.9527 (0.746 sec/step)\n","I0908 16:29:42.398128 140650862335872 learning.py:512] global step 4822: loss = 1.9527 (0.746 sec/step)\n","INFO:tensorflow:global step 4823: loss = 2.1678 (0.745 sec/step)\n","I0908 16:29:43.144996 140650862335872 learning.py:512] global step 4823: loss = 2.1678 (0.745 sec/step)\n","INFO:tensorflow:global step 4824: loss = 1.9880 (0.756 sec/step)\n","I0908 16:29:43.902924 140650862335872 learning.py:512] global step 4824: loss = 1.9880 (0.756 sec/step)\n","INFO:tensorflow:global step 4825: loss = 1.8363 (0.753 sec/step)\n","I0908 16:29:44.657444 140650862335872 learning.py:512] global step 4825: loss = 1.8363 (0.753 sec/step)\n","INFO:tensorflow:global step 4826: loss = 1.7048 (0.758 sec/step)\n","I0908 16:29:45.417227 140650862335872 learning.py:512] global step 4826: loss = 1.7048 (0.758 sec/step)\n","INFO:tensorflow:global step 4827: loss = 2.3141 (0.757 sec/step)\n","I0908 16:29:46.175537 140650862335872 learning.py:512] global step 4827: loss = 2.3141 (0.757 sec/step)\n","INFO:tensorflow:global step 4828: loss = 2.1802 (1.338 sec/step)\n","I0908 16:29:47.515333 140650862335872 learning.py:512] global step 4828: loss = 2.1802 (1.338 sec/step)\n","INFO:tensorflow:Recording summary at step 4828.\n","I0908 16:29:47.518471 140646941251328 supervisor.py:1050] Recording summary at step 4828.\n","INFO:tensorflow:global step 4829: loss = 2.0483 (0.770 sec/step)\n","I0908 16:29:48.287422 140650862335872 learning.py:512] global step 4829: loss = 2.0483 (0.770 sec/step)\n","INFO:tensorflow:global step 4830: loss = 1.8797 (0.761 sec/step)\n","I0908 16:29:49.049680 140650862335872 learning.py:512] global step 4830: loss = 1.8797 (0.761 sec/step)\n","INFO:tensorflow:global step 4831: loss = 1.7586 (0.752 sec/step)\n","I0908 16:29:49.803457 140650862335872 learning.py:512] global step 4831: loss = 1.7586 (0.752 sec/step)\n","INFO:tensorflow:global step 4832: loss = 2.2326 (0.745 sec/step)\n","I0908 16:29:50.550573 140650862335872 learning.py:512] global step 4832: loss = 2.2326 (0.745 sec/step)\n","INFO:tensorflow:global step 4833: loss = 1.9447 (0.765 sec/step)\n","I0908 16:29:51.317157 140650862335872 learning.py:512] global step 4833: loss = 1.9447 (0.765 sec/step)\n","INFO:tensorflow:global step 4834: loss = 1.6083 (0.772 sec/step)\n","I0908 16:29:52.091004 140650862335872 learning.py:512] global step 4834: loss = 1.6083 (0.772 sec/step)\n","INFO:tensorflow:global step 4835: loss = 1.7075 (0.784 sec/step)\n","I0908 16:29:52.876877 140650862335872 learning.py:512] global step 4835: loss = 1.7075 (0.784 sec/step)\n","INFO:tensorflow:global step 4836: loss = 2.0243 (0.773 sec/step)\n","I0908 16:29:53.651583 140650862335872 learning.py:512] global step 4836: loss = 2.0243 (0.773 sec/step)\n","INFO:tensorflow:global step 4837: loss = 2.2411 (0.746 sec/step)\n","I0908 16:29:54.399413 140650862335872 learning.py:512] global step 4837: loss = 2.2411 (0.746 sec/step)\n","INFO:tensorflow:global step 4838: loss = 1.6745 (0.771 sec/step)\n","I0908 16:29:55.172173 140650862335872 learning.py:512] global step 4838: loss = 1.6745 (0.771 sec/step)\n","INFO:tensorflow:global step 4839: loss = 1.7027 (0.733 sec/step)\n","I0908 16:29:55.907108 140650862335872 learning.py:512] global step 4839: loss = 1.7027 (0.733 sec/step)\n","INFO:tensorflow:global step 4840: loss = 1.6422 (0.756 sec/step)\n","I0908 16:29:56.664499 140650862335872 learning.py:512] global step 4840: loss = 1.6422 (0.756 sec/step)\n","INFO:tensorflow:global step 4841: loss = 2.1660 (0.771 sec/step)\n","I0908 16:29:57.437606 140650862335872 learning.py:512] global step 4841: loss = 2.1660 (0.771 sec/step)\n","INFO:tensorflow:global step 4842: loss = 1.5609 (0.756 sec/step)\n","I0908 16:29:58.195434 140650862335872 learning.py:512] global step 4842: loss = 1.5609 (0.756 sec/step)\n","INFO:tensorflow:global step 4843: loss = 2.1284 (0.754 sec/step)\n","I0908 16:29:58.950618 140650862335872 learning.py:512] global step 4843: loss = 2.1284 (0.754 sec/step)\n","INFO:tensorflow:global step 4844: loss = 1.8721 (0.745 sec/step)\n","I0908 16:29:59.696902 140650862335872 learning.py:512] global step 4844: loss = 1.8721 (0.745 sec/step)\n","INFO:tensorflow:global step 4845: loss = 2.3328 (0.752 sec/step)\n","I0908 16:30:00.450890 140650862335872 learning.py:512] global step 4845: loss = 2.3328 (0.752 sec/step)\n","INFO:tensorflow:global step 4846: loss = 1.7900 (0.750 sec/step)\n","I0908 16:30:01.203051 140650862335872 learning.py:512] global step 4846: loss = 1.7900 (0.750 sec/step)\n","INFO:tensorflow:global step 4847: loss = 2.3912 (0.748 sec/step)\n","I0908 16:30:01.952938 140650862335872 learning.py:512] global step 4847: loss = 2.3912 (0.748 sec/step)\n","INFO:tensorflow:global step 4848: loss = 2.3216 (0.757 sec/step)\n","I0908 16:30:02.711244 140650862335872 learning.py:512] global step 4848: loss = 2.3216 (0.757 sec/step)\n","INFO:tensorflow:global step 4849: loss = 2.5065 (0.758 sec/step)\n","I0908 16:30:03.470942 140650862335872 learning.py:512] global step 4849: loss = 2.5065 (0.758 sec/step)\n","INFO:tensorflow:global step 4850: loss = 2.3198 (0.756 sec/step)\n","I0908 16:30:04.229178 140650862335872 learning.py:512] global step 4850: loss = 2.3198 (0.756 sec/step)\n","INFO:tensorflow:global step 4851: loss = 2.2232 (0.740 sec/step)\n","I0908 16:30:04.971085 140650862335872 learning.py:512] global step 4851: loss = 2.2232 (0.740 sec/step)\n","INFO:tensorflow:global step 4852: loss = 1.9891 (0.761 sec/step)\n","I0908 16:30:05.733865 140650862335872 learning.py:512] global step 4852: loss = 1.9891 (0.761 sec/step)\n","INFO:tensorflow:global step 4853: loss = 2.5956 (0.768 sec/step)\n","I0908 16:30:06.503396 140650862335872 learning.py:512] global step 4853: loss = 2.5956 (0.768 sec/step)\n","INFO:tensorflow:global step 4854: loss = 2.1744 (0.755 sec/step)\n","I0908 16:30:07.259824 140650862335872 learning.py:512] global step 4854: loss = 2.1744 (0.755 sec/step)\n","INFO:tensorflow:global step 4855: loss = 1.8402 (0.755 sec/step)\n","I0908 16:30:08.016551 140650862335872 learning.py:512] global step 4855: loss = 1.8402 (0.755 sec/step)\n","INFO:tensorflow:global step 4856: loss = 1.9369 (0.761 sec/step)\n","I0908 16:30:08.778836 140650862335872 learning.py:512] global step 4856: loss = 1.9369 (0.761 sec/step)\n","INFO:tensorflow:global step 4857: loss = 2.1853 (0.782 sec/step)\n","I0908 16:30:09.562245 140650862335872 learning.py:512] global step 4857: loss = 2.1853 (0.782 sec/step)\n","INFO:tensorflow:global step 4858: loss = 1.9667 (0.761 sec/step)\n","I0908 16:30:10.324984 140650862335872 learning.py:512] global step 4858: loss = 1.9667 (0.761 sec/step)\n","INFO:tensorflow:global step 4859: loss = 1.9073 (0.759 sec/step)\n","I0908 16:30:11.085878 140650862335872 learning.py:512] global step 4859: loss = 1.9073 (0.759 sec/step)\n","INFO:tensorflow:global step 4860: loss = 1.8066 (0.773 sec/step)\n","I0908 16:30:11.860717 140650862335872 learning.py:512] global step 4860: loss = 1.8066 (0.773 sec/step)\n","INFO:tensorflow:global step 4861: loss = 2.1099 (0.777 sec/step)\n","I0908 16:30:12.640126 140650862335872 learning.py:512] global step 4861: loss = 2.1099 (0.777 sec/step)\n","INFO:tensorflow:global step 4862: loss = 1.8757 (0.750 sec/step)\n","I0908 16:30:13.392218 140650862335872 learning.py:512] global step 4862: loss = 1.8757 (0.750 sec/step)\n","INFO:tensorflow:global step 4863: loss = 1.9996 (0.744 sec/step)\n","I0908 16:30:14.138113 140650862335872 learning.py:512] global step 4863: loss = 1.9996 (0.744 sec/step)\n","INFO:tensorflow:global step 4864: loss = 1.7286 (0.761 sec/step)\n","I0908 16:30:14.900820 140650862335872 learning.py:512] global step 4864: loss = 1.7286 (0.761 sec/step)\n","INFO:tensorflow:global step 4865: loss = 2.1880 (0.787 sec/step)\n","I0908 16:30:15.689090 140650862335872 learning.py:512] global step 4865: loss = 2.1880 (0.787 sec/step)\n","INFO:tensorflow:global step 4866: loss = 1.9427 (0.758 sec/step)\n","I0908 16:30:16.449710 140650862335872 learning.py:512] global step 4866: loss = 1.9427 (0.758 sec/step)\n","INFO:tensorflow:global step 4867: loss = 2.0860 (0.769 sec/step)\n","I0908 16:30:17.221246 140650862335872 learning.py:512] global step 4867: loss = 2.0860 (0.769 sec/step)\n","INFO:tensorflow:global step 4868: loss = 2.0757 (0.783 sec/step)\n","I0908 16:30:18.005863 140650862335872 learning.py:512] global step 4868: loss = 2.0757 (0.783 sec/step)\n","INFO:tensorflow:global step 4869: loss = 2.3012 (0.750 sec/step)\n","I0908 16:30:18.757719 140650862335872 learning.py:512] global step 4869: loss = 2.3012 (0.750 sec/step)\n","INFO:tensorflow:global step 4870: loss = 1.8614 (0.739 sec/step)\n","I0908 16:30:19.498627 140650862335872 learning.py:512] global step 4870: loss = 1.8614 (0.739 sec/step)\n","INFO:tensorflow:global step 4871: loss = 1.9492 (0.757 sec/step)\n","I0908 16:30:20.258009 140650862335872 learning.py:512] global step 4871: loss = 1.9492 (0.757 sec/step)\n","INFO:tensorflow:global step 4872: loss = 2.1084 (0.761 sec/step)\n","I0908 16:30:21.020807 140650862335872 learning.py:512] global step 4872: loss = 2.1084 (0.761 sec/step)\n","INFO:tensorflow:global step 4873: loss = 1.8905 (0.764 sec/step)\n","I0908 16:30:21.786514 140650862335872 learning.py:512] global step 4873: loss = 1.8905 (0.764 sec/step)\n","INFO:tensorflow:global step 4874: loss = 1.9411 (0.768 sec/step)\n","I0908 16:30:22.556361 140650862335872 learning.py:512] global step 4874: loss = 1.9411 (0.768 sec/step)\n","INFO:tensorflow:global step 4875: loss = 2.2559 (0.753 sec/step)\n","I0908 16:30:23.310628 140650862335872 learning.py:512] global step 4875: loss = 2.2559 (0.753 sec/step)\n","INFO:tensorflow:global step 4876: loss = 2.4081 (0.758 sec/step)\n","I0908 16:30:24.070270 140650862335872 learning.py:512] global step 4876: loss = 2.4081 (0.758 sec/step)\n","INFO:tensorflow:global step 4877: loss = 1.7772 (0.732 sec/step)\n","I0908 16:30:24.803758 140650862335872 learning.py:512] global step 4877: loss = 1.7772 (0.732 sec/step)\n","INFO:tensorflow:global step 4878: loss = 1.7964 (0.757 sec/step)\n","I0908 16:30:25.562766 140650862335872 learning.py:512] global step 4878: loss = 1.7964 (0.757 sec/step)\n","INFO:tensorflow:global step 4879: loss = 2.4928 (0.764 sec/step)\n","I0908 16:30:26.328702 140650862335872 learning.py:512] global step 4879: loss = 2.4928 (0.764 sec/step)\n","INFO:tensorflow:global step 4880: loss = 1.9125 (0.765 sec/step)\n","I0908 16:30:27.095750 140650862335872 learning.py:512] global step 4880: loss = 1.9125 (0.765 sec/step)\n","INFO:tensorflow:global step 4881: loss = 2.0163 (0.755 sec/step)\n","I0908 16:30:27.852664 140650862335872 learning.py:512] global step 4881: loss = 2.0163 (0.755 sec/step)\n","INFO:tensorflow:global step 4882: loss = 2.1560 (0.750 sec/step)\n","I0908 16:30:28.604991 140650862335872 learning.py:512] global step 4882: loss = 2.1560 (0.750 sec/step)\n","INFO:tensorflow:global step 4883: loss = 1.9943 (0.754 sec/step)\n","I0908 16:30:29.360408 140650862335872 learning.py:512] global step 4883: loss = 1.9943 (0.754 sec/step)\n","INFO:tensorflow:global step 4884: loss = 1.7357 (0.756 sec/step)\n","I0908 16:30:30.118477 140650862335872 learning.py:512] global step 4884: loss = 1.7357 (0.756 sec/step)\n","INFO:tensorflow:global step 4885: loss = 1.8922 (0.741 sec/step)\n","I0908 16:30:30.861079 140650862335872 learning.py:512] global step 4885: loss = 1.8922 (0.741 sec/step)\n","INFO:tensorflow:global step 4886: loss = 1.8701 (0.777 sec/step)\n","I0908 16:30:31.640213 140650862335872 learning.py:512] global step 4886: loss = 1.8701 (0.777 sec/step)\n","INFO:tensorflow:global step 4887: loss = 2.2733 (0.771 sec/step)\n","I0908 16:30:32.413037 140650862335872 learning.py:512] global step 4887: loss = 2.2733 (0.771 sec/step)\n","INFO:tensorflow:global step 4888: loss = 1.8471 (0.759 sec/step)\n","I0908 16:30:33.174115 140650862335872 learning.py:512] global step 4888: loss = 1.8471 (0.759 sec/step)\n","INFO:tensorflow:global step 4889: loss = 1.9533 (0.740 sec/step)\n","I0908 16:30:33.915647 140650862335872 learning.py:512] global step 4889: loss = 1.9533 (0.740 sec/step)\n","INFO:tensorflow:global step 4890: loss = 1.9985 (0.738 sec/step)\n","I0908 16:30:34.655461 140650862335872 learning.py:512] global step 4890: loss = 1.9985 (0.738 sec/step)\n","INFO:tensorflow:global step 4891: loss = 1.8660 (0.767 sec/step)\n","I0908 16:30:35.424931 140650862335872 learning.py:512] global step 4891: loss = 1.8660 (0.767 sec/step)\n","INFO:tensorflow:global step 4892: loss = 1.5551 (0.764 sec/step)\n","I0908 16:30:36.190967 140650862335872 learning.py:512] global step 4892: loss = 1.5551 (0.764 sec/step)\n","INFO:tensorflow:global step 4893: loss = 1.8616 (0.768 sec/step)\n","I0908 16:30:36.960320 140650862335872 learning.py:512] global step 4893: loss = 1.8616 (0.768 sec/step)\n","INFO:tensorflow:global step 4894: loss = 2.1687 (0.769 sec/step)\n","I0908 16:30:37.731758 140650862335872 learning.py:512] global step 4894: loss = 2.1687 (0.769 sec/step)\n","INFO:tensorflow:global step 4895: loss = 2.0643 (0.765 sec/step)\n","I0908 16:30:38.498705 140650862335872 learning.py:512] global step 4895: loss = 2.0643 (0.765 sec/step)\n","INFO:tensorflow:global step 4896: loss = 2.1806 (0.750 sec/step)\n","I0908 16:30:39.250561 140650862335872 learning.py:512] global step 4896: loss = 2.1806 (0.750 sec/step)\n","INFO:tensorflow:global step 4897: loss = 2.0422 (0.779 sec/step)\n","I0908 16:30:40.031906 140650862335872 learning.py:512] global step 4897: loss = 2.0422 (0.779 sec/step)\n","INFO:tensorflow:global step 4898: loss = 1.7852 (0.766 sec/step)\n","I0908 16:30:40.799758 140650862335872 learning.py:512] global step 4898: loss = 1.7852 (0.766 sec/step)\n","INFO:tensorflow:global step 4899: loss = 2.4083 (0.786 sec/step)\n","I0908 16:30:41.587439 140650862335872 learning.py:512] global step 4899: loss = 2.4083 (0.786 sec/step)\n","INFO:tensorflow:global step 4900: loss = 1.9812 (0.778 sec/step)\n","I0908 16:30:42.367094 140650862335872 learning.py:512] global step 4900: loss = 1.9812 (0.778 sec/step)\n","INFO:tensorflow:global step 4901: loss = 2.2943 (0.756 sec/step)\n","I0908 16:30:43.125445 140650862335872 learning.py:512] global step 4901: loss = 2.2943 (0.756 sec/step)\n","INFO:tensorflow:global step 4902: loss = 2.0500 (0.778 sec/step)\n","I0908 16:30:43.905593 140650862335872 learning.py:512] global step 4902: loss = 2.0500 (0.778 sec/step)\n","INFO:tensorflow:global step 4903: loss = 2.2764 (0.762 sec/step)\n","I0908 16:30:44.669960 140650862335872 learning.py:512] global step 4903: loss = 2.2764 (0.762 sec/step)\n","INFO:tensorflow:global step 4904: loss = 2.3825 (0.746 sec/step)\n","I0908 16:30:45.417696 140650862335872 learning.py:512] global step 4904: loss = 2.3825 (0.746 sec/step)\n","INFO:tensorflow:global step 4905: loss = 1.7310 (0.771 sec/step)\n","I0908 16:30:46.191160 140650862335872 learning.py:512] global step 4905: loss = 1.7310 (0.771 sec/step)\n","INFO:tensorflow:global step 4906: loss = 1.8994 (0.755 sec/step)\n","I0908 16:30:46.948259 140650862335872 learning.py:512] global step 4906: loss = 1.8994 (0.755 sec/step)\n","INFO:tensorflow:global step 4907: loss = 2.1831 (0.757 sec/step)\n","I0908 16:30:47.707541 140650862335872 learning.py:512] global step 4907: loss = 2.1831 (0.757 sec/step)\n","INFO:tensorflow:global step 4908: loss = 2.0050 (0.765 sec/step)\n","I0908 16:30:48.474808 140650862335872 learning.py:512] global step 4908: loss = 2.0050 (0.765 sec/step)\n","INFO:tensorflow:global step 4909: loss = 1.9334 (0.765 sec/step)\n","I0908 16:30:49.241753 140650862335872 learning.py:512] global step 4909: loss = 1.9334 (0.765 sec/step)\n","INFO:tensorflow:global step 4910: loss = 1.9364 (0.756 sec/step)\n","I0908 16:30:49.999145 140650862335872 learning.py:512] global step 4910: loss = 1.9364 (0.756 sec/step)\n","INFO:tensorflow:global step 4911: loss = 2.4086 (0.746 sec/step)\n","I0908 16:30:50.746629 140650862335872 learning.py:512] global step 4911: loss = 2.4086 (0.746 sec/step)\n","INFO:tensorflow:global step 4912: loss = 2.1587 (0.771 sec/step)\n","I0908 16:30:51.519780 140650862335872 learning.py:512] global step 4912: loss = 2.1587 (0.771 sec/step)\n","INFO:tensorflow:global step 4913: loss = 1.6925 (0.770 sec/step)\n","I0908 16:30:52.291307 140650862335872 learning.py:512] global step 4913: loss = 1.6925 (0.770 sec/step)\n","INFO:tensorflow:global step 4914: loss = 2.2918 (0.774 sec/step)\n","I0908 16:30:53.067212 140650862335872 learning.py:512] global step 4914: loss = 2.2918 (0.774 sec/step)\n","INFO:tensorflow:global step 4915: loss = 2.3910 (0.760 sec/step)\n","I0908 16:30:53.829694 140650862335872 learning.py:512] global step 4915: loss = 2.3910 (0.760 sec/step)\n","INFO:tensorflow:global step 4916: loss = 2.2390 (0.754 sec/step)\n","I0908 16:30:54.585881 140650862335872 learning.py:512] global step 4916: loss = 2.2390 (0.754 sec/step)\n","INFO:tensorflow:global step 4917: loss = 2.5963 (0.777 sec/step)\n","I0908 16:30:55.364505 140650862335872 learning.py:512] global step 4917: loss = 2.5963 (0.777 sec/step)\n","INFO:tensorflow:global step 4918: loss = 2.2033 (0.762 sec/step)\n","I0908 16:30:56.128309 140650862335872 learning.py:512] global step 4918: loss = 2.2033 (0.762 sec/step)\n","INFO:tensorflow:global step 4919: loss = 2.1050 (0.780 sec/step)\n","I0908 16:30:56.910665 140650862335872 learning.py:512] global step 4919: loss = 2.1050 (0.780 sec/step)\n","INFO:tensorflow:global step 4920: loss = 3.2343 (0.742 sec/step)\n","I0908 16:30:57.654707 140650862335872 learning.py:512] global step 4920: loss = 3.2343 (0.742 sec/step)\n","INFO:tensorflow:global step 4921: loss = 2.0623 (0.779 sec/step)\n","I0908 16:30:58.435713 140650862335872 learning.py:512] global step 4921: loss = 2.0623 (0.779 sec/step)\n","INFO:tensorflow:global step 4922: loss = 2.1661 (0.778 sec/step)\n","I0908 16:30:59.215413 140650862335872 learning.py:512] global step 4922: loss = 2.1661 (0.778 sec/step)\n","INFO:tensorflow:global step 4923: loss = 2.0755 (0.758 sec/step)\n","I0908 16:30:59.974886 140650862335872 learning.py:512] global step 4923: loss = 2.0755 (0.758 sec/step)\n","INFO:tensorflow:global step 4924: loss = 2.2536 (0.764 sec/step)\n","I0908 16:31:00.740736 140650862335872 learning.py:512] global step 4924: loss = 2.2536 (0.764 sec/step)\n","INFO:tensorflow:global step 4925: loss = 1.6385 (0.767 sec/step)\n","I0908 16:31:01.509644 140650862335872 learning.py:512] global step 4925: loss = 1.6385 (0.767 sec/step)\n","INFO:tensorflow:global step 4926: loss = 2.2456 (0.724 sec/step)\n","I0908 16:31:02.234926 140650862335872 learning.py:512] global step 4926: loss = 2.2456 (0.724 sec/step)\n","INFO:tensorflow:global step 4927: loss = 1.9454 (0.761 sec/step)\n","I0908 16:31:02.997132 140650862335872 learning.py:512] global step 4927: loss = 1.9454 (0.761 sec/step)\n","INFO:tensorflow:global step 4928: loss = 1.9640 (0.767 sec/step)\n","I0908 16:31:03.766218 140650862335872 learning.py:512] global step 4928: loss = 1.9640 (0.767 sec/step)\n","INFO:tensorflow:global step 4929: loss = 2.0317 (0.759 sec/step)\n","I0908 16:31:04.526616 140650862335872 learning.py:512] global step 4929: loss = 2.0317 (0.759 sec/step)\n","INFO:tensorflow:global step 4930: loss = 2.2174 (0.740 sec/step)\n","I0908 16:31:05.268269 140650862335872 learning.py:512] global step 4930: loss = 2.2174 (0.740 sec/step)\n","INFO:tensorflow:global step 4931: loss = 2.5814 (0.771 sec/step)\n","I0908 16:31:06.040465 140650862335872 learning.py:512] global step 4931: loss = 2.5814 (0.771 sec/step)\n","INFO:tensorflow:global step 4932: loss = 2.3160 (0.756 sec/step)\n","I0908 16:31:06.798041 140650862335872 learning.py:512] global step 4932: loss = 2.3160 (0.756 sec/step)\n","INFO:tensorflow:global step 4933: loss = 1.8378 (0.755 sec/step)\n","I0908 16:31:07.555110 140650862335872 learning.py:512] global step 4933: loss = 1.8378 (0.755 sec/step)\n","INFO:tensorflow:global step 4934: loss = 2.0239 (0.743 sec/step)\n","I0908 16:31:08.300456 140650862335872 learning.py:512] global step 4934: loss = 2.0239 (0.743 sec/step)\n","INFO:tensorflow:global step 4935: loss = 1.6799 (0.750 sec/step)\n","I0908 16:31:09.052527 140650862335872 learning.py:512] global step 4935: loss = 1.6799 (0.750 sec/step)\n","INFO:tensorflow:global step 4936: loss = 1.8628 (0.767 sec/step)\n","I0908 16:31:09.820718 140650862335872 learning.py:512] global step 4936: loss = 1.8628 (0.767 sec/step)\n","INFO:tensorflow:global step 4937: loss = 2.4331 (0.751 sec/step)\n","I0908 16:31:10.573320 140650862335872 learning.py:512] global step 4937: loss = 2.4331 (0.751 sec/step)\n","INFO:tensorflow:global step 4938: loss = 1.9996 (0.751 sec/step)\n","I0908 16:31:11.325789 140650862335872 learning.py:512] global step 4938: loss = 1.9996 (0.751 sec/step)\n","INFO:tensorflow:global step 4939: loss = 2.0724 (0.763 sec/step)\n","I0908 16:31:12.090672 140650862335872 learning.py:512] global step 4939: loss = 2.0724 (0.763 sec/step)\n","INFO:tensorflow:global step 4940: loss = 1.8953 (0.782 sec/step)\n","I0908 16:31:12.873884 140650862335872 learning.py:512] global step 4940: loss = 1.8953 (0.782 sec/step)\n","INFO:tensorflow:global step 4941: loss = 2.1681 (0.746 sec/step)\n","I0908 16:31:13.621867 140650862335872 learning.py:512] global step 4941: loss = 2.1681 (0.746 sec/step)\n","INFO:tensorflow:global step 4942: loss = 1.6625 (0.771 sec/step)\n","I0908 16:31:14.394830 140650862335872 learning.py:512] global step 4942: loss = 1.6625 (0.771 sec/step)\n","INFO:tensorflow:global step 4943: loss = 2.1349 (0.776 sec/step)\n","I0908 16:31:15.172344 140650862335872 learning.py:512] global step 4943: loss = 2.1349 (0.776 sec/step)\n","INFO:tensorflow:global step 4944: loss = 1.9296 (0.791 sec/step)\n","I0908 16:31:15.964973 140650862335872 learning.py:512] global step 4944: loss = 1.9296 (0.791 sec/step)\n","INFO:tensorflow:global step 4945: loss = 1.8476 (0.759 sec/step)\n","I0908 16:31:16.725636 140650862335872 learning.py:512] global step 4945: loss = 1.8476 (0.759 sec/step)\n","INFO:tensorflow:global step 4946: loss = 2.0356 (0.759 sec/step)\n","I0908 16:31:17.486142 140650862335872 learning.py:512] global step 4946: loss = 2.0356 (0.759 sec/step)\n","INFO:tensorflow:global step 4947: loss = 2.2142 (0.780 sec/step)\n","I0908 16:31:18.267703 140650862335872 learning.py:512] global step 4947: loss = 2.2142 (0.780 sec/step)\n","INFO:tensorflow:global step 4948: loss = 1.6808 (0.766 sec/step)\n","I0908 16:31:19.035285 140650862335872 learning.py:512] global step 4948: loss = 1.6808 (0.766 sec/step)\n","INFO:tensorflow:global step 4949: loss = 2.0919 (0.743 sec/step)\n","I0908 16:31:19.779594 140650862335872 learning.py:512] global step 4949: loss = 2.0919 (0.743 sec/step)\n","INFO:tensorflow:global step 4950: loss = 1.7555 (0.748 sec/step)\n","I0908 16:31:20.529484 140650862335872 learning.py:512] global step 4950: loss = 1.7555 (0.748 sec/step)\n","INFO:tensorflow:global step 4951: loss = 1.8424 (0.782 sec/step)\n","I0908 16:31:21.313424 140650862335872 learning.py:512] global step 4951: loss = 1.8424 (0.782 sec/step)\n","INFO:tensorflow:global step 4952: loss = 1.7751 (0.762 sec/step)\n","I0908 16:31:22.076860 140650862335872 learning.py:512] global step 4952: loss = 1.7751 (0.762 sec/step)\n","INFO:tensorflow:global step 4953: loss = 1.5442 (0.728 sec/step)\n","I0908 16:31:22.806799 140650862335872 learning.py:512] global step 4953: loss = 1.5442 (0.728 sec/step)\n","INFO:tensorflow:global step 4954: loss = 2.2826 (0.747 sec/step)\n","I0908 16:31:23.555483 140650862335872 learning.py:512] global step 4954: loss = 2.2826 (0.747 sec/step)\n","INFO:tensorflow:global step 4955: loss = 1.6626 (0.775 sec/step)\n","I0908 16:31:24.332453 140650862335872 learning.py:512] global step 4955: loss = 1.6626 (0.775 sec/step)\n","INFO:tensorflow:global step 4956: loss = 2.1880 (0.737 sec/step)\n","I0908 16:31:25.070927 140650862335872 learning.py:512] global step 4956: loss = 2.1880 (0.737 sec/step)\n","INFO:tensorflow:global step 4957: loss = 1.6802 (0.736 sec/step)\n","I0908 16:31:25.808643 140650862335872 learning.py:512] global step 4957: loss = 1.6802 (0.736 sec/step)\n","INFO:tensorflow:global step 4958: loss = 2.4969 (0.759 sec/step)\n","I0908 16:31:26.569661 140650862335872 learning.py:512] global step 4958: loss = 2.4969 (0.759 sec/step)\n","INFO:tensorflow:global step 4959: loss = 1.6832 (0.761 sec/step)\n","I0908 16:31:27.332035 140650862335872 learning.py:512] global step 4959: loss = 1.6832 (0.761 sec/step)\n","INFO:tensorflow:global step 4960: loss = 2.1238 (0.750 sec/step)\n","I0908 16:31:28.083718 140650862335872 learning.py:512] global step 4960: loss = 2.1238 (0.750 sec/step)\n","INFO:tensorflow:global step 4961: loss = 1.8880 (0.761 sec/step)\n","I0908 16:31:28.846439 140650862335872 learning.py:512] global step 4961: loss = 1.8880 (0.761 sec/step)\n","INFO:tensorflow:global step 4962: loss = 1.9078 (0.768 sec/step)\n","I0908 16:31:29.616399 140650862335872 learning.py:512] global step 4962: loss = 1.9078 (0.768 sec/step)\n","INFO:tensorflow:global step 4963: loss = 2.1240 (0.774 sec/step)\n","I0908 16:31:30.391686 140650862335872 learning.py:512] global step 4963: loss = 2.1240 (0.774 sec/step)\n","INFO:tensorflow:global step 4964: loss = 1.7517 (0.761 sec/step)\n","I0908 16:31:31.154807 140650862335872 learning.py:512] global step 4964: loss = 1.7517 (0.761 sec/step)\n","INFO:tensorflow:global step 4965: loss = 1.7128 (0.759 sec/step)\n","I0908 16:31:31.915292 140650862335872 learning.py:512] global step 4965: loss = 1.7128 (0.759 sec/step)\n","INFO:tensorflow:global step 4966: loss = 2.1093 (0.749 sec/step)\n","I0908 16:31:32.666178 140650862335872 learning.py:512] global step 4966: loss = 2.1093 (0.749 sec/step)\n","INFO:tensorflow:global step 4967: loss = 1.9793 (0.765 sec/step)\n","I0908 16:31:33.432503 140650862335872 learning.py:512] global step 4967: loss = 1.9793 (0.765 sec/step)\n","INFO:tensorflow:global step 4968: loss = 1.8453 (0.750 sec/step)\n","I0908 16:31:34.184746 140650862335872 learning.py:512] global step 4968: loss = 1.8453 (0.750 sec/step)\n","INFO:tensorflow:global step 4969: loss = 2.2781 (0.745 sec/step)\n","I0908 16:31:34.931606 140650862335872 learning.py:512] global step 4969: loss = 2.2781 (0.745 sec/step)\n","INFO:tensorflow:global step 4970: loss = 2.3281 (0.738 sec/step)\n","I0908 16:31:35.671719 140650862335872 learning.py:512] global step 4970: loss = 2.3281 (0.738 sec/step)\n","INFO:tensorflow:global step 4971: loss = 2.5524 (0.746 sec/step)\n","I0908 16:31:36.418999 140650862335872 learning.py:512] global step 4971: loss = 2.5524 (0.746 sec/step)\n","INFO:tensorflow:global step 4972: loss = 2.1768 (0.759 sec/step)\n","I0908 16:31:37.179842 140650862335872 learning.py:512] global step 4972: loss = 2.1768 (0.759 sec/step)\n","INFO:tensorflow:global step 4973: loss = 1.9394 (0.751 sec/step)\n","I0908 16:31:37.932476 140650862335872 learning.py:512] global step 4973: loss = 1.9394 (0.751 sec/step)\n","INFO:tensorflow:global step 4974: loss = 1.6276 (0.761 sec/step)\n","I0908 16:31:38.695397 140650862335872 learning.py:512] global step 4974: loss = 1.6276 (0.761 sec/step)\n","INFO:tensorflow:global step 4975: loss = 1.8730 (0.739 sec/step)\n","I0908 16:31:39.435636 140650862335872 learning.py:512] global step 4975: loss = 1.8730 (0.739 sec/step)\n","INFO:tensorflow:global step 4976: loss = 1.8529 (0.742 sec/step)\n","I0908 16:31:40.180011 140650862335872 learning.py:512] global step 4976: loss = 1.8529 (0.742 sec/step)\n","INFO:tensorflow:global step 4977: loss = 2.3177 (0.756 sec/step)\n","I0908 16:31:40.937345 140650862335872 learning.py:512] global step 4977: loss = 2.3177 (0.756 sec/step)\n","INFO:tensorflow:global step 4978: loss = 2.8680 (0.771 sec/step)\n","I0908 16:31:41.709627 140650862335872 learning.py:512] global step 4978: loss = 2.8680 (0.771 sec/step)\n","INFO:tensorflow:global step 4979: loss = 2.3181 (0.756 sec/step)\n","I0908 16:31:42.467036 140650862335872 learning.py:512] global step 4979: loss = 2.3181 (0.756 sec/step)\n","INFO:tensorflow:global step 4980: loss = 1.6592 (0.759 sec/step)\n","I0908 16:31:43.227115 140650862335872 learning.py:512] global step 4980: loss = 1.6592 (0.759 sec/step)\n","INFO:tensorflow:global step 4981: loss = 1.7014 (0.759 sec/step)\n","I0908 16:31:43.987943 140650862335872 learning.py:512] global step 4981: loss = 1.7014 (0.759 sec/step)\n","INFO:tensorflow:global step 4982: loss = 1.7388 (0.772 sec/step)\n","I0908 16:31:44.761360 140650862335872 learning.py:512] global step 4982: loss = 1.7388 (0.772 sec/step)\n","INFO:tensorflow:global step 4983: loss = 2.2749 (0.750 sec/step)\n","I0908 16:31:45.512900 140650862335872 learning.py:512] global step 4983: loss = 2.2749 (0.750 sec/step)\n","INFO:tensorflow:global step 4984: loss = 2.2224 (0.789 sec/step)\n","I0908 16:31:46.307199 140650862335872 learning.py:512] global step 4984: loss = 2.2224 (0.789 sec/step)\n","INFO:tensorflow:global step 4985: loss = 1.9490 (1.324 sec/step)\n","I0908 16:31:47.633618 140650862335872 learning.py:512] global step 4985: loss = 1.9490 (1.324 sec/step)\n","INFO:tensorflow:Recording summary at step 4985.\n","I0908 16:31:47.635695 140646941251328 supervisor.py:1050] Recording summary at step 4985.\n","INFO:tensorflow:global step 4986: loss = 1.7459 (0.758 sec/step)\n","I0908 16:31:48.393347 140650862335872 learning.py:512] global step 4986: loss = 1.7459 (0.758 sec/step)\n","INFO:tensorflow:global step 4987: loss = 2.1468 (0.744 sec/step)\n","I0908 16:31:49.139356 140650862335872 learning.py:512] global step 4987: loss = 2.1468 (0.744 sec/step)\n","INFO:tensorflow:global step 4988: loss = 1.6344 (0.753 sec/step)\n","I0908 16:31:49.893943 140650862335872 learning.py:512] global step 4988: loss = 1.6344 (0.753 sec/step)\n","INFO:tensorflow:global step 4989: loss = 2.0227 (0.770 sec/step)\n","I0908 16:31:50.665923 140650862335872 learning.py:512] global step 4989: loss = 2.0227 (0.770 sec/step)\n","INFO:tensorflow:global step 4990: loss = 2.1237 (0.759 sec/step)\n","I0908 16:31:51.426508 140650862335872 learning.py:512] global step 4990: loss = 2.1237 (0.759 sec/step)\n","INFO:tensorflow:global step 4991: loss = 1.7794 (0.762 sec/step)\n","I0908 16:31:52.190158 140650862335872 learning.py:512] global step 4991: loss = 1.7794 (0.762 sec/step)\n","INFO:tensorflow:global step 4992: loss = 1.7550 (0.754 sec/step)\n","I0908 16:31:52.946505 140650862335872 learning.py:512] global step 4992: loss = 1.7550 (0.754 sec/step)\n","INFO:tensorflow:global step 4993: loss = 2.1309 (0.754 sec/step)\n","I0908 16:31:53.702483 140650862335872 learning.py:512] global step 4993: loss = 2.1309 (0.754 sec/step)\n","INFO:tensorflow:global step 4994: loss = 2.1144 (0.772 sec/step)\n","I0908 16:31:54.475961 140650862335872 learning.py:512] global step 4994: loss = 2.1144 (0.772 sec/step)\n","INFO:tensorflow:global step 4995: loss = 1.9733 (0.748 sec/step)\n","I0908 16:31:55.225649 140650862335872 learning.py:512] global step 4995: loss = 1.9733 (0.748 sec/step)\n","INFO:tensorflow:global step 4996: loss = 2.5382 (0.744 sec/step)\n","I0908 16:31:55.971719 140650862335872 learning.py:512] global step 4996: loss = 2.5382 (0.744 sec/step)\n","INFO:tensorflow:global step 4997: loss = 2.1059 (0.778 sec/step)\n","I0908 16:31:56.751096 140650862335872 learning.py:512] global step 4997: loss = 2.1059 (0.778 sec/step)\n","INFO:tensorflow:global step 4998: loss = 1.7450 (0.758 sec/step)\n","I0908 16:31:57.510761 140650862335872 learning.py:512] global step 4998: loss = 1.7450 (0.758 sec/step)\n","INFO:tensorflow:global step 4999: loss = 2.2149 (0.748 sec/step)\n","I0908 16:31:58.260357 140650862335872 learning.py:512] global step 4999: loss = 2.2149 (0.748 sec/step)\n","INFO:tensorflow:global step 5000: loss = 1.9787 (0.754 sec/step)\n","I0908 16:31:59.016317 140650862335872 learning.py:512] global step 5000: loss = 1.9787 (0.754 sec/step)\n","INFO:tensorflow:Stopping Training.\n","I0908 16:31:59.017054 140650862335872 learning.py:769] Stopping Training.\n","INFO:tensorflow:Finished training! Saving model to disk.\n","I0908 16:31:59.017286 140650862335872 learning.py:777] Finished training! Saving model to disk.\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/summary/writer/writer.py:386: UserWarning: Attempting to use a closed FileWriter. The operation will be a noop unless the FileWriter is explicitly reopened.\n","  warnings.warn(\"Attempting to use a closed FileWriter. \"\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"YtCKVr_TiTm6","colab_type":"text"},"source":["## Export trained model :"]},{"cell_type":"code","metadata":{"id":"6CbBvlKlidez","colab_type":"code","colab":{}},"source":["#Identify the latest trained model\n","lst = os.listdir('/root/models/trained_v2')\n","lf = filter(lambda k: 'model.ckpt-' in k, lst)\n","last_model = sorted(lf)[-1].replace('.meta', '')\n","os.environ['last_model']=last_model\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aE-ZPXHdauRl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1599583043970,"user_tz":-60,"elapsed":919,"user":{"displayName":"Hazem Barka","photoUrl":"","userId":"05856545852072919715"}},"outputId":"31fde523-be86-4109-a7d9-7602a9a1b204"},"source":["last_model"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'model.ckpt-5000'"]},"metadata":{"tags":[]},"execution_count":106}]},{"cell_type":"code","metadata":{"id":"ZW_znymFKGcY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1599583103963,"user_tz":-60,"elapsed":31799,"user":{"displayName":"Hazem Barka","photoUrl":"","userId":"05856545852072919715"}},"outputId":"9770866d-fbbf-40a9-cb8a-98c45f522ce1"},"source":["!mkdir '/root/drive/My Drive/RGB-D Hand detector/inference_graph_hand_RGBD_v2'\n","# Export trained model\n","!python /root/models/research/object_detection/export_inference_graph.py \\\n","    --input_type=image_tensor \\\n","    --pipeline_config_path=/root/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config \\\n","    --output_directory='/root/drive/My Drive/RGB-D Hand detector/inference_graph_hand_RGBD_v2' \\\n","    --trained_checkpoint_prefix='/root/models/trained_v2/'$last_model"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002c4b208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002c4b208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:00.438062 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002c4b208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002c4b208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002c4bc88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002c4bc88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:00.473316 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002c4bc88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002c4bc88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002b75588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002b75588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:00.519539 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002b75588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002b75588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002b62a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002b62a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:00.592091 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002b62a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002b62a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002b7d048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002b7d048>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:00.626082 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002b7d048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002b7d048>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002b7d9b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002b7d9b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:00.699559 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002b7d9b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002b7d9b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002bdb0f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002bdb0f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:00.735213 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002bdb0f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002bdb0f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002ba1208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002ba1208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:00.787877 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002ba1208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002ba1208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002b7d320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002b7d320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:00.863730 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002b7d320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002b7d320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002bdb5f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002bdb5f8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:00.899693 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002bdb5f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002bdb5f8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002bbf048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002bbf048>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:00.975956 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002bbf048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002bbf048>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40029bbf60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40029bbf60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:01.010671 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40029bbf60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40029bbf60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40029bbf28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40029bbf28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:01.058120 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40029bbf28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40029bbf28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002a2eeb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002a2eeb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:01.131347 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002a2eeb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002a2eeb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002bdbda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002bdbda0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:01.166807 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002bdbda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002bdbda0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002946ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002946ba8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:01.241883 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002946ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002946ba8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002895e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002895e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:01.275705 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002895e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002895e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002913c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002913c88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:01.322624 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002913c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002913c88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002a0c588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002a0c588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:01.396886 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002a0c588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002a0c588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002b7d898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002b7d898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:01.431133 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002b7d898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002b7d898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002913a20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002913a20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:01.507836 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002913a20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002913a20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40027954a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40027954a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:01.543391 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40027954a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40027954a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40027fb128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40027fb128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:01.590314 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40027fb128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40027fb128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f400282cf60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f400282cf60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:01.662111 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f400282cf60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f400282cf60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002810080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002810080>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:01.696024 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002810080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002810080>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f400278b2e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f400278b2e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:01.777536 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f400278b2e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f400278b2e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002a0c8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002a0c8d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:01.813362 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002a0c8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002a0c8d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40026fc3c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40026fc3c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:01.862201 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40026fc3c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40026fc3c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002a0c208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002a0c208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:01.937673 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002a0c208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002a0c208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002913d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002913d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:02.083529 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002913d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002913d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f400264d5c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f400264d5c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:02.161535 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f400264d5c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f400264d5c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002895ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002895ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:02.196875 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002895ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002895ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40025699e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40025699e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:02.246074 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40025699e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40025699e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f400264d5c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f400264d5c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:02.320192 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f400264d5c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f400264d5c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002612828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002612828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:02.357212 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002612828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002612828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002579438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002579438>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:02.434182 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002579438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002579438>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40027fb4a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40027fb4a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:02.468482 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40027fb4a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40027fb4a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40024598d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40024598d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:02.515708 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40024598d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40024598d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002579978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002579978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:02.592885 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002579978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002579978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002736ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002736ac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:02.630446 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002736ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002736ac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40023d8cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40023d8cf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:02.706789 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40023d8cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40023d8cf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40026fca58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40026fca58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:02.741627 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40026fca58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40026fca58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f400248eeb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f400248eeb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:02.794894 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f400248eeb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f400248eeb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f400250a3c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f400250a3c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:02.870889 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f400250a3c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f400250a3c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002612a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002612a58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:02.906842 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002612a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002612a58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40023243c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40023243c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:02.984908 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40023243c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40023243c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40022efbe0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40022efbe0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:03.019789 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40022efbe0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40022efbe0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40022c5240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40022c5240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:03.074014 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40022c5240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40022c5240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40022d2e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40022d2e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:03.147146 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40022d2e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40022d2e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002b717b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002b717b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:03.181618 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002b717b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002b717b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002282f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002282f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:03.258618 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002282f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002282f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f400250a470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f400250a470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:03.294966 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f400250a470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f400250a470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002150a20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002150a20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:03.342228 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002150a20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002150a20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40025769e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40025769e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:03.418178 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40025769e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40025769e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f400248ed30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f400248ed30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:03.453216 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f400248ed30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f400248ed30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40021ab710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40021ab710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:03.527843 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40021ab710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40021ab710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f400238fe10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f400238fe10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:03.565641 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f400238fe10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f400238fe10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002129a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002129a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:03.612574 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002129a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002129a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002148668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002148668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:03.689311 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002148668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002148668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002339f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002339f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:03.722832 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002339f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002339f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40021103c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40021103c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:03.800695 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40021103c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40021103c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40022ef9b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40022ef9b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:03.836617 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40022ef9b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40022ef9b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f400208d898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f400208d898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:03.884688 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f400208d898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f400208d898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001ffe240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001ffe240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:03.959475 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001ffe240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001ffe240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40022230b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40022230b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:03.994647 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40022230b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40022230b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001f24198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001f24198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:04.081020 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001f24198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001f24198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001f3c160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001f3c160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:04.115231 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001f3c160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001f3c160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001f8ab70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001f8ab70>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:04.164292 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001f8ab70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001f8ab70>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001ef8160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001ef8160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:04.239581 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001ef8160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001ef8160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002110b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002110b38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:04.275329 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002110b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002110b38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001e22400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001e22400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:04.352353 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001e22400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001e22400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001e84e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001e84e48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:04.387624 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001e84e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001e84e48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001df65f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001df65f8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:04.434239 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001df65f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001df65f8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001e223c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001e223c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:04.509113 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001e223c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001e223c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001d202b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001d202b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:04.541968 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001d202b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001d202b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001d20748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001d20748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:04.615065 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001d20748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001d20748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001fd5978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001fd5978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:04.649949 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001fd5978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001fd5978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001ca72e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001ca72e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:04.817149 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001ca72e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001ca72e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001d20400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001d20400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:04.894973 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001d20400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001d20400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002569668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002569668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:04.928998 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002569668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002569668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f400354a5c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f400354a5c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:05.004958 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f400354a5c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f400354a5c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001bf3ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001bf3ac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:05.039001 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001bf3ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001bf3ac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001c0d208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001c0d208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:05.088938 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001c0d208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001c0d208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002553f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002553f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:05.161839 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002553f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002553f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001e35668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001e35668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:05.197111 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001e35668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001e35668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f400278beb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f400278beb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:05.272367 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f400278beb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f400278beb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001df60f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001df60f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:05.316775 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001df60f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001df60f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002cba978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002cba978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:05.397982 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002cba978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002cba978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001ed3588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001ed3588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:05.433159 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001ed3588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001ed3588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002cbab38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002cbab38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:05.506279 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002cbab38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002cbab38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001b8a5f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001b8a5f8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:05.539444 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001b8a5f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001b8a5f8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002cba4a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002cba4a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:05.610661 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002cba4a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002cba4a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002b752b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002b752b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:05.645162 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002b752b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4002b752b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001e35be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001e35be0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:05.720431 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001e35be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001e35be0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001a898d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001a898d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:05.757096 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001a898d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001a898d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001a59cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001a59cf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:05.830667 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001a59cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001a59cf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40019b3f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40019b3f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:05.871125 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40019b3f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40019b3f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002c35940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002c35940>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:05.946420 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002c35940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002c35940>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001b044a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001b044a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:05.982645 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001b044a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001b044a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002b754e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002b754e0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:06.055897 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002b754e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4002b754e0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40018ce9b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40018ce9b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:06.094183 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40018ce9b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f40018ce9b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001b044a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001b044a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:06.168729 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001b044a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001b044a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001998f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001998f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:06.204471 139914780792704 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001998f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f4001998f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0908 16:38:06.971768 139914780792704 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40012e5ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40012e5ac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:07.049949 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40012e5ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40012e5ac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40012e5ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40012e5ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:07.140751 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40012e5ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40012e5ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0908 16:38:07.149765 139914780792704 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40012f19b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40012f19b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:07.226944 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40012f19b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40012f19b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40012fc6a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40012fc6a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:07.311463 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40012fc6a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40012fc6a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0908 16:38:07.321235 139914780792704 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001944ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001944ac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:07.398706 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001944ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001944ac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f400125af60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f400125af60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:07.484316 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f400125af60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f400125af60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0908 16:38:07.493498 139914780792704 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40018a7dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40018a7dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:07.568233 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40018a7dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40018a7dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40011d9470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40011d9470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:07.656482 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40011d9470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40011d9470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0908 16:38:07.665822 139914780792704 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40011c2860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40011c2860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:07.744547 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40011c2860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40011c2860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40011c2860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40011c2860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:07.832778 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40011c2860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40011c2860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0908 16:38:07.842547 139914780792704 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40011379b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40011379b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:07.930319 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40011379b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f40011379b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001137d68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001137d68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","W0908 16:38:08.023009 139914780792704 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001137d68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4001137d68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:From /root/models/research/object_detection/core/post_processing.py:595: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0908 16:38:08.483672 139914780792704 deprecation.py:323] From /root/models/research/object_detection/core/post_processing.py:595: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /root/models/research/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_or_create_global_step\n","W0908 16:38:08.937788 139914780792704 deprecation.py:323] From /root/models/research/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_or_create_global_step\n","WARNING:tensorflow:From /root/models/research/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n","Instructions for updating:\n","Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n","W0908 16:38:08.942113 139914780792704 deprecation.py:323] From /root/models/research/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n","Instructions for updating:\n","Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n","W0908 16:38:08.942750 139914780792704 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n","151 ops no flops stats due to incomplete shapes.\n","Parsing Inputs...\n","Incomplete shape.\n","\n","=========================Options=============================\n","-max_depth                  10000\n","-min_bytes                  0\n","-min_peak_bytes             0\n","-min_residual_bytes         0\n","-min_output_bytes           0\n","-min_micros                 0\n","-min_accelerator_micros     0\n","-min_cpu_micros             0\n","-min_params                 0\n","-min_float_ops              0\n","-min_occurrence             0\n","-step                       -1\n","-order_by                   name\n","-account_type_regexes       _trainable_variables\n","-start_name_regexes         .*\n","-trim_name_regexes          .*BatchNorm.*\n","-show_name_regexes          .*\n","-hide_name_regexes          \n","-account_displayed_op_only  true\n","-select                     params\n","-output                     stdout:\n","\n","==================Model Analysis Report======================\n","Incomplete shape.\n","\n","Doc:\n","scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n","param: Number of parameters (in the Variable).\n","\n","Profile:\n","node name | # parameters\n","_TFProfRoot (--/4.57m params)\n","  BoxPredictor_0 (--/10.39k params)\n","    BoxPredictor_0/BoxEncodingPredictor (--/6.92k params)\n","      BoxPredictor_0/BoxEncodingPredictor/biases (12, 12/12 params)\n","      BoxPredictor_0/BoxEncodingPredictor/weights (1x1x576x12, 6.91k/6.91k params)\n","    BoxPredictor_0/ClassPredictor (--/3.46k params)\n","      BoxPredictor_0/ClassPredictor/biases (6, 6/6 params)\n","      BoxPredictor_0/ClassPredictor/weights (1x1x576x6, 3.46k/3.46k params)\n","  BoxPredictor_1 (--/46.12k params)\n","    BoxPredictor_1/BoxEncodingPredictor (--/30.74k params)\n","      BoxPredictor_1/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_1/BoxEncodingPredictor/weights (1x1x1280x24, 30.72k/30.72k params)\n","    BoxPredictor_1/ClassPredictor (--/15.37k params)\n","      BoxPredictor_1/ClassPredictor/biases (12, 12/12 params)\n","      BoxPredictor_1/ClassPredictor/weights (1x1x1280x12, 15.36k/15.36k params)\n","  BoxPredictor_2 (--/18.47k params)\n","    BoxPredictor_2/BoxEncodingPredictor (--/12.31k params)\n","      BoxPredictor_2/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_2/BoxEncodingPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n","    BoxPredictor_2/ClassPredictor (--/6.16k params)\n","      BoxPredictor_2/ClassPredictor/biases (12, 12/12 params)\n","      BoxPredictor_2/ClassPredictor/weights (1x1x512x12, 6.14k/6.14k params)\n","  BoxPredictor_3 (--/9.25k params)\n","    BoxPredictor_3/BoxEncodingPredictor (--/6.17k params)\n","      BoxPredictor_3/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_3/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n","    BoxPredictor_3/ClassPredictor (--/3.08k params)\n","      BoxPredictor_3/ClassPredictor/biases (12, 12/12 params)\n","      BoxPredictor_3/ClassPredictor/weights (1x1x256x12, 3.07k/3.07k params)\n","  BoxPredictor_4 (--/9.25k params)\n","    BoxPredictor_4/BoxEncodingPredictor (--/6.17k params)\n","      BoxPredictor_4/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_4/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n","    BoxPredictor_4/ClassPredictor (--/3.08k params)\n","      BoxPredictor_4/ClassPredictor/biases (12, 12/12 params)\n","      BoxPredictor_4/ClassPredictor/weights (1x1x256x12, 3.07k/3.07k params)\n","  BoxPredictor_5 (--/4.64k params)\n","    BoxPredictor_5/BoxEncodingPredictor (--/3.10k params)\n","      BoxPredictor_5/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_5/BoxEncodingPredictor/weights (1x1x128x24, 3.07k/3.07k params)\n","    BoxPredictor_5/ClassPredictor (--/1.55k params)\n","      BoxPredictor_5/ClassPredictor/biases (12, 12/12 params)\n","      BoxPredictor_5/ClassPredictor/weights (1x1x128x12, 1.54k/1.54k params)\n","  FeatureExtractor (--/4.48m params)\n","    FeatureExtractor/MobilenetV2 (--/4.48m params)\n","      FeatureExtractor/MobilenetV2/Conv (--/864 params)\n","        FeatureExtractor/MobilenetV2/Conv/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/Conv/weights (3x3x3x32, 864/864 params)\n","      FeatureExtractor/MobilenetV2/Conv_1 (--/409.60k params)\n","        FeatureExtractor/MobilenetV2/Conv_1/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/Conv_1/weights (1x1x320x1280, 409.60k/409.60k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv (--/800 params)\n","        FeatureExtractor/MobilenetV2/expanded_conv/depthwise (--/288 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/depthwise/depthwise_weights (3x3x32x1, 288/288 params)\n","        FeatureExtractor/MobilenetV2/expanded_conv/project (--/512 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/project/weights (1x1x32x16, 512/512 params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_1 (--/4.70k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise (--/864 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/depthwise_weights (3x3x96x1, 864/864 params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_1/expand (--/1.54k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/expand/weights (1x1x16x96, 1.54k/1.54k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_1/project (--/2.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/project/weights (1x1x96x24, 2.30k/2.30k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_10 (--/64.90k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_10/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_10/project (--/36.86k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/project/weights (1x1x384x96, 36.86k/36.86k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_11 (--/115.78k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise (--/5.18k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_11/expand (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/expand/weights (1x1x96x576, 55.30k/55.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_11/project (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/project/weights (1x1x576x96, 55.30k/55.30k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_12 (--/115.78k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise (--/5.18k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_12/expand (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/expand/weights (1x1x96x576, 55.30k/55.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_12/project (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/project/weights (1x1x576x96, 55.30k/55.30k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_13 (--/152.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise (--/5.18k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_13/expand (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/expand/weights (1x1x96x576, 55.30k/55.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_13/project (--/92.16k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/project/weights (1x1x576x160, 92.16k/92.16k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_14 (--/315.84k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise (--/8.64k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_14/expand (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/expand/weights (1x1x160x960, 153.60k/153.60k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_14/project (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/project/weights (1x1x960x160, 153.60k/153.60k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_15 (--/315.84k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise (--/8.64k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_15/expand (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/expand/weights (1x1x160x960, 153.60k/153.60k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_15/project (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/project/weights (1x1x960x160, 153.60k/153.60k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_16 (--/469.44k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise (--/8.64k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_16/expand (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/expand/weights (1x1x160x960, 153.60k/153.60k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_16/project (--/307.20k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/project/weights (1x1x960x320, 307.20k/307.20k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_2 (--/8.21k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise (--/1.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/depthwise_weights (3x3x144x1, 1.30k/1.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_2/expand (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/expand/weights (1x1x24x144, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_2/project (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/project/weights (1x1x144x24, 3.46k/3.46k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_3 (--/9.36k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise (--/1.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/depthwise_weights (3x3x144x1, 1.30k/1.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_3/expand (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/expand/weights (1x1x24x144, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_3/project (--/4.61k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/project/weights (1x1x144x32, 4.61k/4.61k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_4 (--/14.02k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise (--/1.73k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_4/expand (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/expand/weights (1x1x32x192, 6.14k/6.14k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_4/project (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/project/weights (1x1x192x32, 6.14k/6.14k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_5 (--/14.02k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise (--/1.73k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_5/expand (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/expand/weights (1x1x32x192, 6.14k/6.14k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_5/project (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/project/weights (1x1x192x32, 6.14k/6.14k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_6 (--/20.16k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise (--/1.73k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_6/expand (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/expand/weights (1x1x32x192, 6.14k/6.14k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_6/project (--/12.29k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/project/weights (1x1x192x64, 12.29k/12.29k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_7 (--/52.61k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_7/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_7/project (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/project/weights (1x1x384x64, 24.58k/24.58k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_8 (--/52.61k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_8/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_8/project (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/project/weights (1x1x384x64, 24.58k/24.58k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_9 (--/52.61k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_9/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_9/project (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/project/weights (1x1x384x64, 24.58k/24.58k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256 (--/327.68k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/weights (1x1x1280x256, 327.68k/327.68k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128 (--/65.54k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/weights (1x1x512x128, 65.54k/65.54k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128 (--/32.77k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/weights (1x1x256x128, 32.77k/32.77k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64 (--/16.38k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/weights (1x1x256x64, 16.38k/16.38k params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512 (--/1.18m params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights (3x3x256x512, 1.18m/1.18m params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256 (--/294.91k params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256 (--/294.91k params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128 (--/73.73k params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights (3x3x64x128, 73.73k/73.73k params)\n","\n","======================End of Report==========================\n","151 ops no flops stats due to incomplete shapes.\n","Parsing Inputs...\n","Incomplete shape.\n","\n","=========================Options=============================\n","-max_depth                  10000\n","-min_bytes                  0\n","-min_peak_bytes             0\n","-min_residual_bytes         0\n","-min_output_bytes           0\n","-min_micros                 0\n","-min_accelerator_micros     0\n","-min_cpu_micros             0\n","-min_params                 0\n","-min_float_ops              1\n","-min_occurrence             0\n","-step                       -1\n","-order_by                   float_ops\n","-account_type_regexes       .*\n","-start_name_regexes         .*\n","-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n","-show_name_regexes          .*\n","-hide_name_regexes          \n","-account_displayed_op_only  true\n","-select                     float_ops\n","-output                     stdout:\n","\n","==================Model Analysis Report======================\n","Incomplete shape.\n","\n","Doc:\n","scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n","flops: Number of float operations. Note: Please read the implementation for the math behind it.\n","\n","Profile:\n","node name | # float_ops\n","_TFProfRoot (--/17.63k flops)\n","  MultipleGridAnchorGenerator/sub (2.17k/2.17k flops)\n","  MultipleGridAnchorGenerator/add_2 (2.17k/2.17k flops)\n","  MultipleGridAnchorGenerator/mul_20 (2.17k/2.17k flops)\n","  MultipleGridAnchorGenerator/mul_19 (2.17k/2.17k flops)\n","  MultipleGridAnchorGenerator/mul_27 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/sub_1 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/add_5 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/mul_28 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/mul_21 (1.08k/1.08k flops)\n","  MultipleGridAnchorGenerator/mul_29 (600/600 flops)\n","  MultipleGridAnchorGenerator/add_8 (300/300 flops)\n","  MultipleGridAnchorGenerator/mul_36 (300/300 flops)\n","  MultipleGridAnchorGenerator/sub_2 (300/300 flops)\n","  MultipleGridAnchorGenerator/mul_35 (300/300 flops)\n","  MultipleGridAnchorGenerator/mul_37 (150/150 flops)\n","  MultipleGridAnchorGenerator/sub_3 (108/108 flops)\n","  MultipleGridAnchorGenerator/mul_44 (108/108 flops)\n","  MultipleGridAnchorGenerator/mul_43 (108/108 flops)\n","  MultipleGridAnchorGenerator/add_11 (108/108 flops)\n","  MultipleGridAnchorGenerator/mul_45 (54/54 flops)\n","  MultipleGridAnchorGenerator/sub_4 (48/48 flops)\n","  MultipleGridAnchorGenerator/add_14 (48/48 flops)\n","  MultipleGridAnchorGenerator/mul_51 (48/48 flops)\n","  MultipleGridAnchorGenerator/mul_52 (48/48 flops)\n","  MultipleGridAnchorGenerator/mul_53 (24/24 flops)\n","  MultipleGridAnchorGenerator/add (19/19 flops)\n","  MultipleGridAnchorGenerator/mul_18 (19/19 flops)\n","  MultipleGridAnchorGenerator/mul_17 (19/19 flops)\n","  MultipleGridAnchorGenerator/add_1 (19/19 flops)\n","  MultipleGridAnchorGenerator/mul_59 (12/12 flops)\n","  MultipleGridAnchorGenerator/mul_60 (12/12 flops)\n","  MultipleGridAnchorGenerator/sub_5 (12/12 flops)\n","  MultipleGridAnchorGenerator/add_17 (12/12 flops)\n","  MultipleGridAnchorGenerator/add_4 (10/10 flops)\n","  MultipleGridAnchorGenerator/add_3 (10/10 flops)\n","  MultipleGridAnchorGenerator/mul_26 (10/10 flops)\n","  MultipleGridAnchorGenerator/mul_25 (10/10 flops)\n","  MultipleGridAnchorGenerator/mul_39 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_54 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_19 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_18 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_17 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_16 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_38 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_40 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_15 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_61 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_46 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_47 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_48 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_56 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_55 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_31 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_30 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_32 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_24 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_23 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_22 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_33 (5/5 flops)\n","  MultipleGridAnchorGenerator/mul_34 (5/5 flops)\n","  MultipleGridAnchorGenerator/add_7 (5/5 flops)\n","  MultipleGridAnchorGenerator/add_6 (5/5 flops)\n","  MultipleGridAnchorGenerator/add_9 (3/3 flops)\n","  MultipleGridAnchorGenerator/add_10 (3/3 flops)\n","  MultipleGridAnchorGenerator/truediv_14 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_14 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_15 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_16 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_42 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_41 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_49 (2/2 flops)\n","  MultipleGridAnchorGenerator/mul_50 (2/2 flops)\n","  MultipleGridAnchorGenerator/add_13 (2/2 flops)\n","  MultipleGridAnchorGenerator/add_12 (2/2 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n","  Preprocessor/map/while/add (1/1 flops)\n","  MultipleGridAnchorGenerator/Minimum (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/add (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n","  Preprocessor/map/while/add_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/add (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/add_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n","  Preprocessor/map/while/Less (1/1 flops)\n","  Preprocessor/map/while/Less_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_6 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_58 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_57 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_5 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_4 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_3 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_2 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_13 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_12 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_11 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_10 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_7 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul (1/1 flops)\n","  MultipleGridAnchorGenerator/assert_equal/Equal (1/1 flops)\n","  MultipleGridAnchorGenerator/add_23 (1/1 flops)\n","  MultipleGridAnchorGenerator/add_22 (1/1 flops)\n","  MultipleGridAnchorGenerator/add_21 (1/1 flops)\n","  MultipleGridAnchorGenerator/add_20 (1/1 flops)\n","  MultipleGridAnchorGenerator/add_19 (1/1 flops)\n","  MultipleGridAnchorGenerator/add_18 (1/1 flops)\n","  MultipleGridAnchorGenerator/add_16 (1/1 flops)\n","  MultipleGridAnchorGenerator/add_15 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_4 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_9 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_8 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_7 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_6 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_5 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_3 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_2 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_13 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_12 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_11 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_10 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_9 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_8 (1/1 flops)\n","\n","======================End of Report==========================\n","2020-09-08 16:38:11.391193: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n","2020-09-08 16:38:11.395657: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-09-08 16:38:11.396320: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-09-08 16:38:11.396612: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n","2020-09-08 16:38:11.398208: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n","2020-09-08 16:38:11.399946: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n","2020-09-08 16:38:11.400358: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n","2020-09-08 16:38:11.402088: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n","2020-09-08 16:38:11.403453: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n","2020-09-08 16:38:11.412561: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n","2020-09-08 16:38:11.412724: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-09-08 16:38:11.413578: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-09-08 16:38:11.414318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n","2020-09-08 16:38:11.414803: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n","2020-09-08 16:38:11.516641: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-09-08 16:38:11.517622: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2711d40 executing computations on platform CUDA. Devices:\n","2020-09-08 16:38:11.517674: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n","2020-09-08 16:38:11.519972: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n","2020-09-08 16:38:11.520362: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2710bc0 executing computations on platform Host. Devices:\n","2020-09-08 16:38:11.520410: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n","2020-09-08 16:38:11.520648: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-09-08 16:38:11.521300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-09-08 16:38:11.521408: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n","2020-09-08 16:38:11.521460: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n","2020-09-08 16:38:11.521498: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n","2020-09-08 16:38:11.521547: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n","2020-09-08 16:38:11.521572: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n","2020-09-08 16:38:11.521596: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n","2020-09-08 16:38:11.521625: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n","2020-09-08 16:38:11.521726: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-09-08 16:38:11.522517: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-09-08 16:38:11.523112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n","2020-09-08 16:38:11.523184: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n","2020-09-08 16:38:11.524683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-09-08 16:38:11.524711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n","2020-09-08 16:38:11.524721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n","2020-09-08 16:38:11.524858: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-09-08 16:38:11.525527: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-09-08 16:38:11.526092: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2020-09-08 16:38:11.526132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8849 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","W0908 16:38:11.527099 139914780792704 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","INFO:tensorflow:Restoring parameters from /root/models/trained_v2/model.ckpt-5000\n","I0908 16:38:11.528600 139914780792704 saver.py:1280] Restoring parameters from /root/models/trained_v2/model.ckpt-5000\n","2020-09-08 16:38:14.365598: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-09-08 16:38:14.366501: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-09-08 16:38:14.366596: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n","2020-09-08 16:38:14.366628: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n","2020-09-08 16:38:14.366668: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n","2020-09-08 16:38:14.366694: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n","2020-09-08 16:38:14.366723: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n","2020-09-08 16:38:14.366754: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n","2020-09-08 16:38:14.366783: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n","2020-09-08 16:38:14.366929: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-09-08 16:38:14.367757: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-09-08 16:38:14.368496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n","2020-09-08 16:38:14.368555: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-09-08 16:38:14.368567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n","2020-09-08 16:38:14.368614: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n","2020-09-08 16:38:14.368766: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-09-08 16:38:14.369522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-09-08 16:38:14.370158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8849 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from /root/models/trained_v2/model.ckpt-5000\n","I0908 16:38:14.371448 139914780792704 saver.py:1280] Restoring parameters from /root/models/trained_v2/model.ckpt-5000\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n","W0908 16:38:14.995067 139914780792704 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n","W0908 16:38:14.995368 139914780792704 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n","INFO:tensorflow:Froze 324 variables.\n","I0908 16:38:15.327028 139914780792704 graph_util_impl.py:311] Froze 324 variables.\n","INFO:tensorflow:Converted 324 variables to const ops.\n","I0908 16:38:15.423957 139914780792704 graph_util_impl.py:364] Converted 324 variables to const ops.\n","2020-09-08 16:38:15.591566: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-09-08 16:38:15.592292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-09-08 16:38:15.592392: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n","2020-09-08 16:38:15.592423: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n","2020-09-08 16:38:15.592454: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n","2020-09-08 16:38:15.592478: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n","2020-09-08 16:38:15.592505: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n","2020-09-08 16:38:15.592533: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n","2020-09-08 16:38:15.592561: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n","2020-09-08 16:38:15.592673: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-09-08 16:38:15.593391: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-09-08 16:38:15.593941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n","2020-09-08 16:38:15.593987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-09-08 16:38:15.593999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n","2020-09-08 16:38:15.594020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n","2020-09-08 16:38:15.594134: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-09-08 16:38:15.594902: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-09-08 16:38:15.595559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8849 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","WARNING:tensorflow:From /root/models/research/object_detection/exporter.py:384: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","W0908 16:38:16.093959 139914780792704 deprecation.py:323] From /root/models/research/object_detection/exporter.py:384: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","INFO:tensorflow:No assets to save.\n","I0908 16:38:16.094798 139914780792704 builder_impl.py:636] No assets to save.\n","INFO:tensorflow:No assets to write.\n","I0908 16:38:16.094935 139914780792704 builder_impl.py:456] No assets to write.\n","INFO:tensorflow:SavedModel written to: /root/drive/My Drive/RGB-D Hand detector/inference_graph_hand_RGBD_v2/saved_model/saved_model.pb\n","I0908 16:38:16.424933 139914780792704 builder_impl.py:421] SavedModel written to: /root/drive/My Drive/RGB-D Hand detector/inference_graph_hand_RGBD_v2/saved_model/saved_model.pb\n","INFO:tensorflow:Writing pipeline config file to /root/drive/My Drive/RGB-D Hand detector/inference_graph_hand_RGBD_v2/pipeline.config\n","I0908 16:38:16.451103 139914780792704 config_util.py:254] Writing pipeline config file to /root/drive/My Drive/RGB-D Hand detector/inference_graph_hand_RGBD_v2/pipeline.config\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TZW9GfAhbagl","colab_type":"text"},"source":["## Testing some images :"]},{"cell_type":"code","metadata":{"id":"uADBmhvcbeER","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1599583118070,"user_tz":-60,"elapsed":5374,"user":{"displayName":"Hazem Barka","photoUrl":"","userId":"05856545852072919715"}},"outputId":"8d223d70-cf25-4a20-ddfe-c6abc7936bdb"},"source":["# This is needed to display the images.\n","%matplotlib inline\n","%cd /root/models/research \n","import pathlib\n","import numpy as np\n","import os\n","import six.moves.urllib as urllib\n","import sys\n","import tarfile\n","import tensorflow as tf\n","import zipfile\n","\n","from collections import defaultdict\n","from io import StringIO\n","from matplotlib import pyplot as plt\n","from PIL import Image\n","from IPython.display import display\n","\n","from object_detection.utils import ops as utils_ops\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as vis_util\n","\n","\n","\n","# What model to download.\n","# Path to frozen detection graph. This is the actual model that is used for the object detection.\n","PATH_TO_CKPT = '/root/drive/My Drive/RGB-D Hand detector/inference_graph_hand_RGBD_v2/frozen_inference_graph.pb'\n","\n","# List of the strings that is used to add correct label for each box.\n","PATH_TO_LABELS = '/root/drive/My Drive/RGB-D Hand detector/inference_graph_hand_RGBD/hand_label_map_RGBD.pbtxt' \n","\n","NUM_CLASSES = 1"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/root/models/research\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9cJ8FuN8U4r4","colab_type":"code","colab":{}},"source":["detection_graph = tf.Graph()\n","with detection_graph.as_default():\n","  od_graph_def = tf.GraphDef()\n","  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n","    serialized_graph = fid.read()\n","    od_graph_def.ParseFromString(serialized_graph)\n","    tf.import_graph_def(od_graph_def, name='')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wqEm90PKVe9t","colab_type":"code","colab":{}},"source":["label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n","categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n","category_index = label_map_util.create_category_index(categories)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E56Y3oSpWUq0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1599583215856,"user_tz":-60,"elapsed":13866,"user":{"displayName":"Hazem Barka","photoUrl":"","userId":"05856545852072919715"}},"outputId":"59fa324f-11e4-4d3c-8d7e-c75863408239"},"source":["print(category_index)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{1: {'id': 1, 'name': 'hand'}}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MOeE5o5dc4XC","colab_type":"code","colab":{}},"source":["def run_inference_for_single_image(image, graph):\n","  with graph.as_default():\n","    with tf.Session() as sess:\n","      # Get handles to input and output tensors\n","      ops = tf.get_default_graph().get_operations()\n","      all_tensor_names = {output.name for op in ops for output in op.outputs}\n","      tensor_dict = {}\n","      for key in [\n","          'num_detections', 'detection_boxes', 'detection_scores',\n","          'detection_classes', 'detection_masks'\n","      ]:\n","        tensor_name = key + ':0'\n","        if tensor_name in all_tensor_names:\n","          tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n","              tensor_name)\n","      if 'detection_masks' in tensor_dict:\n","        # The following processing is only for single image\n","        detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n","        detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n","        # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n","        real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n","        detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n","        detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n","        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n","            detection_masks, detection_boxes, image.shape[0], image.shape[1])\n","        detection_masks_reframed = tf.cast(\n","            tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n","        # Follow the convention by adding back the batch dimension\n","        tensor_dict['detection_masks'] = tf.expand_dims(\n","            detection_masks_reframed, 0)\n","      image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n","\n","      # Run inference\n","      output_dict = sess.run(tensor_dict,\n","                             feed_dict={image_tensor: np.expand_dims(image, 0)})\n","\n","      # all outputs are float32 numpy arrays, so convert types as appropriate\n","      output_dict['num_detections'] = int(output_dict['num_detections'][0])\n","      output_dict['detection_classes'] = output_dict[\n","          'detection_classes'][0].astype(np.uint8)\n","      output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n","      output_dict['detection_scores'] = output_dict['detection_scores'][0]\n","      if 'detection_masks' in output_dict:\n","        output_dict['detection_masks'] = output_dict['detection_masks'][0]\n","  return output_dict"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pmpq3O8Tbk3a","colab_type":"code","colab":{}},"source":["%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'\n","from IPython.display import clear_output\n","\n","\n","def load_image_into_numpy_array(image):\n","  (im_width, im_height) = image.size\n","  return np.array(image.getdata()).reshape(\n","      (im_height, im_width, 3)).astype(np.uint8)\n","# For the sake of simplicity we will use only 5 images:\n","# from image1.jpg\n","# to image5.jpg\n","# If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.\n","PATH_TO_TEST_IMAGES_DIR = '/root/dataset/test/'\n","TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, 'depth_1_000{}0.png'.format(i)) for i in range(600, 700) ]\n","\n","# Size, in inches, of the output images.\n","IMAGE_SIZE = (8, 5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qLIFwC9Qc788","colab_type":"code","colab":{}},"source":["\n","for image_path in TEST_IMAGE_PATHS:\n","  image = Image.open(image_path).convert('RGB')\n","  # the array based representation of the image will be used later in order to prepare the\n","  # result image with boxes and labels on it.\n","  image_np = load_image_into_numpy_array(image)\n","  # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n","  image_np_expanded = np.expand_dims(image_np, axis=0)\n","  # Actual detection.\n","  output_dict = run_inference_for_single_image(image_np, detection_graph)\n","  # Visualization of the results of a detection.\n","  vis_util.visualize_boxes_and_labels_on_image_array(\n","      image_np,\n","      output_dict['detection_boxes'],\n","      output_dict['detection_classes'],\n","      output_dict['detection_scores'],\n","      category_index,\n","      instance_masks=output_dict.get('detection_masks'),\n","      use_normalized_coordinates=True,\n","      line_thickness=10)\n","  plt.figure(figsize=IMAGE_SIZE)\n","  plt.imshow(image_np)\n","  plt.pause(0.04)\n","  clear_output(wait=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3lxxH8PMfS51","colab_type":"code","colab":{}},"source":["output_dict['detection_scores']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vk41u0ggfvI4","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}